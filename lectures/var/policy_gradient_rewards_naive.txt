epoch = 0, step = 0, loss = 1.164, reward = 2.333
  prompt = tensor([1, 0, 2])
    response = tensor([4, 2, 1]), log_probs = [-0.229, -1.052, -2.869], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.229, -0.440, -0.457], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 4]), log_probs = [-1.700, -0.440, -1.176], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 3]), log_probs = [-1.700, -0.440, -0.457], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 3]), log_probs = [-0.229, -0.440, -0.457], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 3]), log_probs = [-1.700, -0.440, -0.457], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-0.229, -1.052, -1.176], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.229, -0.440, -0.457], reward = 2.0, delta = 2.000
    response = tensor([4, 2, 1]), log_probs = [-0.229, -1.052, -2.869], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.229, -0.440, -0.457], reward = 2.0, delta = 2.000
  prompt = tensor([3, 2, 4])
    response = tensor([0, 0, 0]), log_probs = [-0.960, -0.628, -0.133], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 0]), log_probs = [-0.485, -0.766, -0.133], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.485, -0.628, -2.167], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.485, -0.628, -0.133], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.485, -0.628, -0.133], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 0]), log_probs = [-0.485, -0.766, -0.133], reward = 1.0, delta = 1.000
    response = tensor([3, 1, 0]), log_probs = [-0.485, -0.766, -0.133], reward = 1.0, delta = 1.000
    response = tensor([0, 0, 0]), log_probs = [-0.960, -0.628, -0.133], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.485, -0.766, -2.167], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.485, -0.628, -0.133], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.043, -1.327, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.043, -1.327, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.043, -0.315, -0.000], reward = 3.0, delta = 3.000
epoch = 0, step = 1, loss = 1.100, reward = 2.333
epoch = 0, step = 2, loss = 1.073, reward = 2.333
epoch = 0, step = 3, loss = 1.072, reward = 2.333
epoch = 0, step = 4, loss = 1.080, reward = 2.333
epoch = 0, step = 5, loss = 1.084, reward = 2.333
  prompt = tensor([1, 0, 2])
    response = tensor([4, 2, 1]), log_probs = [-0.840, -1.511, -1.571], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.840, -0.256, -0.557], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 4]), log_probs = [-0.592, -0.256, -1.520], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 3]), log_probs = [-0.592, -0.256, -0.557], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 3]), log_probs = [-0.840, -0.256, -0.557], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 3]), log_probs = [-0.592, -0.256, -0.557], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-0.840, -1.511, -1.520], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.840, -0.256, -0.557], reward = 2.0, delta = 2.000
    response = tensor([4, 2, 1]), log_probs = [-0.840, -1.511, -1.571], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.840, -0.256, -0.557], reward = 2.0, delta = 2.000
  prompt = tensor([3, 2, 4])
    response = tensor([0, 0, 0]), log_probs = [-1.748, -0.225, -0.337], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 0]), log_probs = [-0.193, -1.605, -0.337], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.193, -0.225, -1.297], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.193, -0.225, -0.337], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.193, -0.225, -0.337], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 0]), log_probs = [-0.193, -1.605, -0.337], reward = 1.0, delta = 1.000
    response = tensor([3, 1, 0]), log_probs = [-0.193, -1.605, -0.337], reward = 1.0, delta = 1.000
    response = tensor([0, 0, 0]), log_probs = [-1.748, -0.225, -0.337], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.193, -1.605, -1.297], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.193, -0.225, -0.337], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.011, -1.781, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.011, -1.781, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.011, -0.190, -0.000], reward = 3.0, delta = 3.000
epoch = 0, step = 6, loss = 1.081, reward = 2.333
epoch = 0, step = 7, loss = 1.072, reward = 2.333
epoch = 0, step = 8, loss = 1.065, reward = 2.333
epoch = 0, step = 9, loss = 1.061, reward = 2.333
epoch = 1, step = 0, loss = 1.258, reward = 2.500
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 3]), log_probs = [-1.064, -1.346, -0.447], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 3]), log_probs = [-0.440, -0.307, -0.447], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.440, -0.307, -0.447], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-1.064, -1.346, -1.883], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 1]), log_probs = [-0.440, -0.307, -1.571], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-1.064, -1.346, -0.447], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 1]), log_probs = [-1.064, -1.346, -1.571], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 3]), log_probs = [-1.064, -0.307, -0.447], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 4]), log_probs = [-0.440, -0.307, -1.883], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.440, -0.307, -0.447], reward = 2.0, delta = 2.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 0]), log_probs = [-0.294, -0.374, -0.282], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.294, -0.374, -1.446], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.294, -0.374, -0.282], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.294, -0.374, -1.446], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.294, -0.374, -0.282], reward = 2.0, delta = 2.000
    response = tensor([0, 1, 0]), log_probs = [-1.374, -1.168, -0.282], reward = 1.0, delta = 1.000
    response = tensor([0, 0, 0]), log_probs = [-1.374, -0.374, -0.282], reward = 2.0, delta = 2.000
    response = tensor([0, 0, 0]), log_probs = [-1.374, -0.374, -0.282], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.294, -0.374, -1.446], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.294, -1.168, -1.446], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.010, -1.622, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.010, -0.226, -0.000], reward = 3.0, delta = 3.000
epoch = 1, step = 1, loss = 1.243, reward = 2.500
epoch = 1, step = 2, loss = 1.218, reward = 2.500
epoch = 1, step = 3, loss = 1.194, reward = 2.500
epoch = 1, step = 4, loss = 1.176, reward = 2.500
epoch = 1, step = 5, loss = 1.165, reward = 2.500
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 3]), log_probs = [-0.722, -0.684, -0.618], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 3]), log_probs = [-0.679, -0.719, -0.618], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.679, -0.719, -0.618], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.722, -0.684, -1.571], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 1]), log_probs = [-0.679, -0.719, -1.378], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.722, -0.684, -0.618], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 1]), log_probs = [-0.722, -0.684, -1.378], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 3]), log_probs = [-0.722, -0.719, -0.618], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 4]), log_probs = [-0.679, -0.719, -1.571], reward = 2.0, delta = 2.000
    response = tensor([4, 0, 3]), log_probs = [-0.679, -0.719, -0.618], reward = 2.0, delta = 2.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 0]), log_probs = [-0.339, -0.228, -0.677], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.339, -0.228, -0.729], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.339, -0.228, -0.677], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.339, -0.228, -0.729], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.339, -0.228, -0.677], reward = 2.0, delta = 2.000
    response = tensor([0, 1, 0]), log_probs = [-1.251, -1.595, -0.677], reward = 1.0, delta = 1.000
    response = tensor([0, 0, 0]), log_probs = [-1.251, -0.228, -0.677], reward = 2.0, delta = 2.000
    response = tensor([0, 0, 0]), log_probs = [-1.251, -0.228, -0.677], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.339, -0.228, -0.729], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.339, -1.595, -0.729], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.005, -1.988, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.151, -0.000], reward = 3.0, delta = 3.000
epoch = 1, step = 6, loss = 1.161, reward = 2.500
epoch = 1, step = 7, loss = 1.162, reward = 2.500
epoch = 1, step = 8, loss = 1.166, reward = 2.500
epoch = 1, step = 9, loss = 1.170, reward = 2.500
epoch = 2, step = 0, loss = 1.214, reward = 2.533
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 3]), log_probs = [-0.328, -0.678, -0.591], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-1.290, -0.678, -1.569], reward = 2.0, delta = 2.000
    response = tensor([4, 2, 4]), log_probs = [-1.290, -0.678, -1.569], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 3]), log_probs = [-0.328, -0.678, -0.591], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.328, -0.678, -0.591], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.328, -0.678, -0.591], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 1]), log_probs = [-1.290, -0.678, -1.439], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 3]), log_probs = [-0.328, -0.728, -0.591], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 1]), log_probs = [-0.328, -0.678, -1.439], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 4]), log_probs = [-0.328, -0.728, -1.569], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([0, 0, 0]), log_probs = [-1.348, -0.094, -0.527], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.303, -0.094, -0.527], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.303, -0.094, -0.527], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.303, -2.418, -0.912], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.303, -0.094, -0.912], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.303, -2.418, -0.912], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 0]), log_probs = [-0.303, -2.418, -0.527], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 0]), log_probs = [-0.303, -0.094, -0.527], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.303, -2.418, -0.912], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.303, -0.094, -0.527], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -2.578, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.082, -0.000], reward = 3.0, delta = 3.000
epoch = 2, step = 1, loss = 1.201, reward = 2.533
epoch = 2, step = 2, loss = 1.179, reward = 2.533
epoch = 2, step = 3, loss = 1.154, reward = 2.533
epoch = 2, step = 4, loss = 1.130, reward = 2.533
epoch = 2, step = 5, loss = 1.111, reward = 2.533
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 3]), log_probs = [-0.263, -0.370, -0.572], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-1.477, -0.370, -1.396], reward = 2.0, delta = 2.000
    response = tensor([4, 2, 4]), log_probs = [-1.477, -0.370, -1.396], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 3]), log_probs = [-0.263, -0.370, -0.572], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.263, -0.370, -0.572], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.263, -0.370, -0.572], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 1]), log_probs = [-1.477, -0.370, -1.676], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 3]), log_probs = [-0.263, -1.207, -0.572], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 1]), log_probs = [-0.263, -0.370, -1.676], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 4]), log_probs = [-0.263, -1.207, -1.396], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([0, 0, 0]), log_probs = [-2.023, -0.255, -0.762], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.143, -0.255, -0.762], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.143, -0.255, -0.762], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.143, -1.497, -0.642], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.143, -0.255, -0.642], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.143, -1.497, -0.642], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 0]), log_probs = [-0.143, -1.497, -0.762], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 0]), log_probs = [-0.143, -0.255, -0.762], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.143, -1.497, -0.642], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.143, -0.255, -0.762], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -2.886, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.060, -0.000], reward = 3.0, delta = 3.000
epoch = 2, step = 6, loss = 1.097, reward = 2.533
epoch = 2, step = 7, loss = 1.091, reward = 2.533
epoch = 2, step = 8, loss = 1.092, reward = 2.533
epoch = 2, step = 9, loss = 1.098, reward = 2.533
epoch = 3, step = 0, loss = 1.320, reward = 2.500
  prompt = tensor([1, 0, 2])
    response = tensor([4, 2, 4]), log_probs = [-1.547, -0.166, -1.224], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 3]), log_probs = [-0.242, -0.166, -0.654], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.242, -0.166, -1.224], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.242, -0.166, -1.224], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 3]), log_probs = [-1.547, -0.166, -0.654], reward = 2.0, delta = 2.000
    response = tensor([4, 2, 4]), log_probs = [-1.547, -0.166, -1.224], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.242, -0.166, -1.224], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 1]), log_probs = [-1.547, -0.166, -1.684], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 4]), log_probs = [-0.242, -1.942, -1.224], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.242, -0.166, -0.654], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.080, -0.683, -1.057], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.080, -0.683, -0.437], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.080, -0.683, -1.057], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.080, -0.683, -0.437], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.080, -0.706, -1.057], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.080, -0.683, -1.057], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.080, -0.683, -1.057], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.080, -0.683, -0.437], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.080, -0.683, -1.057], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.080, -0.706, -1.057], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.065, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.065, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.065, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.065, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -2.803, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -2.803, -0.000], reward = 3.0, delta = 3.000
    response = tensor([4, 4, 1]), log_probs = [-6.563, -0.065, -0.000], reward = 2.0, delta = 2.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.065, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.065, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.065, -0.000], reward = 3.0, delta = 3.000
epoch = 3, step = 1, loss = 1.293, reward = 2.500
epoch = 3, step = 2, loss = 1.249, reward = 2.500
epoch = 3, step = 3, loss = 1.204, reward = 2.500
epoch = 3, step = 4, loss = 1.165, reward = 2.500
epoch = 3, step = 5, loss = 1.135, reward = 2.500
  prompt = tensor([1, 0, 2])
    response = tensor([4, 2, 4]), log_probs = [-1.155, -0.075, -0.756], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 3]), log_probs = [-0.382, -0.075, -0.885], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.382, -0.075, -0.756], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.382, -0.075, -0.756], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 3]), log_probs = [-1.155, -0.075, -0.885], reward = 2.0, delta = 2.000
    response = tensor([4, 2, 4]), log_probs = [-1.155, -0.075, -0.756], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.382, -0.075, -0.756], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 1]), log_probs = [-1.155, -0.075, -2.146], reward = 2.0, delta = 2.000
    response = tensor([2, 0, 4]), log_probs = [-0.382, -2.743, -0.756], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.382, -0.075, -0.885], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.511, -0.307], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.033, -0.511, -1.351], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.511, -0.307], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.033, -0.511, -1.351], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.033, -0.919, -0.307], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.511, -0.307], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.511, -0.307], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.033, -0.511, -1.351], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.511, -0.307], reward = 2.0, delta = 2.000
    response = tensor([3, 1, 1]), log_probs = [-0.033, -0.919, -0.307], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.131, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.131, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.131, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.131, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.003, -2.117, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.003, -2.117, -0.000], reward = 3.0, delta = 3.000
    response = tensor([4, 4, 1]), log_probs = [-5.951, -0.131, -0.000], reward = 2.0, delta = 2.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.131, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.131, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.131, -0.000], reward = 3.0, delta = 3.000
epoch = 3, step = 6, loss = 1.113, reward = 2.500
epoch = 3, step = 7, loss = 1.100, reward = 2.500
epoch = 3, step = 8, loss = 1.094, reward = 2.500
epoch = 3, step = 9, loss = 1.093, reward = 2.500
epoch = 4, step = 0, loss = 1.074, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.540, -0.049, -0.380], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.540, -0.049, -0.380], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.540, -0.049, -0.380], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.540, -0.049, -0.380], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.540, -0.049, -1.393], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 4]), log_probs = [-0.879, -3.217, -0.380], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.540, -0.049, -0.380], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.540, -0.049, -0.380], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.540, -0.049, -1.393], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.540, -0.049, -0.380], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.014, -0.131, -0.288], reward = 2.0, delta = 2.000
    response = tensor([3, 3, 0]), log_probs = [-0.014, -7.372, -1.404], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.014, -0.131, -0.288], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.014, -0.131, -1.404], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.014, -0.131, -0.288], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.014, -0.131, -1.404], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.014, -0.131, -1.404], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.014, -0.131, -1.404], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.014, -0.131, -0.288], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.014, -0.131, -1.404], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.007, -0.279, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.007, -0.279, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.007, -1.429, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.007, -0.279, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.007, -1.429, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.007, -1.429, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.007, -0.279, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.007, -0.279, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.007, -0.279, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.007, -0.279, -0.000], reward = 3.0, delta = 3.000
epoch = 4, step = 1, loss = 1.025, reward = 2.633
epoch = 4, step = 2, loss = 0.974, reward = 2.633
epoch = 4, step = 3, loss = 0.939, reward = 2.633
epoch = 4, step = 4, loss = 0.925, reward = 2.633
epoch = 4, step = 5, loss = 0.923, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.178, -0.062, -0.213], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.178, -0.062, -0.213], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.178, -0.062, -0.213], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.178, -0.062, -0.213], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.178, -0.062, -1.932], reward = 3.0, delta = 3.000
    response = tensor([4, 0, 4]), log_probs = [-1.823, -2.951, -0.213], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.178, -0.062, -0.213], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.178, -0.062, -0.213], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.178, -0.062, -1.932], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.178, -0.062, -0.213], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.028, -1.460], reward = 2.0, delta = 2.000
    response = tensor([3, 3, 0]), log_probs = [-0.008, -8.042, -0.271], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.028, -1.460], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.008, -0.028, -0.271], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.028, -1.460], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.008, -0.028, -0.271], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.008, -0.028, -0.271], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.008, -0.028, -0.271], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.028, -1.460], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.008, -0.028, -0.271], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.008, -0.430, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.008, -0.430, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.008, -1.066, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.008, -0.430, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.008, -1.066, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.008, -1.066, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.008, -0.430, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.008, -0.430, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.008, -0.430, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.008, -0.430, -0.000], reward = 3.0, delta = 3.000
epoch = 4, step = 6, loss = 0.923, reward = 2.633
epoch = 4, step = 7, loss = 0.919, reward = 2.633
epoch = 4, step = 8, loss = 0.911, reward = 2.633
epoch = 4, step = 9, loss = 0.900, reward = 2.633
epoch = 5, step = 0, loss = 0.706, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.104, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.104, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.040, -0.104, -2.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.104, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.104, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.104, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.104, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 4]), log_probs = [-0.040, -2.387, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.040, -4.960, -0.176], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.104, -0.176], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.006, -0.021, -1.091], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.006, -0.021, -1.091], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.006, -0.021, -0.418], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.005, -1.021, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.005, -0.454, -0.000], reward = 3.0, delta = 3.000
epoch = 5, step = 1, loss = 0.698, reward = 2.667
epoch = 5, step = 2, loss = 0.681, reward = 2.667
epoch = 5, step = 3, loss = 0.657, reward = 2.667
epoch = 5, step = 4, loss = 0.632, reward = 2.667
epoch = 5, step = 5, loss = 0.611, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.013, -0.149, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.013, -0.149, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.013, -0.149, -2.192], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.013, -0.149, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.013, -0.149, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.013, -0.149, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.013, -0.149, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 0, 4]), log_probs = [-0.013, -2.077, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.013, -4.382, -0.135], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.013, -0.149, -0.135], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.004, -0.015, -1.335], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.004, -0.015, -1.335], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.015, -0.312], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.003, -1.725, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.003, -0.201, -0.000], reward = 3.0, delta = 3.000
epoch = 5, step = 6, loss = 0.595, reward = 2.667
epoch = 5, step = 7, loss = 0.586, reward = 2.667
epoch = 5, step = 8, loss = 0.581, reward = 2.667
epoch = 5, step = 9, loss = 0.578, reward = 2.667
epoch = 6, step = 0, loss = 0.494, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.006, -0.176, -0.089], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.004, -0.008, -2.207], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.008, -0.120], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.008, -0.120], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.008, -0.120], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.004, -0.008, -2.207], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.008, -0.120], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 3]), log_probs = [-0.004, -0.008, -5.659], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.004, -0.008, -2.207], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.008, -0.120], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.004, -0.008, -0.120], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -2.712, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.071, -0.000], reward = 3.0, delta = 3.000
epoch = 6, step = 1, loss = 0.490, reward = 2.667
epoch = 6, step = 2, loss = 0.477, reward = 2.667
epoch = 6, step = 3, loss = 0.460, reward = 2.667
epoch = 6, step = 4, loss = 0.444, reward = 2.667
epoch = 6, step = 5, loss = 0.433, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.143, -0.049], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.008, -1.122], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.008, -0.402], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.008, -0.402], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.008, -0.402], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.008, -1.122], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.008, -0.402], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 3]), log_probs = [-0.003, -0.008, -5.251], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.008, -1.122], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.008, -0.402], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.008, -0.402], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -3.196, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.043, -0.000], reward = 3.0, delta = 3.000
epoch = 6, step = 6, loss = 0.429, reward = 2.667
epoch = 6, step = 7, loss = 0.429, reward = 2.667
epoch = 6, step = 8, loss = 0.427, reward = 2.667
epoch = 6, step = 9, loss = 0.421, reward = 2.667
epoch = 7, step = 0, loss = 0.494, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.003, -2.764, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.003, -2.764, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.003, -0.088, -0.024], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.007, -0.700], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.007, -0.700], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.007, -0.700], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.007, -0.701], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.007, -0.701], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.007, -0.700], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.007, -0.701], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.007, -0.700], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.007, -0.700], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.007, -0.701], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -3.147, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.045, -0.000], reward = 3.0, delta = 3.000
epoch = 7, step = 1, loss = 0.492, reward = 2.667
epoch = 7, step = 2, loss = 0.487, reward = 2.667
epoch = 7, step = 3, loss = 0.479, reward = 2.667
epoch = 7, step = 4, loss = 0.470, reward = 2.667
epoch = 7, step = 5, loss = 0.462, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -2.434, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -2.434, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.101, -0.013], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.006, -0.515], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.006, -0.515], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.006, -0.515], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.006, -0.932], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.006, -0.932], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.006, -0.515], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.006, -0.932], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.006, -0.515], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.006, -0.515], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.003, -0.006, -0.932], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -2.877, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.059, -0.000], reward = 3.0, delta = 3.000
epoch = 7, step = 6, loss = 0.455, reward = 2.667
epoch = 7, step = 7, loss = 0.449, reward = 2.667
epoch = 7, step = 8, loss = 0.443, reward = 2.667
epoch = 7, step = 9, loss = 0.439, reward = 2.667
epoch = 8, step = 0, loss = 0.384, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.597, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.232, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.232, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.232, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.232, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.232, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.232, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.597, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.232, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.597, -0.008], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.005, -1.086], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.005, -0.426], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.005, -0.426], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.005, -0.426], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.005, -0.426], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.005, -0.426], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.005, -1.086], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.005, -1.086], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.005, -0.426], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.005, -0.426], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.079, -0.000], reward = 3.0, delta = 3.000
epoch = 8, step = 1, loss = 0.379, reward = 2.667
epoch = 8, step = 2, loss = 0.376, reward = 2.667
epoch = 8, step = 3, loss = 0.375, reward = 2.667
epoch = 8, step = 4, loss = 0.376, reward = 2.667
epoch = 8, step = 5, loss = 0.379, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 4, 4]), log_probs = [-0.002, -0.902, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.524, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.524, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.524, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.524, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.524, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.524, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -0.902, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.524, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -0.902, -0.005], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.004, -1.206], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.370], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.370], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.370], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.370], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.370], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.004, -1.206], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.004, -1.206], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.370], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.370], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.072, -0.000], reward = 3.0, delta = 3.000
epoch = 8, step = 6, loss = 0.380, reward = 2.667
epoch = 8, step = 7, loss = 0.381, reward = 2.667
epoch = 8, step = 8, loss = 0.378, reward = 2.667
epoch = 8, step = 9, loss = 0.374, reward = 2.667
epoch = 9, step = 0, loss = 1.057, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.503, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -0.933, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.503, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -0.933, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.503, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.503, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.503, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -0.933, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -0.933, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.503, -0.004], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.004, -1.302], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.330], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.050, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.050, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.050, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.050, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 1]), log_probs = [-0.001, -7.859, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 4]), log_probs = [-0.001, -3.041, -7.712], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.050, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -3.041, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.050, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.050, -0.000], reward = 3.0, delta = 3.000
epoch = 9, step = 1, loss = 1.050, reward = 2.667
epoch = 9, step = 2, loss = 1.037, reward = 2.667
epoch = 9, step = 3, loss = 1.022, reward = 2.667
epoch = 9, step = 4, loss = 1.005, reward = 2.667
epoch = 9, step = 5, loss = 0.989, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.336, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.259, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.336, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.259, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.336, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.336, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.336, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.259, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.259, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.336, -0.003], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 0]), log_probs = [-0.002, -0.004, -2.214], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.123], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.068, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.068, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.068, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.068, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 1]), log_probs = [-0.001, -7.217, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 4]), log_probs = [-0.001, -2.744, -7.113], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.068, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -2.744, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.068, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.068, -0.001], reward = 3.0, delta = 3.000
epoch = 9, step = 6, loss = 0.971, reward = 2.667
epoch = 9, step = 7, loss = 0.953, reward = 2.667
epoch = 9, step = 8, loss = 0.933, reward = 2.667
epoch = 9, step = 9, loss = 0.913, reward = 2.667
epoch = 10, step = 0, loss = 0.394, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.233, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.347, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.347, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.233, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.347, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.347, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.347, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.347, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.347, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.002, -1.233, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.061], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.971, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.971, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.153, -0.003], reward = 3.0, delta = 3.000
epoch = 10, step = 1, loss = 0.390, reward = 2.667
epoch = 10, step = 2, loss = 0.387, reward = 2.667
epoch = 10, step = 3, loss = 0.387, reward = 2.667
epoch = 10, step = 4, loss = 0.387, reward = 2.667
epoch = 10, step = 5, loss = 0.388, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.121, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.397, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.397, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.121, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.397, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.397, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.397, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.397, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.397, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.121, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.032], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.351, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.351, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.305, -0.006], reward = 3.0, delta = 3.000
epoch = 10, step = 6, loss = 0.390, reward = 2.667
epoch = 10, step = 7, loss = 0.391, reward = 2.667
epoch = 10, step = 8, loss = 0.391, reward = 2.667
epoch = 10, step = 9, loss = 0.391, reward = 2.667
epoch = 11, step = 0, loss = 0.366, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.126, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.126, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.394, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.004, -0.014], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.232, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.232, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.352, -0.011], reward = 3.0, delta = 3.000
epoch = 11, step = 1, loss = 0.363, reward = 2.667
epoch = 11, step = 2, loss = 0.358, reward = 2.667
epoch = 11, step = 3, loss = 0.354, reward = 2.667
epoch = 11, step = 4, loss = 0.350, reward = 2.667
epoch = 11, step = 5, loss = 0.348, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.484, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.484, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.259, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.007], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.453, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.453, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.276, -0.015], reward = 3.0, delta = 3.000
epoch = 11, step = 6, loss = 0.347, reward = 2.667
epoch = 11, step = 7, loss = 0.347, reward = 2.667
epoch = 11, step = 8, loss = 0.347, reward = 2.667
epoch = 11, step = 9, loss = 0.348, reward = 2.667
epoch = 12, step = 0, loss = 0.465, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.001, -0.174, -6.667], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -1.841, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.174, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 1, 1]), log_probs = [-0.002, -1.715, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.002, -0.210, -0.016], reward = 3.0, delta = 3.000
epoch = 12, step = 1, loss = 0.461, reward = 2.667
epoch = 12, step = 2, loss = 0.455, reward = 2.667
epoch = 12, step = 3, loss = 0.448, reward = 2.667
epoch = 12, step = 4, loss = 0.440, reward = 2.667
epoch = 12, step = 5, loss = 0.433, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.001, -0.116, -6.056], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.001, -2.224, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.116, -0.003], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 1, 1]), log_probs = [-0.001, -2.035, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.152, -0.015], reward = 3.0, delta = 3.000
epoch = 12, step = 6, loss = 0.425, reward = 2.667
epoch = 12, step = 7, loss = 0.417, reward = 2.667
epoch = 12, step = 8, loss = 0.409, reward = 2.667
epoch = 12, step = 9, loss = 0.400, reward = 2.667
epoch = 13, step = 0, loss = 0.148, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.080, -0.008], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -2.335, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.113, -0.011], reward = 3.0, delta = 3.000
epoch = 13, step = 1, loss = 0.146, reward = 2.667
epoch = 13, step = 2, loss = 0.145, reward = 2.667
epoch = 13, step = 3, loss = 0.143, reward = 2.667
epoch = 13, step = 4, loss = 0.142, reward = 2.667
epoch = 13, step = 5, loss = 0.141, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.048, -0.022], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.002], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -2.450, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.102, -0.008], reward = 3.0, delta = 3.000
epoch = 13, step = 6, loss = 0.140, reward = 2.667
epoch = 13, step = 7, loss = 0.139, reward = 2.667
epoch = 13, step = 8, loss = 0.139, reward = 2.667
epoch = 13, step = 9, loss = 0.138, reward = 2.667
epoch = 14, step = 0, loss = 0.138, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.026, -0.036], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -2.414, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.108, -0.006], reward = 3.0, delta = 3.000
epoch = 14, step = 1, loss = 0.138, reward = 2.667
epoch = 14, step = 2, loss = 0.137, reward = 2.667
epoch = 14, step = 3, loss = 0.136, reward = 2.667
epoch = 14, step = 4, loss = 0.136, reward = 2.667
epoch = 14, step = 5, loss = 0.135, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.016, -0.037], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 1, 1]), log_probs = [-0.001, -2.342, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.117, -0.005], reward = 3.0, delta = 3.000
epoch = 14, step = 6, loss = 0.134, reward = 2.667
epoch = 14, step = 7, loss = 0.133, reward = 2.667
epoch = 14, step = 8, loss = 0.132, reward = 2.667
epoch = 14, step = 9, loss = 0.131, reward = 2.667
epoch = 15, step = 0, loss = 0.177, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.001, -0.012, -3.618], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.012, -0.028], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.005, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.122, -0.004], reward = 3.0, delta = 3.000
epoch = 15, step = 1, loss = 0.177, reward = 2.667
epoch = 15, step = 2, loss = 0.175, reward = 2.667
epoch = 15, step = 3, loss = 0.171, reward = 2.667
epoch = 15, step = 4, loss = 0.167, reward = 2.667
epoch = 15, step = 5, loss = 0.162, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.001, -0.010, -3.492], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.010, -0.032], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.087, -0.004], reward = 3.0, delta = 3.000
epoch = 15, step = 6, loss = 0.156, reward = 2.667
epoch = 15, step = 7, loss = 0.151, reward = 2.667
epoch = 15, step = 8, loss = 0.145, reward = 2.667
epoch = 15, step = 9, loss = 0.140, reward = 2.667
epoch = 16, step = 0, loss = 0.042, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.059], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.048, -0.004], reward = 3.0, delta = 3.000
epoch = 16, step = 1, loss = 0.042, reward = 2.667
epoch = 16, step = 2, loss = 0.042, reward = 2.667
epoch = 16, step = 3, loss = 0.041, reward = 2.667
epoch = 16, step = 4, loss = 0.040, reward = 2.667
epoch = 16, step = 5, loss = 0.038, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.070], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.004, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.026, -0.004], reward = 3.0, delta = 3.000
epoch = 16, step = 6, loss = 0.036, reward = 2.667
epoch = 16, step = 7, loss = 0.034, reward = 2.667
epoch = 16, step = 8, loss = 0.031, reward = 2.667
epoch = 16, step = 9, loss = 0.028, reward = 2.667
epoch = 17, step = 0, loss = 0.130, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.001, -0.009, -3.168], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.044], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.016, -0.004], reward = 3.0, delta = 3.000
epoch = 17, step = 1, loss = 0.132, reward = 2.667
epoch = 17, step = 2, loss = 0.132, reward = 2.667
epoch = 17, step = 3, loss = 0.132, reward = 2.667
epoch = 17, step = 4, loss = 0.132, reward = 2.667
epoch = 17, step = 5, loss = 0.130, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 3]), log_probs = [-0.001, -0.009, -3.262], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.009, -0.040], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.011, -0.004], reward = 3.0, delta = 3.000
epoch = 17, step = 6, loss = 0.129, reward = 2.667
epoch = 17, step = 7, loss = 0.127, reward = 2.667
epoch = 17, step = 8, loss = 0.125, reward = 2.667
epoch = 17, step = 9, loss = 0.123, reward = 2.667
epoch = 18, step = 0, loss = 0.030, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.008, -0.065], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.009, -0.004], reward = 3.0, delta = 3.000
epoch = 18, step = 1, loss = 0.032, reward = 2.667
epoch = 18, step = 2, loss = 0.033, reward = 2.667
epoch = 18, step = 3, loss = 0.033, reward = 2.667
epoch = 18, step = 4, loss = 0.032, reward = 2.667
epoch = 18, step = 5, loss = 0.031, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.069], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.008, -0.004], reward = 3.0, delta = 3.000
epoch = 18, step = 6, loss = 0.029, reward = 2.667
epoch = 18, step = 7, loss = 0.027, reward = 2.667
epoch = 18, step = 8, loss = 0.025, reward = 2.667
epoch = 18, step = 9, loss = 0.023, reward = 2.667
epoch = 19, step = 0, loss = 0.174, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-6.929, -0.007, -0.040], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.007, -0.040], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.003, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.007, -0.004], reward = 3.0, delta = 3.000
epoch = 19, step = 1, loss = 0.172, reward = 2.633
epoch = 19, step = 2, loss = 0.169, reward = 2.633
epoch = 19, step = 3, loss = 0.165, reward = 2.633
epoch = 19, step = 4, loss = 0.160, reward = 2.633
epoch = 19, step = 5, loss = 0.155, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-6.347, -0.007, -0.021], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.007, -0.021], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.006, -0.004], reward = 3.0, delta = 3.000
epoch = 19, step = 6, loss = 0.149, reward = 2.633
epoch = 19, step = 7, loss = 0.143, reward = 2.633
epoch = 19, step = 8, loss = 0.137, reward = 2.633
epoch = 19, step = 9, loss = 0.130, reward = 2.633
epoch = 20, step = 0, loss = 0.013, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.006, -0.013], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
epoch = 20, step = 1, loss = 0.013, reward = 2.667
epoch = 20, step = 2, loss = 0.014, reward = 2.667
epoch = 20, step = 3, loss = 0.014, reward = 2.667
epoch = 20, step = 4, loss = 0.015, reward = 2.667
epoch = 20, step = 5, loss = 0.015, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.020, -0.006, -0.009], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
epoch = 20, step = 6, loss = 0.016, reward = 2.667
epoch = 20, step = 7, loss = 0.016, reward = 2.667
epoch = 20, step = 8, loss = 0.017, reward = 2.667
epoch = 20, step = 9, loss = 0.017, reward = 2.667
epoch = 21, step = 0, loss = 0.097, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-3.654, -0.005, -0.006], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.026, -0.005, -0.006], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
epoch = 21, step = 1, loss = 0.096, reward = 2.633
epoch = 21, step = 2, loss = 0.095, reward = 2.633
epoch = 21, step = 3, loss = 0.094, reward = 2.633
epoch = 21, step = 4, loss = 0.092, reward = 2.633
epoch = 21, step = 5, loss = 0.091, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([4, 2, 4]), log_probs = [-3.234, -0.005, -0.005], reward = 2.0, delta = 2.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.040, -0.005, -0.005], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.004], reward = 3.0, delta = 3.000
epoch = 21, step = 6, loss = 0.090, reward = 2.633
epoch = 21, step = 7, loss = 0.089, reward = 2.633
epoch = 21, step = 8, loss = 0.088, reward = 2.633
epoch = 21, step = 9, loss = 0.088, reward = 2.633
epoch = 22, step = 0, loss = 0.032, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.077, -0.004, -0.004], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.005, -0.003], reward = 3.0, delta = 3.000
epoch = 22, step = 1, loss = 0.034, reward = 2.667
epoch = 22, step = 2, loss = 0.033, reward = 2.667
epoch = 22, step = 3, loss = 0.031, reward = 2.667
epoch = 22, step = 4, loss = 0.028, reward = 2.667
epoch = 22, step = 5, loss = 0.025, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.055, -0.004, -0.004], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
epoch = 22, step = 6, loss = 0.021, reward = 2.667
epoch = 22, step = 7, loss = 0.018, reward = 2.667
epoch = 22, step = 8, loss = 0.016, reward = 2.667
epoch = 22, step = 9, loss = 0.014, reward = 2.667
epoch = 23, step = 0, loss = 0.012, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.019, -0.004, -0.003], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.001, -0.004, -0.003], reward = 3.0, delta = 3.000
epoch = 23, step = 1, loss = 0.011, reward = 2.667
epoch = 23, step = 2, loss = 0.010, reward = 2.667
epoch = 23, step = 3, loss = 0.009, reward = 2.667
epoch = 23, step = 4, loss = 0.008, reward = 2.667
epoch = 23, step = 5, loss = 0.008, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.007, -0.004, -0.003], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
epoch = 23, step = 6, loss = 0.007, reward = 2.667
epoch = 23, step = 7, loss = 0.007, reward = 2.667
epoch = 23, step = 8, loss = 0.007, reward = 2.667
epoch = 23, step = 9, loss = 0.006, reward = 2.667
epoch = 24, step = 0, loss = 0.006, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.004, -0.004, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
epoch = 24, step = 1, loss = 0.006, reward = 2.667
epoch = 24, step = 2, loss = 0.006, reward = 2.667
epoch = 24, step = 3, loss = 0.006, reward = 2.667
epoch = 24, step = 4, loss = 0.006, reward = 2.667
epoch = 24, step = 5, loss = 0.005, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
epoch = 24, step = 6, loss = 0.005, reward = 2.667
epoch = 24, step = 7, loss = 0.005, reward = 2.667
epoch = 24, step = 8, loss = 0.005, reward = 2.667
epoch = 24, step = 9, loss = 0.005, reward = 2.667
epoch = 25, step = 0, loss = 0.005, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.002, -0.004, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.004, -0.002], reward = 3.0, delta = 3.000
epoch = 25, step = 1, loss = 0.005, reward = 2.667
epoch = 25, step = 2, loss = 0.005, reward = 2.667
epoch = 25, step = 3, loss = 0.005, reward = 2.667
epoch = 25, step = 4, loss = 0.005, reward = 2.667
epoch = 25, step = 5, loss = 0.005, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.002, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
epoch = 25, step = 6, loss = 0.005, reward = 2.667
epoch = 25, step = 7, loss = 0.005, reward = 2.667
epoch = 25, step = 8, loss = 0.005, reward = 2.667
epoch = 25, step = 9, loss = 0.004, reward = 2.667
epoch = 26, step = 0, loss = 0.004, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.004, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
epoch = 26, step = 1, loss = 0.004, reward = 2.667
epoch = 26, step = 2, loss = 0.004, reward = 2.667
epoch = 26, step = 3, loss = 0.004, reward = 2.667
epoch = 26, step = 4, loss = 0.004, reward = 2.667
epoch = 26, step = 5, loss = 0.004, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
epoch = 26, step = 6, loss = 0.004, reward = 2.667
epoch = 26, step = 7, loss = 0.004, reward = 2.667
epoch = 26, step = 8, loss = 0.004, reward = 2.667
epoch = 26, step = 9, loss = 0.004, reward = 2.667
epoch = 27, step = 0, loss = 0.226, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.003, -6.667], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.001], reward = 3.0, delta = 3.000
epoch = 27, step = 1, loss = 0.224, reward = 2.667
epoch = 27, step = 2, loss = 0.219, reward = 2.667
epoch = 27, step = 3, loss = 0.211, reward = 2.667
epoch = 27, step = 4, loss = 0.202, reward = 2.667
epoch = 27, step = 5, loss = 0.192, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.003, -5.620], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.004], reward = 3.0, delta = 3.000
epoch = 27, step = 6, loss = 0.180, reward = 2.667
epoch = 27, step = 7, loss = 0.167, reward = 2.667
epoch = 27, step = 8, loss = 0.154, reward = 2.667
epoch = 27, step = 9, loss = 0.141, reward = 2.667
epoch = 28, step = 0, loss = 0.013, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.003, -0.031], reward = 3.0, delta = 3.000
epoch = 28, step = 1, loss = 0.018, reward = 2.667
epoch = 28, step = 2, loss = 0.024, reward = 2.667
epoch = 28, step = 3, loss = 0.029, reward = 2.667
epoch = 28, step = 4, loss = 0.034, reward = 2.667
epoch = 28, step = 5, loss = 0.036, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.100], reward = 3.0, delta = 3.000
epoch = 28, step = 6, loss = 0.036, reward = 2.667
epoch = 28, step = 7, loss = 0.034, reward = 2.667
epoch = 28, step = 8, loss = 0.030, reward = 2.667
epoch = 28, step = 9, loss = 0.026, reward = 2.667
epoch = 29, step = 0, loss = 0.117, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.002, -2.903], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.056], reward = 3.0, delta = 3.000
epoch = 29, step = 1, loss = 0.119, reward = 2.667
epoch = 29, step = 2, loss = 0.121, reward = 2.667
epoch = 29, step = 3, loss = 0.122, reward = 2.667
epoch = 29, step = 4, loss = 0.122, reward = 2.667
epoch = 29, step = 5, loss = 0.121, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.003, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.002, -3.143], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.044], reward = 3.0, delta = 3.000
epoch = 29, step = 6, loss = 0.119, reward = 2.667
epoch = 29, step = 7, loss = 0.117, reward = 2.667
epoch = 29, step = 8, loss = 0.115, reward = 2.667
epoch = 29, step = 9, loss = 0.113, reward = 2.667
epoch = 30, step = 0, loss = 0.031, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.084], reward = 3.0, delta = 3.000
epoch = 30, step = 1, loss = 0.033, reward = 2.667
epoch = 30, step = 2, loss = 0.033, reward = 2.667
epoch = 30, step = 3, loss = 0.032, reward = 2.667
epoch = 30, step = 4, loss = 0.029, reward = 2.667
epoch = 30, step = 5, loss = 0.025, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.068], reward = 3.0, delta = 3.000
epoch = 30, step = 6, loss = 0.022, reward = 2.667
epoch = 30, step = 7, loss = 0.018, reward = 2.667
epoch = 30, step = 8, loss = 0.015, reward = 2.667
epoch = 30, step = 9, loss = 0.013, reward = 2.667
epoch = 31, step = 0, loss = 0.135, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.002, -3.754], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.024], reward = 3.0, delta = 3.000
epoch = 31, step = 1, loss = 0.139, reward = 2.667
epoch = 31, step = 2, loss = 0.141, reward = 2.667
epoch = 31, step = 3, loss = 0.141, reward = 2.667
epoch = 31, step = 4, loss = 0.139, reward = 2.667
epoch = 31, step = 5, loss = 0.136, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.002, -3.810], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.022], reward = 3.0, delta = 3.000
epoch = 31, step = 6, loss = 0.132, reward = 2.667
epoch = 31, step = 7, loss = 0.128, reward = 2.667
epoch = 31, step = 8, loss = 0.123, reward = 2.667
epoch = 31, step = 9, loss = 0.118, reward = 2.667
epoch = 32, step = 0, loss = 0.114, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.002, -2.765], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.065], reward = 3.0, delta = 3.000
epoch = 32, step = 1, loss = 0.112, reward = 2.667
epoch = 32, step = 2, loss = 0.111, reward = 2.667
epoch = 32, step = 3, loss = 0.112, reward = 2.667
epoch = 32, step = 4, loss = 0.114, reward = 2.667
epoch = 32, step = 5, loss = 0.116, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 4]), log_probs = [-0.000, -0.002, -1.821], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.177], reward = 3.0, delta = 3.000
epoch = 32, step = 6, loss = 0.118, reward = 2.667
epoch = 32, step = 7, loss = 0.118, reward = 2.667
epoch = 32, step = 8, loss = 0.117, reward = 2.667
epoch = 32, step = 9, loss = 0.115, reward = 2.667
epoch = 33, step = 0, loss = 0.053, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.153], reward = 3.0, delta = 3.000
epoch = 33, step = 1, loss = 0.044, reward = 2.667
epoch = 33, step = 2, loss = 0.035, reward = 2.667
epoch = 33, step = 3, loss = 0.026, reward = 2.667
epoch = 33, step = 4, loss = 0.020, reward = 2.667
epoch = 33, step = 5, loss = 0.015, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.038], reward = 3.0, delta = 3.000
epoch = 33, step = 6, loss = 0.011, reward = 2.667
epoch = 33, step = 7, loss = 0.009, reward = 2.667
epoch = 33, step = 8, loss = 0.007, reward = 2.667
epoch = 33, step = 9, loss = 0.006, reward = 2.667
epoch = 34, step = 0, loss = 0.005, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.001, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.001], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.009], reward = 3.0, delta = 3.000
epoch = 34, step = 1, loss = 0.005, reward = 2.667
epoch = 34, step = 2, loss = 0.004, reward = 2.667
epoch = 34, step = 3, loss = 0.004, reward = 2.667
epoch = 34, step = 4, loss = 0.004, reward = 2.667
epoch = 34, step = 5, loss = 0.003, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.003], reward = 3.0, delta = 3.000
epoch = 34, step = 6, loss = 0.003, reward = 2.667
epoch = 34, step = 7, loss = 0.003, reward = 2.667
epoch = 34, step = 8, loss = 0.003, reward = 2.667
epoch = 34, step = 9, loss = 0.003, reward = 2.667
epoch = 35, step = 0, loss = 0.003, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
epoch = 35, step = 1, loss = 0.003, reward = 2.667
epoch = 35, step = 2, loss = 0.003, reward = 2.667
epoch = 35, step = 3, loss = 0.003, reward = 2.667
epoch = 35, step = 4, loss = 0.003, reward = 2.667
epoch = 35, step = 5, loss = 0.003, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 35, step = 6, loss = 0.003, reward = 2.667
epoch = 35, step = 7, loss = 0.003, reward = 2.667
epoch = 35, step = 8, loss = 0.003, reward = 2.667
epoch = 35, step = 9, loss = 0.003, reward = 2.667
epoch = 36, step = 0, loss = 0.003, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 36, step = 1, loss = 0.003, reward = 2.667
epoch = 36, step = 2, loss = 0.003, reward = 2.667
epoch = 36, step = 3, loss = 0.003, reward = 2.667
epoch = 36, step = 4, loss = 0.003, reward = 2.667
epoch = 36, step = 5, loss = 0.003, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 36, step = 6, loss = 0.003, reward = 2.667
epoch = 36, step = 7, loss = 0.003, reward = 2.667
epoch = 36, step = 8, loss = 0.003, reward = 2.667
epoch = 36, step = 9, loss = 0.002, reward = 2.667
epoch = 37, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.002], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 37, step = 1, loss = 0.002, reward = 2.667
epoch = 37, step = 2, loss = 0.002, reward = 2.667
epoch = 37, step = 3, loss = 0.002, reward = 2.667
epoch = 37, step = 4, loss = 0.002, reward = 2.667
epoch = 37, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 37, step = 6, loss = 0.002, reward = 2.667
epoch = 37, step = 7, loss = 0.002, reward = 2.667
epoch = 37, step = 8, loss = 0.002, reward = 2.667
epoch = 37, step = 9, loss = 0.002, reward = 2.667
epoch = 38, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 38, step = 1, loss = 0.002, reward = 2.667
epoch = 38, step = 2, loss = 0.002, reward = 2.667
epoch = 38, step = 3, loss = 0.002, reward = 2.667
epoch = 38, step = 4, loss = 0.002, reward = 2.667
epoch = 38, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 38, step = 6, loss = 0.002, reward = 2.667
epoch = 38, step = 7, loss = 0.002, reward = 2.667
epoch = 38, step = 8, loss = 0.002, reward = 2.667
epoch = 38, step = 9, loss = 0.002, reward = 2.667
epoch = 39, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 39, step = 1, loss = 0.002, reward = 2.667
epoch = 39, step = 2, loss = 0.002, reward = 2.667
epoch = 39, step = 3, loss = 0.002, reward = 2.667
epoch = 39, step = 4, loss = 0.002, reward = 2.667
epoch = 39, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 39, step = 6, loss = 0.002, reward = 2.667
epoch = 39, step = 7, loss = 0.002, reward = 2.667
epoch = 39, step = 8, loss = 0.002, reward = 2.667
epoch = 39, step = 9, loss = 0.002, reward = 2.667
epoch = 40, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 40, step = 1, loss = 0.002, reward = 2.667
epoch = 40, step = 2, loss = 0.002, reward = 2.667
epoch = 40, step = 3, loss = 0.002, reward = 2.667
epoch = 40, step = 4, loss = 0.002, reward = 2.667
epoch = 40, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 40, step = 6, loss = 0.002, reward = 2.667
epoch = 40, step = 7, loss = 0.002, reward = 2.667
epoch = 40, step = 8, loss = 0.002, reward = 2.667
epoch = 40, step = 9, loss = 0.002, reward = 2.667
epoch = 41, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 41, step = 1, loss = 0.002, reward = 2.667
epoch = 41, step = 2, loss = 0.002, reward = 2.667
epoch = 41, step = 3, loss = 0.002, reward = 2.667
epoch = 41, step = 4, loss = 0.002, reward = 2.667
epoch = 41, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 41, step = 6, loss = 0.002, reward = 2.667
epoch = 41, step = 7, loss = 0.002, reward = 2.667
epoch = 41, step = 8, loss = 0.002, reward = 2.667
epoch = 41, step = 9, loss = 0.002, reward = 2.667
epoch = 42, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 42, step = 1, loss = 0.002, reward = 2.667
epoch = 42, step = 2, loss = 0.002, reward = 2.667
epoch = 42, step = 3, loss = 0.002, reward = 2.667
epoch = 42, step = 4, loss = 0.002, reward = 2.667
epoch = 42, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.001], reward = 3.0, delta = 3.000
epoch = 42, step = 6, loss = 0.002, reward = 2.667
epoch = 42, step = 7, loss = 0.002, reward = 2.667
epoch = 42, step = 8, loss = 0.002, reward = 2.667
epoch = 42, step = 9, loss = 0.002, reward = 2.667
epoch = 43, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
epoch = 43, step = 1, loss = 0.002, reward = 2.667
epoch = 43, step = 2, loss = 0.002, reward = 2.667
epoch = 43, step = 3, loss = 0.002, reward = 2.667
epoch = 43, step = 4, loss = 0.002, reward = 2.667
epoch = 43, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
epoch = 43, step = 6, loss = 0.002, reward = 2.667
epoch = 43, step = 7, loss = 0.002, reward = 2.667
epoch = 43, step = 8, loss = 0.002, reward = 2.667
epoch = 43, step = 9, loss = 0.002, reward = 2.667
epoch = 44, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
epoch = 44, step = 1, loss = 0.002, reward = 2.667
epoch = 44, step = 2, loss = 0.002, reward = 2.667
epoch = 44, step = 3, loss = 0.002, reward = 2.667
epoch = 44, step = 4, loss = 0.002, reward = 2.667
epoch = 44, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.002, -0.000], reward = 3.0, delta = 3.000
epoch = 44, step = 6, loss = 0.002, reward = 2.667
epoch = 44, step = 7, loss = 0.002, reward = 2.667
epoch = 44, step = 8, loss = 0.002, reward = 2.667
epoch = 44, step = 9, loss = 0.002, reward = 2.667
epoch = 45, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 45, step = 1, loss = 0.002, reward = 2.667
epoch = 45, step = 2, loss = 0.002, reward = 2.667
epoch = 45, step = 3, loss = 0.002, reward = 2.667
epoch = 45, step = 4, loss = 0.002, reward = 2.667
epoch = 45, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 45, step = 6, loss = 0.002, reward = 2.667
epoch = 45, step = 7, loss = 0.002, reward = 2.667
epoch = 45, step = 8, loss = 0.002, reward = 2.667
epoch = 45, step = 9, loss = 0.002, reward = 2.667
epoch = 46, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 46, step = 1, loss = 0.002, reward = 2.667
epoch = 46, step = 2, loss = 0.002, reward = 2.667
epoch = 46, step = 3, loss = 0.002, reward = 2.667
epoch = 46, step = 4, loss = 0.002, reward = 2.667
epoch = 46, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 46, step = 6, loss = 0.002, reward = 2.667
epoch = 46, step = 7, loss = 0.002, reward = 2.667
epoch = 46, step = 8, loss = 0.002, reward = 2.667
epoch = 46, step = 9, loss = 0.002, reward = 2.667
epoch = 47, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 47, step = 1, loss = 0.002, reward = 2.667
epoch = 47, step = 2, loss = 0.002, reward = 2.667
epoch = 47, step = 3, loss = 0.002, reward = 2.667
epoch = 47, step = 4, loss = 0.002, reward = 2.667
epoch = 47, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 47, step = 6, loss = 0.002, reward = 2.667
epoch = 47, step = 7, loss = 0.002, reward = 2.667
epoch = 47, step = 8, loss = 0.002, reward = 2.667
epoch = 47, step = 9, loss = 0.002, reward = 2.667
epoch = 48, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 48, step = 1, loss = 0.002, reward = 2.667
epoch = 48, step = 2, loss = 0.002, reward = 2.667
epoch = 48, step = 3, loss = 0.002, reward = 2.667
epoch = 48, step = 4, loss = 0.002, reward = 2.667
epoch = 48, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 48, step = 6, loss = 0.002, reward = 2.667
epoch = 48, step = 7, loss = 0.002, reward = 2.667
epoch = 48, step = 8, loss = 0.002, reward = 2.667
epoch = 48, step = 9, loss = 0.001, reward = 2.667
epoch = 49, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 49, step = 1, loss = 0.001, reward = 2.667
epoch = 49, step = 2, loss = 0.001, reward = 2.667
epoch = 49, step = 3, loss = 0.001, reward = 2.667
epoch = 49, step = 4, loss = 0.001, reward = 2.667
epoch = 49, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 49, step = 6, loss = 0.001, reward = 2.667
epoch = 49, step = 7, loss = 0.001, reward = 2.667
epoch = 49, step = 8, loss = 0.001, reward = 2.667
epoch = 49, step = 9, loss = 0.001, reward = 2.667
epoch = 50, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 50, step = 1, loss = 0.001, reward = 2.667
epoch = 50, step = 2, loss = 0.001, reward = 2.667
epoch = 50, step = 3, loss = 0.001, reward = 2.667
epoch = 50, step = 4, loss = 0.001, reward = 2.667
epoch = 50, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 50, step = 6, loss = 0.001, reward = 2.667
epoch = 50, step = 7, loss = 0.001, reward = 2.667
epoch = 50, step = 8, loss = 0.001, reward = 2.667
epoch = 50, step = 9, loss = 0.001, reward = 2.667
epoch = 51, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 51, step = 1, loss = 0.001, reward = 2.667
epoch = 51, step = 2, loss = 0.001, reward = 2.667
epoch = 51, step = 3, loss = 0.001, reward = 2.667
epoch = 51, step = 4, loss = 0.001, reward = 2.667
epoch = 51, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 51, step = 6, loss = 0.001, reward = 2.667
epoch = 51, step = 7, loss = 0.001, reward = 2.667
epoch = 51, step = 8, loss = 0.001, reward = 2.667
epoch = 51, step = 9, loss = 0.001, reward = 2.667
epoch = 52, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 52, step = 1, loss = 0.001, reward = 2.667
epoch = 52, step = 2, loss = 0.001, reward = 2.667
epoch = 52, step = 3, loss = 0.001, reward = 2.667
epoch = 52, step = 4, loss = 0.001, reward = 2.667
epoch = 52, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 52, step = 6, loss = 0.001, reward = 2.667
epoch = 52, step = 7, loss = 0.001, reward = 2.667
epoch = 52, step = 8, loss = 0.001, reward = 2.667
epoch = 52, step = 9, loss = 0.001, reward = 2.667
epoch = 53, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 53, step = 1, loss = 0.001, reward = 2.667
epoch = 53, step = 2, loss = 0.001, reward = 2.667
epoch = 53, step = 3, loss = 0.001, reward = 2.667
epoch = 53, step = 4, loss = 0.001, reward = 2.667
epoch = 53, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 53, step = 6, loss = 0.001, reward = 2.667
epoch = 53, step = 7, loss = 0.001, reward = 2.667
epoch = 53, step = 8, loss = 0.001, reward = 2.667
epoch = 53, step = 9, loss = 0.001, reward = 2.667
epoch = 54, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 54, step = 1, loss = 0.001, reward = 2.667
epoch = 54, step = 2, loss = 0.001, reward = 2.667
epoch = 54, step = 3, loss = 0.001, reward = 2.667
epoch = 54, step = 4, loss = 0.001, reward = 2.667
epoch = 54, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 54, step = 6, loss = 0.001, reward = 2.667
epoch = 54, step = 7, loss = 0.001, reward = 2.667
epoch = 54, step = 8, loss = 0.001, reward = 2.667
epoch = 54, step = 9, loss = 0.001, reward = 2.667
epoch = 55, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 55, step = 1, loss = 0.001, reward = 2.667
epoch = 55, step = 2, loss = 0.001, reward = 2.667
epoch = 55, step = 3, loss = 0.001, reward = 2.667
epoch = 55, step = 4, loss = 0.001, reward = 2.667
epoch = 55, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 55, step = 6, loss = 0.001, reward = 2.667
epoch = 55, step = 7, loss = 0.001, reward = 2.667
epoch = 55, step = 8, loss = 0.001, reward = 2.667
epoch = 55, step = 9, loss = 0.001, reward = 2.667
epoch = 56, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 56, step = 1, loss = 0.001, reward = 2.667
epoch = 56, step = 2, loss = 0.001, reward = 2.667
epoch = 56, step = 3, loss = 0.001, reward = 2.667
epoch = 56, step = 4, loss = 0.001, reward = 2.667
epoch = 56, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 56, step = 6, loss = 0.001, reward = 2.667
epoch = 56, step = 7, loss = 0.001, reward = 2.667
epoch = 56, step = 8, loss = 0.001, reward = 2.667
epoch = 56, step = 9, loss = 0.001, reward = 2.667
epoch = 57, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 57, step = 1, loss = 0.001, reward = 2.667
epoch = 57, step = 2, loss = 0.001, reward = 2.667
epoch = 57, step = 3, loss = 0.001, reward = 2.667
epoch = 57, step = 4, loss = 0.001, reward = 2.667
epoch = 57, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 57, step = 6, loss = 0.001, reward = 2.667
epoch = 57, step = 7, loss = 0.001, reward = 2.667
epoch = 57, step = 8, loss = 0.001, reward = 2.667
epoch = 57, step = 9, loss = 0.001, reward = 2.667
epoch = 58, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 58, step = 1, loss = 0.001, reward = 2.667
epoch = 58, step = 2, loss = 0.001, reward = 2.667
epoch = 58, step = 3, loss = 0.001, reward = 2.667
epoch = 58, step = 4, loss = 0.001, reward = 2.667
epoch = 58, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 58, step = 6, loss = 0.001, reward = 2.667
epoch = 58, step = 7, loss = 0.001, reward = 2.667
epoch = 58, step = 8, loss = 0.001, reward = 2.667
epoch = 58, step = 9, loss = 0.001, reward = 2.667
epoch = 59, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 59, step = 1, loss = 0.001, reward = 2.667
epoch = 59, step = 2, loss = 0.001, reward = 2.667
epoch = 59, step = 3, loss = 0.001, reward = 2.667
epoch = 59, step = 4, loss = 0.001, reward = 2.667
epoch = 59, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 59, step = 6, loss = 0.001, reward = 2.667
epoch = 59, step = 7, loss = 0.001, reward = 2.667
epoch = 59, step = 8, loss = 0.001, reward = 2.667
epoch = 59, step = 9, loss = 0.001, reward = 2.667
epoch = 60, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 60, step = 1, loss = 0.001, reward = 2.667
epoch = 60, step = 2, loss = 0.001, reward = 2.667
epoch = 60, step = 3, loss = 0.001, reward = 2.667
epoch = 60, step = 4, loss = 0.001, reward = 2.667
epoch = 60, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 60, step = 6, loss = 0.001, reward = 2.667
epoch = 60, step = 7, loss = 0.001, reward = 2.667
epoch = 60, step = 8, loss = 0.001, reward = 2.667
epoch = 60, step = 9, loss = 0.001, reward = 2.667
epoch = 61, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 61, step = 1, loss = 0.001, reward = 2.667
epoch = 61, step = 2, loss = 0.001, reward = 2.667
epoch = 61, step = 3, loss = 0.001, reward = 2.667
epoch = 61, step = 4, loss = 0.001, reward = 2.667
epoch = 61, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 61, step = 6, loss = 0.001, reward = 2.667
epoch = 61, step = 7, loss = 0.001, reward = 2.667
epoch = 61, step = 8, loss = 0.001, reward = 2.667
epoch = 61, step = 9, loss = 0.001, reward = 2.667
epoch = 62, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 62, step = 1, loss = 0.001, reward = 2.667
epoch = 62, step = 2, loss = 0.001, reward = 2.667
epoch = 62, step = 3, loss = 0.001, reward = 2.667
epoch = 62, step = 4, loss = 0.001, reward = 2.667
epoch = 62, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 62, step = 6, loss = 0.001, reward = 2.667
epoch = 62, step = 7, loss = 0.001, reward = 2.667
epoch = 62, step = 8, loss = 0.001, reward = 2.667
epoch = 62, step = 9, loss = 0.001, reward = 2.667
epoch = 63, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 63, step = 1, loss = 0.001, reward = 2.667
epoch = 63, step = 2, loss = 0.001, reward = 2.667
epoch = 63, step = 3, loss = 0.001, reward = 2.667
epoch = 63, step = 4, loss = 0.001, reward = 2.667
epoch = 63, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 63, step = 6, loss = 0.001, reward = 2.667
epoch = 63, step = 7, loss = 0.001, reward = 2.667
epoch = 63, step = 8, loss = 0.001, reward = 2.667
epoch = 63, step = 9, loss = 0.001, reward = 2.667
epoch = 64, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 64, step = 1, loss = 0.001, reward = 2.667
epoch = 64, step = 2, loss = 0.001, reward = 2.667
epoch = 64, step = 3, loss = 0.001, reward = 2.667
epoch = 64, step = 4, loss = 0.001, reward = 2.667
epoch = 64, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 64, step = 6, loss = 0.001, reward = 2.667
epoch = 64, step = 7, loss = 0.001, reward = 2.667
epoch = 64, step = 8, loss = 0.001, reward = 2.667
epoch = 64, step = 9, loss = 0.001, reward = 2.667
epoch = 65, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.001], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 65, step = 1, loss = 0.001, reward = 2.667
epoch = 65, step = 2, loss = 0.001, reward = 2.667
epoch = 65, step = 3, loss = 0.001, reward = 2.667
epoch = 65, step = 4, loss = 0.001, reward = 2.667
epoch = 65, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 65, step = 6, loss = 0.001, reward = 2.667
epoch = 65, step = 7, loss = 0.001, reward = 2.667
epoch = 65, step = 8, loss = 0.001, reward = 2.667
epoch = 65, step = 9, loss = 0.001, reward = 2.667
epoch = 66, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 66, step = 1, loss = 0.001, reward = 2.667
epoch = 66, step = 2, loss = 0.001, reward = 2.667
epoch = 66, step = 3, loss = 0.001, reward = 2.667
epoch = 66, step = 4, loss = 0.001, reward = 2.667
epoch = 66, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 66, step = 6, loss = 0.001, reward = 2.667
epoch = 66, step = 7, loss = 0.001, reward = 2.667
epoch = 66, step = 8, loss = 0.001, reward = 2.667
epoch = 66, step = 9, loss = 0.001, reward = 2.667
epoch = 67, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 67, step = 1, loss = 0.001, reward = 2.667
epoch = 67, step = 2, loss = 0.001, reward = 2.667
epoch = 67, step = 3, loss = 0.001, reward = 2.667
epoch = 67, step = 4, loss = 0.001, reward = 2.667
epoch = 67, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 67, step = 6, loss = 0.001, reward = 2.667
epoch = 67, step = 7, loss = 0.001, reward = 2.667
epoch = 67, step = 8, loss = 0.001, reward = 2.667
epoch = 67, step = 9, loss = 0.001, reward = 2.667
epoch = 68, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 68, step = 1, loss = 0.001, reward = 2.667
epoch = 68, step = 2, loss = 0.001, reward = 2.667
epoch = 68, step = 3, loss = 0.001, reward = 2.667
epoch = 68, step = 4, loss = 0.001, reward = 2.667
epoch = 68, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 68, step = 6, loss = 0.001, reward = 2.667
epoch = 68, step = 7, loss = 0.001, reward = 2.667
epoch = 68, step = 8, loss = 0.001, reward = 2.667
epoch = 68, step = 9, loss = 0.001, reward = 2.667
epoch = 69, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 69, step = 1, loss = 0.001, reward = 2.667
epoch = 69, step = 2, loss = 0.001, reward = 2.667
epoch = 69, step = 3, loss = 0.001, reward = 2.667
epoch = 69, step = 4, loss = 0.001, reward = 2.667
epoch = 69, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 69, step = 6, loss = 0.001, reward = 2.667
epoch = 69, step = 7, loss = 0.001, reward = 2.667
epoch = 69, step = 8, loss = 0.001, reward = 2.667
epoch = 69, step = 9, loss = 0.001, reward = 2.667
epoch = 70, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 70, step = 1, loss = 0.001, reward = 2.667
epoch = 70, step = 2, loss = 0.001, reward = 2.667
epoch = 70, step = 3, loss = 0.001, reward = 2.667
epoch = 70, step = 4, loss = 0.001, reward = 2.667
epoch = 70, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 70, step = 6, loss = 0.001, reward = 2.667
epoch = 70, step = 7, loss = 0.001, reward = 2.667
epoch = 70, step = 8, loss = 0.001, reward = 2.667
epoch = 70, step = 9, loss = 0.001, reward = 2.667
epoch = 71, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 71, step = 1, loss = 0.001, reward = 2.667
epoch = 71, step = 2, loss = 0.001, reward = 2.667
epoch = 71, step = 3, loss = 0.001, reward = 2.667
epoch = 71, step = 4, loss = 0.001, reward = 2.667
epoch = 71, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 71, step = 6, loss = 0.001, reward = 2.667
epoch = 71, step = 7, loss = 0.001, reward = 2.667
epoch = 71, step = 8, loss = 0.001, reward = 2.667
epoch = 71, step = 9, loss = 0.001, reward = 2.667
epoch = 72, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 72, step = 1, loss = 0.001, reward = 2.667
epoch = 72, step = 2, loss = 0.001, reward = 2.667
epoch = 72, step = 3, loss = 0.001, reward = 2.667
epoch = 72, step = 4, loss = 0.001, reward = 2.667
epoch = 72, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 72, step = 6, loss = 0.001, reward = 2.667
epoch = 72, step = 7, loss = 0.001, reward = 2.667
epoch = 72, step = 8, loss = 0.001, reward = 2.667
epoch = 72, step = 9, loss = 0.001, reward = 2.667
epoch = 73, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 73, step = 1, loss = 0.001, reward = 2.667
epoch = 73, step = 2, loss = 0.001, reward = 2.667
epoch = 73, step = 3, loss = 0.001, reward = 2.667
epoch = 73, step = 4, loss = 0.001, reward = 2.667
epoch = 73, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 73, step = 6, loss = 0.001, reward = 2.667
epoch = 73, step = 7, loss = 0.001, reward = 2.667
epoch = 73, step = 8, loss = 0.001, reward = 2.667
epoch = 73, step = 9, loss = 0.001, reward = 2.667
epoch = 74, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 74, step = 1, loss = 0.001, reward = 2.667
epoch = 74, step = 2, loss = 0.001, reward = 2.667
epoch = 74, step = 3, loss = 0.001, reward = 2.667
epoch = 74, step = 4, loss = 0.001, reward = 2.667
epoch = 74, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 74, step = 6, loss = 0.001, reward = 2.667
epoch = 74, step = 7, loss = 0.001, reward = 2.667
epoch = 74, step = 8, loss = 0.001, reward = 2.667
epoch = 74, step = 9, loss = 0.001, reward = 2.667
epoch = 75, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 75, step = 1, loss = 0.001, reward = 2.667
epoch = 75, step = 2, loss = 0.001, reward = 2.667
epoch = 75, step = 3, loss = 0.001, reward = 2.667
epoch = 75, step = 4, loss = 0.001, reward = 2.667
epoch = 75, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 75, step = 6, loss = 0.001, reward = 2.667
epoch = 75, step = 7, loss = 0.001, reward = 2.667
epoch = 75, step = 8, loss = 0.001, reward = 2.667
epoch = 75, step = 9, loss = 0.001, reward = 2.667
epoch = 76, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 76, step = 1, loss = 0.001, reward = 2.667
epoch = 76, step = 2, loss = 0.001, reward = 2.667
epoch = 76, step = 3, loss = 0.001, reward = 2.667
epoch = 76, step = 4, loss = 0.001, reward = 2.667
epoch = 76, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 76, step = 6, loss = 0.001, reward = 2.667
epoch = 76, step = 7, loss = 0.001, reward = 2.667
epoch = 76, step = 8, loss = 0.001, reward = 2.667
epoch = 76, step = 9, loss = 0.001, reward = 2.667
epoch = 77, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 77, step = 1, loss = 0.001, reward = 2.667
epoch = 77, step = 2, loss = 0.001, reward = 2.667
epoch = 77, step = 3, loss = 0.001, reward = 2.667
epoch = 77, step = 4, loss = 0.001, reward = 2.667
epoch = 77, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 77, step = 6, loss = 0.001, reward = 2.667
epoch = 77, step = 7, loss = 0.001, reward = 2.667
epoch = 77, step = 8, loss = 0.001, reward = 2.667
epoch = 77, step = 9, loss = 0.001, reward = 2.667
epoch = 78, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 78, step = 1, loss = 0.001, reward = 2.667
epoch = 78, step = 2, loss = 0.001, reward = 2.667
epoch = 78, step = 3, loss = 0.001, reward = 2.667
epoch = 78, step = 4, loss = 0.001, reward = 2.667
epoch = 78, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 78, step = 6, loss = 0.001, reward = 2.667
epoch = 78, step = 7, loss = 0.001, reward = 2.667
epoch = 78, step = 8, loss = 0.001, reward = 2.667
epoch = 78, step = 9, loss = 0.001, reward = 2.667
epoch = 79, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 79, step = 1, loss = 0.001, reward = 2.667
epoch = 79, step = 2, loss = 0.001, reward = 2.667
epoch = 79, step = 3, loss = 0.001, reward = 2.667
epoch = 79, step = 4, loss = 0.001, reward = 2.667
epoch = 79, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.001, -0.000], reward = 3.0, delta = 3.000
epoch = 79, step = 6, loss = 0.001, reward = 2.667
epoch = 79, step = 7, loss = 0.001, reward = 2.667
epoch = 79, step = 8, loss = 0.001, reward = 2.667
epoch = 79, step = 9, loss = 0.001, reward = 2.667
epoch = 80, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 80, step = 1, loss = 0.001, reward = 2.667
epoch = 80, step = 2, loss = 0.001, reward = 2.667
epoch = 80, step = 3, loss = 0.001, reward = 2.667
epoch = 80, step = 4, loss = 0.001, reward = 2.667
epoch = 80, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 80, step = 6, loss = 0.001, reward = 2.667
epoch = 80, step = 7, loss = 0.001, reward = 2.667
epoch = 80, step = 8, loss = 0.001, reward = 2.667
epoch = 80, step = 9, loss = 0.001, reward = 2.667
epoch = 81, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 81, step = 1, loss = 0.001, reward = 2.667
epoch = 81, step = 2, loss = 0.001, reward = 2.667
epoch = 81, step = 3, loss = 0.001, reward = 2.667
epoch = 81, step = 4, loss = 0.001, reward = 2.667
epoch = 81, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 81, step = 6, loss = 0.001, reward = 2.667
epoch = 81, step = 7, loss = 0.001, reward = 2.667
epoch = 81, step = 8, loss = 0.001, reward = 2.667
epoch = 81, step = 9, loss = 0.001, reward = 2.667
epoch = 82, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 82, step = 1, loss = 0.001, reward = 2.667
epoch = 82, step = 2, loss = 0.001, reward = 2.667
epoch = 82, step = 3, loss = 0.001, reward = 2.667
epoch = 82, step = 4, loss = 0.001, reward = 2.667
epoch = 82, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 82, step = 6, loss = 0.001, reward = 2.667
epoch = 82, step = 7, loss = 0.001, reward = 2.667
epoch = 82, step = 8, loss = 0.001, reward = 2.667
epoch = 82, step = 9, loss = 0.001, reward = 2.667
epoch = 83, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 83, step = 1, loss = 0.001, reward = 2.667
epoch = 83, step = 2, loss = 0.001, reward = 2.667
epoch = 83, step = 3, loss = 0.001, reward = 2.667
epoch = 83, step = 4, loss = 0.001, reward = 2.667
epoch = 83, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 83, step = 6, loss = 0.001, reward = 2.667
epoch = 83, step = 7, loss = 0.001, reward = 2.667
epoch = 83, step = 8, loss = 0.001, reward = 2.667
epoch = 83, step = 9, loss = 0.001, reward = 2.667
epoch = 84, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 84, step = 1, loss = 0.001, reward = 2.667
epoch = 84, step = 2, loss = 0.001, reward = 2.667
epoch = 84, step = 3, loss = 0.001, reward = 2.667
epoch = 84, step = 4, loss = 0.001, reward = 2.667
epoch = 84, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 84, step = 6, loss = 0.001, reward = 2.667
epoch = 84, step = 7, loss = 0.001, reward = 2.667
epoch = 84, step = 8, loss = 0.001, reward = 2.667
epoch = 84, step = 9, loss = 0.001, reward = 2.667
epoch = 85, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 85, step = 1, loss = 0.001, reward = 2.667
epoch = 85, step = 2, loss = 0.001, reward = 2.667
epoch = 85, step = 3, loss = 0.001, reward = 2.667
epoch = 85, step = 4, loss = 0.001, reward = 2.667
epoch = 85, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 85, step = 6, loss = 0.001, reward = 2.667
epoch = 85, step = 7, loss = 0.001, reward = 2.667
epoch = 85, step = 8, loss = 0.001, reward = 2.667
epoch = 85, step = 9, loss = 0.001, reward = 2.667
epoch = 86, step = 0, loss = 0.109, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-9.774, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 86, step = 1, loss = 0.108, reward = 2.633
epoch = 86, step = 2, loss = 0.106, reward = 2.633
epoch = 86, step = 3, loss = 0.104, reward = 2.633
epoch = 86, step = 4, loss = 0.101, reward = 2.633
epoch = 86, step = 5, loss = 0.097, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-8.681, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 86, step = 6, loss = 0.093, reward = 2.633
epoch = 86, step = 7, loss = 0.088, reward = 2.633
epoch = 86, step = 8, loss = 0.084, reward = 2.633
epoch = 86, step = 9, loss = 0.079, reward = 2.633
epoch = 87, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 87, step = 1, loss = 0.001, reward = 2.667
epoch = 87, step = 2, loss = 0.001, reward = 2.667
epoch = 87, step = 3, loss = 0.002, reward = 2.667
epoch = 87, step = 4, loss = 0.002, reward = 2.667
epoch = 87, step = 5, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.008, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 87, step = 6, loss = 0.003, reward = 2.667
epoch = 87, step = 7, loss = 0.003, reward = 2.667
epoch = 87, step = 8, loss = 0.004, reward = 2.667
epoch = 87, step = 9, loss = 0.004, reward = 2.667
epoch = 88, step = 0, loss = 0.049, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.017, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-4.066, -0.000, -0.000], reward = 1.0, delta = 1.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 88, step = 1, loss = 0.048, reward = 2.633
epoch = 88, step = 2, loss = 0.047, reward = 2.633
epoch = 88, step = 3, loss = 0.046, reward = 2.633
epoch = 88, step = 4, loss = 0.045, reward = 2.633
epoch = 88, step = 5, loss = 0.045, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.040, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-3.241, -0.000, -0.000], reward = 1.0, delta = 1.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 88, step = 6, loss = 0.044, reward = 2.633
epoch = 88, step = 7, loss = 0.044, reward = 2.633
epoch = 88, step = 8, loss = 0.044, reward = 2.633
epoch = 88, step = 9, loss = 0.045, reward = 2.633
epoch = 89, step = 0, loss = 0.071, reward = 2.600
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.517, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.517, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.084, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 89, step = 1, loss = 0.071, reward = 2.600
epoch = 89, step = 2, loss = 0.070, reward = 2.600
epoch = 89, step = 3, loss = 0.070, reward = 2.600
epoch = 89, step = 4, loss = 0.071, reward = 2.600
epoch = 89, step = 5, loss = 0.071, reward = 2.600
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.000, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.000, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.146, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 89, step = 6, loss = 0.071, reward = 2.600
epoch = 89, step = 7, loss = 0.071, reward = 2.600
epoch = 89, step = 8, loss = 0.071, reward = 2.600
epoch = 89, step = 9, loss = 0.071, reward = 2.600
epoch = 90, step = 0, loss = 0.070, reward = 2.600
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.121, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.128, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.121, -0.000, -0.000], reward = 1.0, delta = 1.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 90, step = 1, loss = 0.070, reward = 2.600
epoch = 90, step = 2, loss = 0.070, reward = 2.600
epoch = 90, step = 3, loss = 0.071, reward = 2.600
epoch = 90, step = 4, loss = 0.071, reward = 2.600
epoch = 90, step = 5, loss = 0.071, reward = 2.600
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.366, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.099, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.366, -0.000, -0.000], reward = 1.0, delta = 1.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 90, step = 6, loss = 0.071, reward = 2.600
epoch = 90, step = 7, loss = 0.071, reward = 2.600
epoch = 90, step = 8, loss = 0.070, reward = 2.600
epoch = 90, step = 9, loss = 0.070, reward = 2.600
epoch = 91, step = 0, loss = 0.049, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.195, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.118, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 91, step = 1, loss = 0.048, reward = 2.633
epoch = 91, step = 2, loss = 0.047, reward = 2.633
epoch = 91, step = 3, loss = 0.046, reward = 2.633
epoch = 91, step = 4, loss = 0.045, reward = 2.633
epoch = 91, step = 5, loss = 0.044, reward = 2.633
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([1, 0, 1]), log_probs = [-2.796, -0.000, -0.000], reward = 1.0, delta = 1.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.063, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 91, step = 6, loss = 0.044, reward = 2.633
epoch = 91, step = 7, loss = 0.044, reward = 2.633
epoch = 91, step = 8, loss = 0.045, reward = 2.633
epoch = 91, step = 9, loss = 0.045, reward = 2.633
epoch = 92, step = 0, loss = 0.008, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.033, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 92, step = 1, loss = 0.007, reward = 2.667
epoch = 92, step = 2, loss = 0.006, reward = 2.667
epoch = 92, step = 3, loss = 0.006, reward = 2.667
epoch = 92, step = 4, loss = 0.005, reward = 2.667
epoch = 92, step = 5, loss = 0.004, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.016, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 92, step = 6, loss = 0.003, reward = 2.667
epoch = 92, step = 7, loss = 0.003, reward = 2.667
epoch = 92, step = 8, loss = 0.003, reward = 2.667
epoch = 92, step = 9, loss = 0.002, reward = 2.667
epoch = 93, step = 0, loss = 0.002, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.007, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 93, step = 1, loss = 0.002, reward = 2.667
epoch = 93, step = 2, loss = 0.002, reward = 2.667
epoch = 93, step = 3, loss = 0.001, reward = 2.667
epoch = 93, step = 4, loss = 0.001, reward = 2.667
epoch = 93, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.003, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 93, step = 6, loss = 0.001, reward = 2.667
epoch = 93, step = 7, loss = 0.001, reward = 2.667
epoch = 93, step = 8, loss = 0.001, reward = 2.667
epoch = 93, step = 9, loss = 0.001, reward = 2.667
epoch = 94, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.002, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 94, step = 1, loss = 0.001, reward = 2.667
epoch = 94, step = 2, loss = 0.001, reward = 2.667
epoch = 94, step = 3, loss = 0.001, reward = 2.667
epoch = 94, step = 4, loss = 0.001, reward = 2.667
epoch = 94, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 94, step = 6, loss = 0.001, reward = 2.667
epoch = 94, step = 7, loss = 0.001, reward = 2.667
epoch = 94, step = 8, loss = 0.001, reward = 2.667
epoch = 94, step = 9, loss = 0.001, reward = 2.667
epoch = 95, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 95, step = 1, loss = 0.001, reward = 2.667
epoch = 95, step = 2, loss = 0.001, reward = 2.667
epoch = 95, step = 3, loss = 0.001, reward = 2.667
epoch = 95, step = 4, loss = 0.001, reward = 2.667
epoch = 95, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 95, step = 6, loss = 0.001, reward = 2.667
epoch = 95, step = 7, loss = 0.001, reward = 2.667
epoch = 95, step = 8, loss = 0.001, reward = 2.667
epoch = 95, step = 9, loss = 0.001, reward = 2.667
epoch = 96, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 96, step = 1, loss = 0.001, reward = 2.667
epoch = 96, step = 2, loss = 0.001, reward = 2.667
epoch = 96, step = 3, loss = 0.001, reward = 2.667
epoch = 96, step = 4, loss = 0.001, reward = 2.667
epoch = 96, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 96, step = 6, loss = 0.001, reward = 2.667
epoch = 96, step = 7, loss = 0.001, reward = 2.667
epoch = 96, step = 8, loss = 0.001, reward = 2.667
epoch = 96, step = 9, loss = 0.001, reward = 2.667
epoch = 97, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 97, step = 1, loss = 0.001, reward = 2.667
epoch = 97, step = 2, loss = 0.001, reward = 2.667
epoch = 97, step = 3, loss = 0.001, reward = 2.667
epoch = 97, step = 4, loss = 0.001, reward = 2.667
epoch = 97, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 97, step = 6, loss = 0.001, reward = 2.667
epoch = 97, step = 7, loss = 0.001, reward = 2.667
epoch = 97, step = 8, loss = 0.001, reward = 2.667
epoch = 97, step = 9, loss = 0.001, reward = 2.667
epoch = 98, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 98, step = 1, loss = 0.001, reward = 2.667
epoch = 98, step = 2, loss = 0.001, reward = 2.667
epoch = 98, step = 3, loss = 0.001, reward = 2.667
epoch = 98, step = 4, loss = 0.001, reward = 2.667
epoch = 98, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 98, step = 6, loss = 0.001, reward = 2.667
epoch = 98, step = 7, loss = 0.001, reward = 2.667
epoch = 98, step = 8, loss = 0.001, reward = 2.667
epoch = 98, step = 9, loss = 0.001, reward = 2.667
epoch = 99, step = 0, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 99, step = 1, loss = 0.001, reward = 2.667
epoch = 99, step = 2, loss = 0.001, reward = 2.667
epoch = 99, step = 3, loss = 0.001, reward = 2.667
epoch = 99, step = 4, loss = 0.001, reward = 2.667
epoch = 99, step = 5, loss = 0.001, reward = 2.667
  prompt = tensor([1, 0, 2])
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 2, 4]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
  prompt = tensor([3, 2, 4])
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
    response = tensor([3, 0, 1]), log_probs = [-0.001, -0.000, -0.000], reward = 2.0, delta = 2.000
  prompt = tensor([1, 2, 3])
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
    response = tensor([2, 4, 1]), log_probs = [-0.000, -0.000, -0.000], reward = 3.0, delta = 3.000
epoch = 99, step = 6, loss = 0.001, reward = 2.667
epoch = 99, step = 7, loss = 0.001, reward = 2.667
epoch = 99, step = 8, loss = 0.001, reward = 2.667
epoch = 99, step = 9, loss = 0.001, reward = 2.667
