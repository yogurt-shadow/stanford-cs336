{
  "files": {
    "lecture_12.py": "from execute_util import text, link, image\nfrom lecture_util import x_link, blog_link\nfrom references import deepseek_r1, llama4, olmo2_32b, mmlu\n\ndef main():\n    text(\"**Evaluation**: given a **fixed model**, how \\\"**good**\\\" is it?\")\n\n    what_you_see()\n    how_to_think_about_evaluation()\n\n    perplexity()\n\n    knowledge_benchmarks()\n    instruction_following_benchmarks()\n    agent_benchmarks()\n    pure_reasoning_benchmarks()\n    safety_benchmarks()\n\n    realism()\n    validity()\n    what_are_we_evaluating()\n\n    text(\"Takeaways\")\n    text(\"- There is no one true evaluation; choose the evaluation depending on what you're trying to measure.\")\n    text(\"- Always look at the individual instances and the predictions.\")\n    text(\"- There are many aspects to consider: capabilities, safety, costs, realism.\")\n    text(\"- Clearly state the rules of the game (methods versus models/systems).\")\n\n\ndef what_you_see():\n    text(\"## Benchmark scores\")\n    image(\"images/deepseek-r1-benchmarks.png\", width=800), link(deepseek_r1)\n    image(\"images/llama4-benchmarks.png\", width=800), link(llama4)\n    image(\"https://www.datocms-assets.com/64837/1741887109-instruct-1.png\", width=800), link(olmo2_32b)\n\n    text(\"Recent language models are evaluated on similar, but not entirely identical, benchmarks (MMLU, MATH, etc.).\")\n    text(\"What are these benchmarks?\")\n    text(\"What do these numbers mean?\")\n\n    image(\"images/helm-capabilities-leaderboard.png\", width=1000)\n    link(title=\"[HELM capabilities]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard\")\n\n    text(\"Pay close attention to the costs!\")\n    image(\"images/artificial-analysis.png\", width=800), link(title=\"[Artificial Analysis]\", url=\"https://artificialanalysis.ai/\")\n\n    text(\"Maybe a model is good if people choose to use it (and pay for it)...\")\n    image(\"images/openrouter.png\", width=600), link(title=\"[OpenRouter]\", url=\"https://openrouter.ai/rankings\")\n\n    image(\"images/chatbot-arena-leaderboard.png\", width=800)\n    link(title=\"[Chatbot Arena]\", url=\"https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard\")\n\n    text(\"## Vibes\")\n    x_link(\"https://x.com/demishassabis/status/1919779362980692364\")\n    image(\"images/demis-gemini-2.5.png\", width=500)\n\n    text(\"A crisis...\")\n    image(\"images/karpathy-crisis.png\", width=600)\n\n\ndef how_to_think_about_evaluation():\n    text(\"You might think evaluation is a mechanical process (take existing model, throw prompts at it, average some numbers)...\")\n    text(\"Actually, evaluation is a profound and rich topic...\")\n    text(\"...and it determines the future of language models.\")\n\n    text(\"What's the point of evaluation?\")\n    text(\"There is no one true evaluation; it depends on what question you're trying to answer.\")\n    text(\"1. User or company wants to make a purchase decision (model A or model B) for their use case (e.g., customer service chatbots).\")\n    text(\"2. Researchers want to measure the raw capabilities of a model (e.g., intelligence).\")\n    text(\"3. We want to understand the benefits + harms of a model (for business and policy reasons).\")\n    text(\"4. Model developers want to get feedback to improve the model.\")\n    text(\"In each case, there is an abstract **goal** that needs to be translated into a concrete evaluation.\")\n\n    text(\"Framework\")\n    text(\"1. What are the **inputs**?\")\n    text(\"2. How do **call** the language model?\")\n    text(\"3. How do you evaluate the **outputs**?\")\n    text(\"4. How to **interpret** the results?\")\n\n    text(\"What are the inputs?\")\n    text(\"1. What use cases are **covered**?\")\n    text(\"2. Do we have representation of **difficult** inputs in the tail?\")\n    text(\"3. Are the inputs **adapted** to the model (e.g., multi-turn)?\")\n\n    text(\"How do you call the language model?\")\n    text(\"1. How do you prompt the language model?\")\n    text(\"2. Does the language model use chain-of-thought, tools, RAG, etc.?\")\n    text(\"3. Are we evaluating the language model or an agentic system (model developer wants former, user wants latter)?\")\n\n    text(\"How do you evaluate the outputs?\")\n    text(\"1. Are the reference outputs used for evaluation error-free?\")\n    text(\"2. What metrics do you use (e.g., pass@k)?\")\n    text(\"3. How do you factor in cost (e.g., inference + training)?\")\n    text(\"4. How do you factor in asymmetric errors (e.g., hallucinations in a medical setting)?\")\n    text(\"5. How do you handle open-ended generation (no ground truth)?\")\n\n    text(\"How do you inteprret the metrics?\")\n    text(\"1. How do you interpret a number (e.g., 91%) - is it ready for deployment?\")\n    text(\"2. How do we assess generalization in the face of train-test overlap?\")\n    text(\"3. Are we evaluating the final model or the method?\")\n\n    text(\"Summary: lots of questions to think through when doing evaluation\")\n\ndef perplexity():\n    text(\"Recall: that a language model is a probability distribution **p(x)** over sequences of tokens.\")\n    text(\"Perplexity (1/p(D))^(1/|D|) measures whether p assigns high probability to some dataset D.\")\n\n    text(\"In pre-training, you minimize perplexity on the training set.\")\n    text(\"The obvious thing is to measure perplexity on the test set.\")\n\n    text(\"Standard datasets: Penn Treebank (WSJ), WikiText-103 (Wikipedia), One Billion Word Benchmark (from machine translation WMT11 - EuroParl, UN, news)\")\n    text(\"Papers trained on a dataset (training split) and evaluated on the same dataset (test split)\")\n    text(\"Pure CNNs+LSTMs on the One Billion Word Benchmark (perplexity 51.3 -> 30.0) \"), link(\"https://arxiv.org/abs/1602.02410\")\n\n    text(\"GPT-2 trained on WebText (40GB text, websites linked from Reddit), zero-shot on standard datasets\")\n    text(\"This is out-of-distribution evaluation (but idea is that training covers a lot)\")\n    image(\"images/gpt2-perplexity.png\", width=800)\n    text(\"Works better on small datasets (transfer is helpful), but not larger datasets (1BW)\")\n\n    text(\"Since GPT-2 and GPT-3, language modeling papers have shifted more towards downstream task accuracy.\")\n    text(\"But reasons why perplexity is still useful:\")\n    text(\"- Smoother than downstream task accuracy (for fitting scaling laws)\")\n    text(\"- Is universal (why we use it for training) whereas task accuracy might miss some nuances\")\n    text(\"- Note: can measure conditional perplexity on downstream task too (used for scaling laws) \"), link(\"https://arxiv.org/abs/2412.04403\")\n\n    text(\"Warning (if you're running a leaderboard): evaluator needs to trust the language model\")\n    text(\"For task accuracy, can just take output generated from a blackbox model and compute the desired metrics\")\n    text(\"For perplexity, need LM to generate probabilities and trust that they sum to 1 (even worse with UNKs back in the day)\")\n\n    text(\"The perplexity maximalist view:\")\n    text(\"- Your true distribution is t, model is p\")\n    text(\"- Best possible perplexity is H(t) obtained iff p = t\")\n    text(\"- If have t, then solve all the tasks\")\n    text(\"- So by pushing down on perplexity, will eventually reach AGI\")\n    text(\"- Caveat: this might not be the most efficient way to get there (pushing down on parts of the distribution that don't matter)\")\n\n    text(\"Things that are spiritually perplexity:\")\n    text(\"Similar idea: cloze tasks like LAMBADA \"), link(\"https://arxiv.org/abs/1606.06031\")\n    image(\"images/lambada.png\", width=800)\n    text(\"HellaSwag \"), link(\"https://arxiv.org/pdf/1905.07830\")\n    image(\"images/hellaswag.png\", width=600)\n\n\ndef knowledge_benchmarks():\n    text(\"### Massive Multitask Language Understanding (MMLU)\")\n    link(mmlu)\n    text(\"- 57 subjects (e.g., math, US history, law, morality), multiple-choice\")\n    text(\"- \\\"collected by graduate and undergraduate students from freely available sources online\\\"\")\n    text(\"- Really about testing knowledge, not language understanding\")\n    text(\"- Evaluated on GPT-3 using few-shot prompting\")\n    image(\"images/mmlu.png\", width=800)\n    link(title=\"[HELM MMLU for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/mmlu/latest/\")\n\n    text(\"### MMLU-Pro\")\n    link(\"https://arxiv.org/abs/2406.01574\")\n    text(\"- Removed noisy/trivial questions from MMLU\")\n    text(\"- Expanded 4 choices to 10 choices\")\n    text(\"- Evaluated using chain of thought (gives model more of a chance)\")\n    text(\"- Accuracy of models drop by 16% to 33% (not as saturated)\")\n    image(\"images/mmlu-pro.png\", width=800)\n    link(title=\"[HELM MMLU-Pro for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/mmlu_pro\")\n\n    text(\"### Graduate-Level Google-Proof Q&A (GPQA)\")\n    link(\"https://arxiv.org/abs/2311.12022\")\n    text(\"- Questions written by 61 PhD contractors from Upwork\")\n    image(\"images/gpqa.png\", width=800)\n    text(\"- PhD experts achieve 65% accuracy\")\n    text(\"- Non-experts achieve 34% over 30 minutes with access to Google\")\n    text(\"- GPT-4 achieves 39%\")\n    link(title=\"[HELM GPQA for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/gpqa\")\n\n    text(\"### Humanity's Last Exam\")\n    link(\"https://arxiv.org/abs/2501.14249\")\n    text(\"- 2500 questions: multimodal, many subjects, multiple-choice + short-answer\")\n    image(\"images/hle-examples.png\", width=800)\n    text(\"- Awarded $500K prize pool + co-authorship to question creators\")\n    text(\"- Filtered by frontier LLMs, multiple stages of review\")\n    image(\"images/hle-pipeline.png\", width=800)\n    image(\"images/hle-results.png\", width=800)\n    link(title=\"[latest leaderboard]\", url=\"https://agi.safe.ai/\")\n\n\ndef instruction_following_benchmarks():\n    text(\"So far, we've been evaluating on fairly structured tasks.\")\n    text(\"Instruction following (as popularized by ChatGPT): just follow the instructions.\")\n    text(\"Challenge: how to evaluate an open-ended response?\")\n\n    text(\"### Chatbot Arena\")\n    link(\"https://arxiv.org/abs/2403.04132\")\n    text(\"How it works:\")\n    text(\"- Random person from the Internet types in prompt\")\n    text(\"- They get response from two random (anonymized) models\")\n    text(\"- They rate which one is better\")\n    text(\"- ELO scores are computed based on the pairwise comparisons\")\n    text(\"- Features: live (not static) inputs, can accomodate new models\")\n    image(\"images/chatbot-arena-leaderboard.png\", width=800)\n    link(title=\"[Chatbot Arena]\", url=\"https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard\")\n\n    text(\"### Instruction-Following Eval (IFEval)\")\n    link(\"https://arxiv.org/abs/2311.07911\")\n    image(\"images/ifeval-categories.png\", width=600)\n    text(\"- Add simple synthetic constraints to instructions\")\n    text(\"- Constraints can be automatically verified, but not the semantics of the response\")\n    text(\"- Fairly simple instructions, constraints are a bit artificial\")\n    link(title=\"[HELM IFEval for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/ifeval\")\n\n    text(\"### AlpacaEval\")\n    link(\"https://tatsu-lab.github.io/alpaca_eval/\")\n    text(\"- 805 instructions from various sources\")\n    text(\"- Metric: win rate against GPT-4 preview as judged by GPT-4 preview (potential bias)\")\n    image(\"images/alpacaeval-leaderboard.png\", width=600)\n\n    text(\"### WildBench\")\n    link(\"https://arxiv.org/pdf/2406.04770\")\n    text(\"- Sourced 1024 examples from 1M human-chatbot conversations\")\n    text(\"- Uses GPT-4 turbo as a judge with a checklist (like CoT for judging) + GPT-4 as a judge\")\n    text(\"- Well-correlated (0.95) with Chatbot Arena (seems to be the de facto sanity check for benchmarks)\")\n    image(\"images/wildbench.png\", width=800)\n    link(title=\"[HELM WildBench for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/wildbench\")\n\n\ndef agent_benchmarks():\n    text(\"Consider tasks that require tool use (e.g., running code) and iterating over a period of time\")\n    text(\"Agent = language model + agent scaffolding (logic for deciding how to use the LM)\")\n\n    text(\"### SWEBench\")\n    link(\"https://arxiv.org/abs/2310.06770\")\n    text(\"- 2294 tasks across 12 Python repositories\")\n    text(\"- Given codebase + issue description, submit a PR\")\n    text(\"- Evaluation metric: unit tests\")\n    image(\"images/swebench.png\", width=800)\n\n    text(\"### CyBench\")\n    link(\"https://arxiv.org/abs/2408.08926\")\n    text(\"- 40 Capture the Flag (CTF) tasks\")\n    text(\"- Use first-solve time as a measure of difficulty\")\n    image(\"images/cybench.png\", width=800)\n    image(\"images/cybench-agent.png\", width=800)\n    image(\"images/cybench-results.png\", width=800)\n\n    text(\"### MLEBench\")\n    link(\"https://arxiv.org/abs/2410.07095\")\n    text(\"- 75 Kaggle competitions (require training models, processing data, etc.)\")\n    image(\"images/mlebench.png\", width=800)\n    image(\"images/mlebench-results.png\", width=800)\n\n\ndef pure_reasoning_benchmarks():\n    text(\"All of the tasks so far require linguistic and world knowledge\")\n    text(\"Can we isolate reasoning from knowledge?\")\n    text(\"Arguably, reasoning captures a more pure form of intelligence (isn't just about memorizing facts)\")\n\n    link(title=\"ARC-AGI\", url=\"https://arcprize.org/arc-agi\")\n    text(\"Introduced in 2019 by Francois Chollet\")\n\n    text(\"ARC-AGI-1\")\n    image(\"https://arcprize.org/media/images/arc-task-grids.jpg\", width=800)\n    image(\"https://arcprize.org/media/images/oseriesleaderboard.png\", width=800)\n\n    text(\"ARC-AGI-2: harder\")\n    image(\"https://arcprize.org/media/images/blog/arc-agi-2-unsolved-1.png\", width=800)\n\n\ndef safety_benchmarks():\n    image(\"https://www.team-bhp.com/forum/attachments/road-safety/2173645d1625144681-will-crash-test-rating-change-if-higher-variant-chosen-images-30.jpeg\", width=500)\n    text(\"What does safety mean for AI?\")\n\n    link(title=\"[HELM safety: curated set of benchmarks]\", url=\"https://crfm.stanford.edu/helm/safety/latest/#/leaderboard\")\n\n    text(\"### HarmBench\")\n    link(\"https://arxiv.org/abs/2402.04249\")\n    text(\"- Based on 510 harmful behaviors that violate laws or norms\")\n    link(title=\"[HarmBench on HELM]\", url=\"https://crfm.stanford.edu/helm/safety/latest/#/leaderboard/harm_bench\")\n    link(title=\"[Example of safety failure]\", url=\"https://crfm.stanford.edu/helm/safety/latest/#/runs/harm_bench:model=anthropic_claude-3-7-sonnet-20250219?instancesPage=4\")\n\n    text(\"### AIR-Bench\")\n    link(\"https://arxiv.org/abs/2407.17436\")\n    text(\"- Based on regulatory frameworks and company policies\")\n    text(\"- Taxonomized into 314 risk categories, 5694 prompts\")\n    image(\"https://crfm.stanford.edu/helm/assets/air-overview-d2e6c49f.png\", width=800)\n    link(title=\"[HELM AIR-Bench]\", url=\"https://crfm.stanford.edu/helm/air-bench/latest/#/leaderboard\")\n\n    text(\"### Jailbreaking\")\n    text(\"- Language models are trained to refuse harmful instructions\")\n    text(\"- Greedy Coordinate Gradient (GCG) automatically optimizes prompts to bypass safety \"), link(\"https://arxiv.org/pdf/2307.15043\")\n    text(\"- Transfers from open-weight models (Llama) to closed models (GPT-4)\")\n    image(\"images/gcg-examples.png\", width=800)\n\n    text(\"### Pre-deployment testing\")\n    text(\"- US Safety Institute + UK AI Safety Institute working together\")\n    text(\"- Company gives safety institutes access to model before release (currently voluntary)\")\n    text(\"- Safety institutes run evaluations and produce a report to company\")\n    link(title=\"[report]\", url=\"https://www.nist.gov/system/files/documents/2024/12/18/US_UK_AI%20Safety%20Institute_%20December_Publication-OpenAIo1.pdf\")\n\n    text(\"### But what is safety?\")\n    text(\"- Many aspects of safety are strongly contextual (politics, law, social norms - which vary across countries)\")\n    text(\"- Naively, one might think safety is about refusal and is at odds with capability, but there's more...\")\n    text(\"- Hallucinations in a medical setting makes systems more capable and more safe\")\n\n    text(\"Two aspects of a model that reduce safety: capabilities + propensity\")\n    text(\"- A system could be capable of doing something, but refuse to do it\")\n    text(\"- For API models, propensity matters\")\n    text(\"- For open weight models, capability matters (since can easily fine-tune safety away)\")\n\n    text(\"**Dual-use**: capable cybersecurity agents (do well on CyBench) can be used to hack into a system or to do penetration testing\")\n    text(\"CyBench is used by the safety institute as a safety evaluation, but is it really a capability evaluation?\")\n\n\ndef realism():\n    text(\"Language models are used heavily in practice:\")\n    image(\"images/openai-100b-tokens.png\", width=600); link(title=\" [tweet]\", url=\"https://x.com/sama/status/1756089361609981993\")\n    image(\"images/cursor-1b-lines.png\", width=600); link(title=\" [tweet]\", url=\"https://x.com/amanrsanger/status/1916968123535880684\")\n\n    text(\"However, most existing benchmarks (e.g., MMLU) are far away from real-world use.\")\n    text(\"Live traffic from real people contain garbage, that's not always what we want either.\")\n\n    text(\"Two types of prompts:\")\n    text(\"1. Quizzing: User knows the answer and trying to test the system (think standardized exams).\")\n    text(\"2. Asking: User doesn't know the answer is trying to use the system to get it.\")\n    text(\"Asking is more realistic and produces value for the user.\")\n\n    text(\"### Clio (Anthropic)\")\n    link(\"https://arxiv.org/abs/2412.13678\")\n    text(\"- Use language models to analyze real user data\")\n    text(\"- Share general patterns of what people are asking\")\n    image(\"images/clio-table4.png\", width=700)\n\n    text(\"### MedHELM\")\n    link(\"https://arxiv.org/abs/2412.13678\")\n    text(\"- Previous medical benchmarks were based on standardized exams\")\n    text(\"- 121 clinical tasks sourced from 29 clinicians, mixture of private and public datasets\")\n    image(\"https://crfm.stanford.edu/helm/assets/medhelm-overview-3ddfcd65.png\", width=700)\n    link(title=\"[MedHELM]\", url=\"https://crfm.stanford.edu/helm/medhelm/latest/#/leaderboard\")\n\n    text(\"Unfortunately, realism and privacy are sometimes at odds with each other.\")\n\n\ndef validity():\n    text(\"How do we know our evaluations are valid?\")\n\n    text(\"### Train-test overlap\")\n    text(\"- Machine learning 101: don't train on your test set\")\n    text(\"- Pre-foundation models (ImageNet, SQuAD): well-defined train-test splits\")\n    text(\"- Nowadays: train on the Internet and don't tell people about your data\")\n\n    text(\"Route 1: try to infer train-test overlap from model\")\n    text(\"- Exploit exchangeability of data points\"), link(\"https://arxiv.org/pdf/2310.17623\")\n    image(\"images/contamination-exchangeability.png\", width=600)\n\n    text(\"Route 2: encourage reporting norms (e.g., people report confidence intervals)\")\n    text(\"- Model providers should report train-test overlap \"), link(\"https://arxiv.org/abs/2410.08385\")\n\n    text(\"### Dataset quality\")\n    text(\"- Fixed up SWE-Bench to produce SWE-Bench Verified \"), blog_link(\"https://openai.com/index/introducing-swe-bench-verified/\")\n    text(\"- Create Platinum versions of benchmarks\"), link(\"https://arxiv.org/abs/2502.03461\")\n    image(\"https://pbs.twimg.com/media/GjICXQlWkAAYnDS?format=jpg&name=4096x4096\", width=700)\n    image(\"https://pbs.twimg.com/media/GjICcGQXYAAM4o1?format=jpg&name=4096x4096\", width=800)\n\n\ndef what_are_we_evaluating():\n    text(\"What are we even evaluating?\")\n    text(\"In other words, what are the rules of a game?\")\n\n    text(\"Pre-foundation models, we evaluated **methods** (standardized train-test splits).\")\n    text(\"Today, we're evaluating **models/systems** (anything goes).\")\n\n    text(\"There are some exceptions...\")\n    text(\"nanogpt speedrun: fixed data, compute time to get to a particular validation loss\")\n    image(\"images/karpathy-nanogpt-speedrun.png\", width=600), x_link(\"https://x.com/karpathy/status/1846790537262571739\")\n\n    text(\"DataComp-LM: given a raw dataset, get the best accuracy using standard training pipeline \"), link(\"https://arxiv.org/abs/2406.11794\")\n\n    text(\"Evaluating methods encourage algorithmic innovation from researchers.\")\n    text(\"Evaluating models/systems is useful for downstream users.\")\n\n    text(\"Either way, we need to define the rules of the game!\")\n\n\nif __name__ == \"__main__\":\n    main()\n"
  },
  "steps": [
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 5,
          "function_name": "main",
          "code": "def main():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 6,
          "function_name": "main",
          "code": "text(\"**Evaluation**: given a **fixed model**, how \\\"**good**\\\" is it?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "**Evaluation**: given a **fixed model**, how \"**good**\" is it?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 30,
          "function_name": "what_you_see",
          "code": "def what_you_see():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 31,
          "function_name": "what_you_see",
          "code": "text(\"## Benchmark scores\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "## Benchmark scores",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 32,
          "function_name": "what_you_see",
          "code": "image(\"images/deepseek-r1-benchmarks.png\", width=800), link(deepseek_r1)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/deepseek-r1-benchmarks.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
            "authors": [
              "DeepSeek-AI",
              "Daya Guo",
              "Dejian Yang",
              "Haowei Zhang",
              "Junxiao Song",
              "Ruoyu Zhang",
              "Runxin Xu",
              "Qihao Zhu",
              "Shirong Ma",
              "Peiyi Wang",
              "Xiao Bi",
              "Xiaokang Zhang",
              "Xingkai Yu",
              "Yu Wu",
              "Z. F. Wu",
              "Zhibin Gou",
              "Zhihong Shao",
              "Zhuoshu Li",
              "Ziyi Gao",
              "Aixin Liu",
              "Bing Xue",
              "Bingxuan Wang",
              "Bochao Wu",
              "Bei Feng",
              "Chengda Lu",
              "Chenggang Zhao",
              "Chengqi Deng",
              "Chenyu Zhang",
              "Chong Ruan",
              "Damai Dai",
              "Deli Chen",
              "Dongjie Ji",
              "Erhang Li",
              "Fangyun Lin",
              "Fucong Dai",
              "Fuli Luo",
              "Guangbo Hao",
              "Guanting Chen",
              "Guowei Li",
              "H. Zhang",
              "Han Bao",
              "Hanwei Xu",
              "Haocheng Wang",
              "Honghui Ding",
              "Huajian Xin",
              "Huazuo Gao",
              "Hui Qu",
              "Hui Li",
              "Jianzhong Guo",
              "Jiashi Li",
              "Jiawei Wang",
              "Jingchang Chen",
              "Jingyang Yuan",
              "Junjie Qiu",
              "Junlong Li",
              "J. L. Cai",
              "Jiaqi Ni",
              "Jian Liang",
              "Jin Chen",
              "Kai Dong",
              "Kai Hu",
              "Kaige Gao",
              "Kang Guan",
              "Kexin Huang",
              "Kuai Yu",
              "Lean Wang",
              "Lecong Zhang",
              "Liang Zhao",
              "Litong Wang",
              "Liyue Zhang",
              "Lei Xu",
              "Leyi Xia",
              "Mingchuan Zhang",
              "Minghua Zhang",
              "Minghui Tang",
              "Meng Li",
              "Miaojun Wang",
              "Mingming Li",
              "Ning Tian",
              "Panpan Huang",
              "Peng Zhang",
              "Qiancheng Wang",
              "Qinyu Chen",
              "Qiushi Du",
              "Ruiqi Ge",
              "Ruisong Zhang",
              "Ruizhe Pan",
              "Runji Wang",
              "R. J. Chen",
              "R. L. Jin",
              "Ruyi Chen",
              "Shanghao Lu",
              "Shangyan Zhou",
              "Shanhuang Chen",
              "Shengfeng Ye",
              "Shiyu Wang",
              "Shuiping Yu",
              "Shunfeng Zhou",
              "Shuting Pan",
              "S. S. Li",
              "Shuang Zhou",
              "Shaoqing Wu",
              "Shengfeng Ye",
              "Tao Yun",
              "Tian Pei",
              "Tianyu Sun",
              "T. Wang",
              "Wangding Zeng",
              "Wanjia Zhao",
              "Wen Liu",
              "Wenfeng Liang",
              "Wenjun Gao",
              "Wenqin Yu",
              "Wentao Zhang",
              "W. L. Xiao",
              "Wei An",
              "Xiaodong Liu",
              "Xiaohan Wang",
              "Xiaokang Chen",
              "Xiaotao Nie",
              "Xin Cheng",
              "Xin Liu",
              "Xin Xie",
              "Xingchao Liu",
              "Xinyu Yang",
              "Xinyuan Li",
              "Xuecheng Su",
              "Xuheng Lin",
              "X. Q. Li",
              "Xiangyue Jin",
              "Xiaojin Shen",
              "Xiaosha Chen",
              "Xiaowen Sun",
              "Xiaoxiang Wang",
              "Xinnan Song",
              "Xinyi Zhou",
              "Xianzu Wang",
              "Xinxia Shan",
              "Y. K. Li",
              "Y. Q. Wang",
              "Y. X. Wei",
              "Yang Zhang",
              "Yanhong Xu",
              "Yao Li",
              "Yao Zhao",
              "Yaofeng Sun",
              "Yaohui Wang",
              "Yi Yu",
              "Yichao Zhang",
              "Yifan Shi",
              "Yiliang Xiong",
              "Ying He",
              "Yishi Piao",
              "Yisong Wang",
              "Yixuan Tan",
              "Yiyang Ma",
              "Yiyuan Liu",
              "Yongqiang Guo",
              "Yuan Ou",
              "Yuduan Wang",
              "Yue Gong",
              "Yuheng Zou",
              "Yujia He",
              "Yunfan Xiong",
              "Yuxiang Luo",
              "Yuxiang You",
              "Yuxuan Liu",
              "Yuyang Zhou",
              "Y. X. Zhu",
              "Yanhong Xu",
              "Yanping Huang",
              "Yaohui Li",
              "Yi Zheng",
              "Yuchen Zhu",
              "Yunxian Ma",
              "Ying Tang",
              "Yukun Zha",
              "Yuting Yan",
              "Z. Z. Ren",
              "Zehui Ren",
              "Zhangli Sha",
              "Zhe Fu",
              "Zhean Xu",
              "Zhenda Xie",
              "Zhengyan Zhang",
              "Zhewen Hao",
              "Zhicheng Ma",
              "Zhigang Yan",
              "Zhiyu Wu",
              "Zihui Gu",
              "Zijia Zhu",
              "Zijun Liu",
              "Zilin Li",
              "Ziwei Xie",
              "Ziyang Song",
              "Zizheng Pan",
              "Zhen Huang",
              "Zhipeng Xu",
              "Zhongyu Zhang",
              "Zhen Zhang"
            ],
            "organization": null,
            "date": "2025-01-22T15:19:35Z",
            "url": "https://arxiv.org/pdf/2501.12948.pdf",
            "description": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 33,
          "function_name": "what_you_see",
          "code": "image(\"images/llama4-benchmarks.png\", width=800), link(llama4)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/llama4-benchmarks.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Llama 4",
            "authors": null,
            "organization": "Meta",
            "date": null,
            "url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 34,
          "function_name": "what_you_see",
          "code": "image(\"https://www.datocms-assets.com/64837/1741887109-instruct-1.png\", width=800), link(olmo2_32b)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-514a4fe0690116810f840ff30c6cdf3f-https_www_datocms-assets_com_64837_1741887109-instruct-1_png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "OLMo 2 (32B)",
            "authors": null,
            "organization": "AI2",
            "date": null,
            "url": "https://allenai.org/blog/olmo2-32B",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 36,
          "function_name": "what_you_see",
          "code": "text(\"Recent language models are evaluated on similar, but not entirely identical, benchmarks (MMLU, MATH, etc.).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Recent language models are evaluated on similar, but not entirely identical, benchmarks (MMLU, MATH, etc.).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 37,
          "function_name": "what_you_see",
          "code": "text(\"What are these benchmarks?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "What are these benchmarks?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 38,
          "function_name": "what_you_see",
          "code": "text(\"What do these numbers mean?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "What do these numbers mean?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 40,
          "function_name": "what_you_see",
          "code": "image(\"images/helm-capabilities-leaderboard.png\", width=1000)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/helm-capabilities-leaderboard.png",
          "style": {
            "width": 1000
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 41,
          "function_name": "what_you_see",
          "code": "link(title=\"[HELM capabilities]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM capabilities]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 43,
          "function_name": "what_you_see",
          "code": "text(\"Pay close attention to the costs!\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Pay close attention to the costs!",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 44,
          "function_name": "what_you_see",
          "code": "image(\"images/artificial-analysis.png\", width=800), link(title=\"[Artificial Analysis]\", url=\"https://artificialanalysis.ai/\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/artificial-analysis.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[Artificial Analysis]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://artificialanalysis.ai/",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 46,
          "function_name": "what_you_see",
          "code": "text(\"Maybe a model is good if people choose to use it (and pay for it)...\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Maybe a model is good if people choose to use it (and pay for it)...",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 47,
          "function_name": "what_you_see",
          "code": "image(\"images/openrouter.png\", width=600), link(title=\"[OpenRouter]\", url=\"https://openrouter.ai/rankings\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/openrouter.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[OpenRouter]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://openrouter.ai/rankings",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 49,
          "function_name": "what_you_see",
          "code": "image(\"images/chatbot-arena-leaderboard.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/chatbot-arena-leaderboard.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 50,
          "function_name": "what_you_see",
          "code": "link(title=\"[Chatbot Arena]\", url=\"https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[Chatbot Arena]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 52,
          "function_name": "what_you_see",
          "code": "text(\"## Vibes\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "## Vibes",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 53,
          "function_name": "what_you_see",
          "code": "x_link(\"https://x.com/demishassabis/status/1919779362980692364\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": " [X]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://x.com/demishassabis/status/1919779362980692364",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 54,
          "function_name": "what_you_see",
          "code": "image(\"images/demis-gemini-2.5.png\", width=500)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/demis-gemini-2.5.png",
          "style": {
            "width": 500
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 56,
          "function_name": "what_you_see",
          "code": "text(\"A crisis...\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "A crisis...",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 57,
          "function_name": "what_you_see",
          "code": "image(\"images/karpathy-crisis.png\", width=600)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/karpathy-crisis.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 8,
          "function_name": "main",
          "code": "what_you_see()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 60,
          "function_name": "how_to_think_about_evaluation",
          "code": "def how_to_think_about_evaluation():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 61,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"You might think evaluation is a mechanical process (take existing model, throw prompts at it, average some numbers)...\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "You might think evaluation is a mechanical process (take existing model, throw prompts at it, average some numbers)...",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 62,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"Actually, evaluation is a profound and rich topic...\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Actually, evaluation is a profound and rich topic...",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 63,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"...and it determines the future of language models.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "...and it determines the future of language models.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 65,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"What's the point of evaluation?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "What's the point of evaluation?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 66,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"There is no one true evaluation; it depends on what question you're trying to answer.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "There is no one true evaluation; it depends on what question you're trying to answer.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 67,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"1. User or company wants to make a purchase decision (model A or model B) for their use case (e.g., customer service chatbots).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "1. User or company wants to make a purchase decision (model A or model B) for their use case (e.g., customer service chatbots).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 68,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"2. Researchers want to measure the raw capabilities of a model (e.g., intelligence).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "2. Researchers want to measure the raw capabilities of a model (e.g., intelligence).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 69,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"3. We want to understand the benefits + harms of a model (for business and policy reasons).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "3. We want to understand the benefits + harms of a model (for business and policy reasons).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 70,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"4. Model developers want to get feedback to improve the model.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "4. Model developers want to get feedback to improve the model.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 71,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"In each case, there is an abstract **goal** that needs to be translated into a concrete evaluation.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "In each case, there is an abstract **goal** that needs to be translated into a concrete evaluation.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 73,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"Framework\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Framework",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 74,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"1. What are the **inputs**?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "1. What are the **inputs**?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 75,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"2. How do **call** the language model?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "2. How do **call** the language model?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 76,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"3. How do you evaluate the **outputs**?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "3. How do you evaluate the **outputs**?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 77,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"4. How to **interpret** the results?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "4. How to **interpret** the results?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 79,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"What are the inputs?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "What are the inputs?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 80,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"1. What use cases are **covered**?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "1. What use cases are **covered**?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 81,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"2. Do we have representation of **difficult** inputs in the tail?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "2. Do we have representation of **difficult** inputs in the tail?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 82,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"3. Are the inputs **adapted** to the model (e.g., multi-turn)?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "3. Are the inputs **adapted** to the model (e.g., multi-turn)?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 84,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"How do you call the language model?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "How do you call the language model?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 85,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"1. How do you prompt the language model?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "1. How do you prompt the language model?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 86,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"2. Does the language model use chain-of-thought, tools, RAG, etc.?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "2. Does the language model use chain-of-thought, tools, RAG, etc.?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 87,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"3. Are we evaluating the language model or an agentic system (model developer wants former, user wants latter)?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "3. Are we evaluating the language model or an agentic system (model developer wants former, user wants latter)?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 89,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"How do you evaluate the outputs?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "How do you evaluate the outputs?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 90,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"1. Are the reference outputs used for evaluation error-free?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "1. Are the reference outputs used for evaluation error-free?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 91,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"2. What metrics do you use (e.g., pass@k)?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "2. What metrics do you use (e.g., pass@k)?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 92,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"3. How do you factor in cost (e.g., inference + training)?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "3. How do you factor in cost (e.g., inference + training)?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 93,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"4. How do you factor in asymmetric errors (e.g., hallucinations in a medical setting)?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "4. How do you factor in asymmetric errors (e.g., hallucinations in a medical setting)?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 94,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"5. How do you handle open-ended generation (no ground truth)?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "5. How do you handle open-ended generation (no ground truth)?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 96,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"How do you inteprret the metrics?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "How do you inteprret the metrics?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 97,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"1. How do you interpret a number (e.g., 91%) - is it ready for deployment?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "1. How do you interpret a number (e.g., 91%) - is it ready for deployment?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 98,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"2. How do we assess generalization in the face of train-test overlap?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "2. How do we assess generalization in the face of train-test overlap?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 99,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"3. Are we evaluating the final model or the method?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "3. Are we evaluating the final model or the method?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 101,
          "function_name": "how_to_think_about_evaluation",
          "code": "text(\"Summary: lots of questions to think through when doing evaluation\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Summary: lots of questions to think through when doing evaluation",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 9,
          "function_name": "main",
          "code": "how_to_think_about_evaluation()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 103,
          "function_name": "perplexity",
          "code": "def perplexity():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 104,
          "function_name": "perplexity",
          "code": "text(\"Recall: that a language model is a probability distribution **p(x)** over sequences of tokens.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Recall: that a language model is a probability distribution **p(x)** over sequences of tokens.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 105,
          "function_name": "perplexity",
          "code": "text(\"Perplexity (1/p(D))^(1/|D|) measures whether p assigns high probability to some dataset D.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Perplexity (1/p(D))^(1/|D|) measures whether p assigns high probability to some dataset D.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 107,
          "function_name": "perplexity",
          "code": "text(\"In pre-training, you minimize perplexity on the training set.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "In pre-training, you minimize perplexity on the training set.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 108,
          "function_name": "perplexity",
          "code": "text(\"The obvious thing is to measure perplexity on the test set.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "The obvious thing is to measure perplexity on the test set.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 110,
          "function_name": "perplexity",
          "code": "text(\"Standard datasets: Penn Treebank (WSJ), WikiText-103 (Wikipedia), One Billion Word Benchmark (from machine translation WMT11 - EuroParl, UN, news)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Standard datasets: Penn Treebank (WSJ), WikiText-103 (Wikipedia), One Billion Word Benchmark (from machine translation WMT11 - EuroParl, UN, news)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 111,
          "function_name": "perplexity",
          "code": "text(\"Papers trained on a dataset (training split) and evaluated on the same dataset (test split)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Papers trained on a dataset (training split) and evaluated on the same dataset (test split)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 112,
          "function_name": "perplexity",
          "code": "text(\"Pure CNNs+LSTMs on the One Billion Word Benchmark (perplexity 51.3 -> 30.0) \"), link(\"https://arxiv.org/abs/1602.02410\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Pure CNNs+LSTMs on the One Billion Word Benchmark (perplexity 51.3 -> 30.0) ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Exploring the Limits of Language Modeling",
            "authors": [
              "Rafal Jozefowicz",
              "Oriol Vinyals",
              "Mike Schuster",
              "Noam Shazeer",
              "Yonghui Wu"
            ],
            "organization": null,
            "date": "2016-02-07T19:11:17Z",
            "url": "https://arxiv.org/abs/1602.02410",
            "description": "In this work we explore recent advances in Recurrent Neural Networks for large scale Language Modeling, a task central to language understanding. We extend current models to deal with two key challenges present in this task: corpora and vocabulary sizes, and complex, long term structure of language. We perform an exhaustive study on techniques such as character Convolutional Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark. Our best single model significantly improves state-of-the-art perplexity from 51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20), while an ensemble of models sets a new record by improving perplexity from 41.0 down to 23.7. We also release these models for the NLP and ML community to study and improve upon.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 114,
          "function_name": "perplexity",
          "code": "text(\"GPT-2 trained on WebText (40GB text, websites linked from Reddit), zero-shot on standard datasets\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "GPT-2 trained on WebText (40GB text, websites linked from Reddit), zero-shot on standard datasets",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 115,
          "function_name": "perplexity",
          "code": "text(\"This is out-of-distribution evaluation (but idea is that training covers a lot)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "This is out-of-distribution evaluation (but idea is that training covers a lot)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 116,
          "function_name": "perplexity",
          "code": "image(\"images/gpt2-perplexity.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/gpt2-perplexity.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 117,
          "function_name": "perplexity",
          "code": "text(\"Works better on small datasets (transfer is helpful), but not larger datasets (1BW)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Works better on small datasets (transfer is helpful), but not larger datasets (1BW)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 119,
          "function_name": "perplexity",
          "code": "text(\"Since GPT-2 and GPT-3, language modeling papers have shifted more towards downstream task accuracy.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Since GPT-2 and GPT-3, language modeling papers have shifted more towards downstream task accuracy.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 120,
          "function_name": "perplexity",
          "code": "text(\"But reasons why perplexity is still useful:\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "But reasons why perplexity is still useful:",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 121,
          "function_name": "perplexity",
          "code": "text(\"- Smoother than downstream task accuracy (for fitting scaling laws)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Smoother than downstream task accuracy (for fitting scaling laws)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 122,
          "function_name": "perplexity",
          "code": "text(\"- Is universal (why we use it for training) whereas task accuracy might miss some nuances\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Is universal (why we use it for training) whereas task accuracy might miss some nuances",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 123,
          "function_name": "perplexity",
          "code": "text(\"- Note: can measure conditional perplexity on downstream task too (used for scaling laws) \"), link(\"https://arxiv.org/abs/2412.04403\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Note: can measure conditional perplexity on downstream task too (used for scaling laws) ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Establishing Task Scaling Laws via Compute-Efficient Model Ladders",
            "authors": [
              "Akshita Bhagia",
              "Jiacheng Liu",
              "Alexander Wettig",
              "David Heineman",
              "Oyvind Tafjord",
              "Ananya Harsh Jha",
              "Luca Soldaini",
              "Noah A. Smith",
              "Dirk Groeneveld",
              "Pang Wei Koh",
              "Jesse Dodge",
              "Hannaneh Hajishirzi"
            ],
            "organization": null,
            "date": "2024-12-05T18:21:49Z",
            "url": "https://arxiv.org/abs/2412.04403",
            "description": "We develop task scaling laws and model ladders to predict the individual task performance of pretrained language models (LMs) in the overtrained setting. Standard power laws for language modeling loss cannot accurately model task performance. Therefore, we leverage a two-step prediction approach: first use model and data size to predict a task-specific loss, and then use this task loss to predict task performance. We train a set of small-scale \"ladder\" models, collect data points to fit the parameterized functions of the two prediction steps, and make predictions for two target models: a 7B model trained to 4T tokens and a 13B model trained to 5T tokens. Training the ladder models only costs 1% of the compute used for the target models. On four multiple-choice tasks written in ranked classification format, we can predict the accuracy of both target models within 2 points of absolute error. We have higher prediction error on four other tasks (average absolute error 6.9) and find that these are often tasks with higher variance in task metrics. We also find that using less compute to train fewer ladder models tends to deteriorate predictions. Finally, we empirically show that our design choices and the two-step approach lead to superior performance in establishing scaling laws.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 125,
          "function_name": "perplexity",
          "code": "text(\"Warning (if you're running a leaderboard): evaluator needs to trust the language model\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Warning (if you're running a leaderboard): evaluator needs to trust the language model",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 126,
          "function_name": "perplexity",
          "code": "text(\"For task accuracy, can just take output generated from a blackbox model and compute the desired metrics\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "For task accuracy, can just take output generated from a blackbox model and compute the desired metrics",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 127,
          "function_name": "perplexity",
          "code": "text(\"For perplexity, need LM to generate probabilities and trust that they sum to 1 (even worse with UNKs back in the day)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "For perplexity, need LM to generate probabilities and trust that they sum to 1 (even worse with UNKs back in the day)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 129,
          "function_name": "perplexity",
          "code": "text(\"The perplexity maximalist view:\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "The perplexity maximalist view:",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 130,
          "function_name": "perplexity",
          "code": "text(\"- Your true distribution is t, model is p\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Your true distribution is t, model is p",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 131,
          "function_name": "perplexity",
          "code": "text(\"- Best possible perplexity is H(t) obtained iff p = t\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Best possible perplexity is H(t) obtained iff p = t",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 132,
          "function_name": "perplexity",
          "code": "text(\"- If have t, then solve all the tasks\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- If have t, then solve all the tasks",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 133,
          "function_name": "perplexity",
          "code": "text(\"- So by pushing down on perplexity, will eventually reach AGI\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- So by pushing down on perplexity, will eventually reach AGI",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 134,
          "function_name": "perplexity",
          "code": "text(\"- Caveat: this might not be the most efficient way to get there (pushing down on parts of the distribution that don't matter)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Caveat: this might not be the most efficient way to get there (pushing down on parts of the distribution that don't matter)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 136,
          "function_name": "perplexity",
          "code": "text(\"Things that are spiritually perplexity:\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Things that are spiritually perplexity:",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 137,
          "function_name": "perplexity",
          "code": "text(\"Similar idea: cloze tasks like LAMBADA \"), link(\"https://arxiv.org/abs/1606.06031\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Similar idea: cloze tasks like LAMBADA ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context",
            "authors": [
              "Denis Paperno",
              "Germ\u00e1n Kruszewski",
              "Angeliki Lazaridou",
              "Quan Ngoc Pham",
              "Raffaella Bernardi",
              "Sandro Pezzelle",
              "Marco Baroni",
              "Gemma Boleda",
              "Raquel Fern\u00e1ndez"
            ],
            "organization": null,
            "date": "2016-06-20T09:37:17Z",
            "url": "https://arxiv.org/abs/1606.06031",
            "description": "We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 138,
          "function_name": "perplexity",
          "code": "image(\"images/lambada.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/lambada.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 139,
          "function_name": "perplexity",
          "code": "text(\"HellaSwag \"), link(\"https://arxiv.org/pdf/1905.07830\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "HellaSwag ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "HellaSwag: Can a Machine Really Finish Your Sentence?",
            "authors": [
              "Rowan Zellers",
              "Ari Holtzman",
              "Yonatan Bisk",
              "Ali Farhadi",
              "Yejin Choi"
            ],
            "organization": null,
            "date": "2019-05-19T23:57:23Z",
            "url": "https://arxiv.org/pdf/1905.07830",
            "description": "Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as \"A woman sits at a piano,\" a machine must select the most likely followup: \"She sets her fingers on the keys.\" With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans (>95% accuracy), state-of-the-art models struggle (<48%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical 'Goldilocks' zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 140,
          "function_name": "perplexity",
          "code": "image(\"images/hellaswag.png\", width=600)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/hellaswag.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 11,
          "function_name": "main",
          "code": "perplexity()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 143,
          "function_name": "knowledge_benchmarks",
          "code": "def knowledge_benchmarks():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 144,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"### Massive Multitask Language Understanding (MMLU)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Massive Multitask Language Understanding (MMLU)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 145,
          "function_name": "knowledge_benchmarks",
          "code": "link(mmlu)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Measuring Massive Multitask Language Understanding",
            "authors": [
              "Dan Hendrycks",
              "Collin Burns",
              "Steven Basart",
              "Andy Zou",
              "Mantas Mazeika",
              "Dawn Song",
              "Jacob Steinhardt"
            ],
            "organization": "Berkeley",
            "date": "2020-09-07T17:59:25Z",
            "url": "https://arxiv.org/pdf/2009.03300.pdf",
            "description": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
            "notes": "57 subjects, multiple-choice"
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 146,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- 57 subjects (e.g., math, US history, law, morality), multiple-choice\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- 57 subjects (e.g., math, US history, law, morality), multiple-choice",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 147,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- \\\"collected by graduate and undergraduate students from freely available sources online\\\"\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- \"collected by graduate and undergraduate students from freely available sources online\"",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 148,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Really about testing knowledge, not language understanding\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Really about testing knowledge, not language understanding",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 149,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Evaluated on GPT-3 using few-shot prompting\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Evaluated on GPT-3 using few-shot prompting",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 150,
          "function_name": "knowledge_benchmarks",
          "code": "image(\"images/mmlu.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/mmlu.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 151,
          "function_name": "knowledge_benchmarks",
          "code": "link(title=\"[HELM MMLU for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/mmlu/latest/\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM MMLU for visualizing predictions]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/mmlu/latest/",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 153,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"### MMLU-Pro\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### MMLU-Pro",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 154,
          "function_name": "knowledge_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2406.01574\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark",
            "authors": [
              "Yubo Wang",
              "Xueguang Ma",
              "Ge Zhang",
              "Yuansheng Ni",
              "Abhranil Chandra",
              "Shiguang Guo",
              "Weiming Ren",
              "Aaran Arulraj",
              "Xuan He",
              "Ziyan Jiang",
              "Tianle Li",
              "Max Ku",
              "Kai Wang",
              "Alex Zhuang",
              "Rongqi Fan",
              "Xiang Yue",
              "Wenhu Chen"
            ],
            "organization": null,
            "date": "2024-06-03T17:53:00Z",
            "url": "https://arxiv.org/abs/2406.01574",
            "description": "In the age of large-scale language models, benchmarks like the Massive Multitask Language Understanding (MMLU) have been pivotal in pushing the boundaries of what AI can achieve in language comprehension and reasoning across diverse domains. However, as models continue to improve, their performance on these benchmarks has begun to plateau, making it increasingly difficult to discern differences in model capabilities. This paper introduces MMLU-Pro, an enhanced dataset designed to extend the mostly knowledge-driven MMLU benchmark by integrating more challenging, reasoning-focused questions and expanding the choice set from four to ten options. Additionally, MMLU-Pro eliminates the trivial and noisy questions in MMLU. Our experimental results show that MMLU-Pro not only raises the challenge, causing a significant drop in accuracy by 16% to 33% compared to MMLU but also demonstrates greater stability under varying prompts. With 24 different prompt styles tested, the sensitivity of model scores to prompt variations decreased from 4-5% in MMLU to just 2% in MMLU-Pro. Additionally, we found that models utilizing Chain of Thought (CoT) reasoning achieved better performance on MMLU-Pro compared to direct answering, which is in stark contrast to the findings on the original MMLU, indicating that MMLU-Pro includes more complex reasoning questions. Our assessments confirm that MMLU-Pro is a more discriminative benchmark to better track progress in the field.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 155,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Removed noisy/trivial questions from MMLU\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Removed noisy/trivial questions from MMLU",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 156,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Expanded 4 choices to 10 choices\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Expanded 4 choices to 10 choices",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 157,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Evaluated using chain of thought (gives model more of a chance)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Evaluated using chain of thought (gives model more of a chance)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 158,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Accuracy of models drop by 16% to 33% (not as saturated)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Accuracy of models drop by 16% to 33% (not as saturated)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 159,
          "function_name": "knowledge_benchmarks",
          "code": "image(\"images/mmlu-pro.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/mmlu-pro.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 160,
          "function_name": "knowledge_benchmarks",
          "code": "link(title=\"[HELM MMLU-Pro for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/mmlu_pro\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM MMLU-Pro for visualizing predictions]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/mmlu_pro",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 162,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"### Graduate-Level Google-Proof Q&A (GPQA)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Graduate-Level Google-Proof Q&A (GPQA)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 163,
          "function_name": "knowledge_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2311.12022\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
            "authors": [
              "David Rein",
              "Betty Li Hou",
              "Asa Cooper Stickland",
              "Jackson Petty",
              "Richard Yuanzhe Pang",
              "Julien Dirani",
              "Julian Michael",
              "Samuel R. Bowman"
            ],
            "organization": null,
            "date": "2023-11-20T18:57:34Z",
            "url": "https://arxiv.org/abs/2311.12022",
            "description": "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are \"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 164,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Questions written by 61 PhD contractors from Upwork\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Questions written by 61 PhD contractors from Upwork",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 165,
          "function_name": "knowledge_benchmarks",
          "code": "image(\"images/gpqa.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/gpqa.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 166,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- PhD experts achieve 65% accuracy\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- PhD experts achieve 65% accuracy",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 167,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Non-experts achieve 34% over 30 minutes with access to Google\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Non-experts achieve 34% over 30 minutes with access to Google",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 168,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- GPT-4 achieves 39%\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- GPT-4 achieves 39%",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 169,
          "function_name": "knowledge_benchmarks",
          "code": "link(title=\"[HELM GPQA for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/gpqa\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM GPQA for visualizing predictions]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/gpqa",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 171,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"### Humanity's Last Exam\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Humanity's Last Exam",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 172,
          "function_name": "knowledge_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2501.14249\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Humanity's Last Exam",
            "authors": [
              "Long Phan",
              "Alice Gatti",
              "Ziwen Han",
              "Nathaniel Li",
              "Josephina Hu",
              "Hugh Zhang",
              "Chen Bo Calvin Zhang",
              "Mohamed Shaaban",
              "John Ling",
              "Sean Shi",
              "Michael Choi",
              "Anish Agrawal",
              "Arnav Chopra",
              "Adam Khoja",
              "Ryan Kim",
              "Richard Ren",
              "Jason Hausenloy",
              "Oliver Zhang",
              "Mantas Mazeika",
              "Dmitry Dodonov",
              "Tung Nguyen",
              "Jaeho Lee",
              "Daron Anderson",
              "Mikhail Doroshenko",
              "Alun Cennyth Stokes",
              "Mobeen Mahmood",
              "Oleksandr Pokutnyi",
              "Oleg Iskra",
              "Jessica P. Wang",
              "John-Clark Levin",
              "Mstyslav Kazakov",
              "Fiona Feng",
              "Steven Y. Feng",
              "Haoran Zhao",
              "Michael Yu",
              "Varun Gangal",
              "Chelsea Zou",
              "Zihan Wang",
              "Serguei Popov",
              "Robert Gerbicz",
              "Geoff Galgon",
              "Johannes Schmitt",
              "Will Yeadon",
              "Yongki Lee",
              "Scott Sauers",
              "Alvaro Sanchez",
              "Fabian Giska",
              "Marc Roth",
              "S\u00f8ren Riis",
              "Saiteja Utpala",
              "Noah Burns",
              "Gashaw M. Goshu",
              "Mohinder Maheshbhai Naiya",
              "Chidozie Agu",
              "Zachary Giboney",
              "Antrell Cheatom",
              "Francesco Fournier-Facio",
              "Sarah-Jane Crowson",
              "Lennart Finke",
              "Zerui Cheng",
              "Jennifer Zampese",
              "Ryan G. Hoerr",
              "Mark Nandor",
              "Hyunwoo Park",
              "Tim Gehrunger",
              "Jiaqi Cai",
              "Ben McCarty",
              "Alexis C Garretson",
              "Edwin Taylor",
              "Damien Sileo",
              "Qiuyu Ren",
              "Usman Qazi",
              "Lianghui Li",
              "Jungbae Nam",
              "John B. Wydallis",
              "Pavel Arkhipov",
              "Jack Wei Lun Shi",
              "Aras Bacho",
              "Chris G. Willcocks",
              "Hangrui Cao",
              "Sumeet Motwani",
              "Emily de Oliveira Santos",
              "Johannes Veith",
              "Edward Vendrow",
              "Doru Cojoc",
              "Kengo Zenitani",
              "Joshua Robinson",
              "Longke Tang",
              "Yuqi Li",
              "Joshua Vendrow",
              "Natanael Wildner Fraga",
              "Vladyslav Kuchkin",
              "Andrey Pupasov Maksimov",
              "Pierre Marion",
              "Denis Efremov",
              "Jayson Lynch",
              "Kaiqu Liang",
              "Aleksandar Mikov",
              "Andrew Gritsevskiy",
              "Julien Guillod",
              "G\u00f6zdenur Demir",
              "Dakotah Martinez",
              "Ben Pageler",
              "Kevin Zhou",
              "Saeed Soori",
              "Ori Press",
              "Henry Tang",
              "Paolo Rissone",
              "Sean R. Green",
              "Lina Br\u00fcssel",
              "Moon Twayana",
              "Aymeric Dieuleveut",
              "Joseph Marvin Imperial",
              "Ameya Prabhu",
              "Jinzhou Yang",
              "Nick Crispino",
              "Arun Rao",
              "Dimitri Zvonkine",
              "Gabriel Loiseau",
              "Mikhail Kalinin",
              "Marco Lukas",
              "Ciprian Manolescu",
              "Nate Stambaugh",
              "Subrata Mishra",
              "Tad Hogg",
              "Carlo Bosio",
              "Brian P Coppola",
              "Julian Salazar",
              "Jaehyeok Jin",
              "Rafael Sayous",
              "Stefan Ivanov",
              "Philippe Schwaller",
              "Shaipranesh Senthilkuma",
              "Andres M Bran",
              "Andres Algaba",
              "Kelsey Van den Houte",
              "Lynn Van Der Sypt",
              "Brecht Verbeken",
              "David Noever",
              "Alexei Kopylov",
              "Benjamin Myklebust",
              "Bikun Li",
              "Lisa Schut",
              "Evgenii Zheltonozhskii",
              "Qiaochu Yuan",
              "Derek Lim",
              "Richard Stanley",
              "Tong Yang",
              "John Maar",
              "Julian Wykowski",
              "Mart\u00ed Oller",
              "Anmol Sahu",
              "Cesare Giulio Ardito",
              "Yuzheng Hu",
              "Ariel Ghislain Kemogne Kamdoum",
              "Alvin Jin",
              "Tobias Garcia Vilchis",
              "Yuexuan Zu",
              "Martin Lackner",
              "James Koppel",
              "Gongbo Sun",
              "Daniil S. Antonenko",
              "Steffi Chern",
              "Bingchen Zhao",
              "Pierrot Arsene",
              "Joseph M Cavanagh",
              "Daofeng Li",
              "Jiawei Shen",
              "Donato Crisostomi",
              "Wenjin Zhang",
              "Ali Dehghan",
              "Sergey Ivanov",
              "David Perrella",
              "Nurdin Kaparov",
              "Allen Zang",
              "Ilia Sucholutsky",
              "Arina Kharlamova",
              "Daniil Orel",
              "Vladislav Poritski",
              "Shalev Ben-David",
              "Zachary Berger",
              "Parker Whitfill",
              "Michael Foster",
              "Daniel Munro",
              "Linh Ho",
              "Shankar Sivarajan",
              "Dan Bar Hava",
              "Aleksey Kuchkin",
              "David Holmes",
              "Alexandra Rodriguez-Romero",
              "Frank Sommerhage",
              "Anji Zhang",
              "Richard Moat",
              "Keith Schneider",
              "Zakayo Kazibwe",
              "Don Clarke",
              "Dae Hyun Kim",
              "Felipe Meneguitti Dias",
              "Sara Fish",
              "Veit Elser",
              "Tobias Kreiman",
              "Victor Efren Guadarrama Vilchis",
              "Immo Klose",
              "Ujjwala Anantheswaran",
              "Adam Zweiger",
              "Kaivalya Rawal",
              "Jeffery Li",
              "Jeremy Nguyen",
              "Nicolas Daans",
              "Haline Heidinger",
              "Maksim Radionov",
              "V\u00e1clav Rozho\u0148",
              "Vincent Ginis",
              "Christian Stump",
              "Niv Cohen",
              "Rafa\u0142 Po\u015bwiata",
              "Josef Tkadlec",
              "Alan Goldfarb",
              "Chenguang Wang",
              "Piotr Padlewski",
              "Stanislaw Barzowski",
              "Kyle Montgomery",
              "Ryan Stendall",
              "Jamie Tucker-Foltz",
              "Jack Stade",
              "T. Ryan Rogers",
              "Tom Goertzen",
              "Declan Grabb",
              "Abhishek Shukla",
              "Alan Givr\u00e9",
              "John Arnold Ambay",
              "Archan Sen",
              "Muhammad Fayez Aziz",
              "Mark H Inlow",
              "Hao He",
              "Ling Zhang",
              "Younesse Kaddar",
              "Ivar \u00c4ngquist",
              "Yanxu Chen",
              "Harrison K Wang",
              "Kalyan Ramakrishnan",
              "Elliott Thornley",
              "Antonio Terpin",
              "Hailey Schoelkopf",
              "Eric Zheng",
              "Avishy Carmi",
              "Ethan D. L. Brown",
              "Kelin Zhu",
              "Max Bartolo",
              "Richard Wheeler",
              "Martin Stehberger",
              "Peter Bradshaw",
              "JP Heimonen",
              "Kaustubh Sridhar",
              "Ido Akov",
              "Jennifer Sandlin",
              "Yury Makarychev",
              "Joanna Tam",
              "Hieu Hoang",
              "David M. Cunningham",
              "Vladimir Goryachev",
              "Demosthenes Patramanis",
              "Michael Krause",
              "Andrew Redenti",
              "David Aldous",
              "Jesyin Lai",
              "Shannon Coleman",
              "Jiangnan Xu",
              "Sangwon Lee",
              "Ilias Magoulas",
              "Sandy Zhao",
              "Ning Tang",
              "Michael K. Cohen",
              "Orr Paradise",
              "Jan Hendrik Kirchner",
              "Maksym Ovchynnikov",
              "Jason O. Matos",
              "Adithya Shenoy",
              "Michael Wang",
              "Yuzhou Nie",
              "Anna Sztyber-Betley",
              "Paolo Faraboschi",
              "Robin Riblet",
              "Jonathan Crozier",
              "Shiv Halasyamani",
              "Shreyas Verma",
              "Prashant Joshi",
              "Eli Meril",
              "Ziqiao Ma",
              "J\u00e9r\u00e9my Andr\u00e9oletti",
              "Raghav Singhal",
              "Jacob Platnick",
              "Volodymyr Nevirkovets",
              "Luke Basler",
              "Alexander Ivanov",
              "Seri Khoury",
              "Nils Gustafsson",
              "Marco Piccardo",
              "Hamid Mostaghimi",
              "Qijia Chen",
              "Virendra Singh",
              "Tran Quoc Kh\u00e1nh",
              "Paul Rosu",
              "Hannah Szlyk",
              "Zachary Brown",
              "Himanshu Narayan",
              "Aline Menezes",
              "Jonathan Roberts",
              "William Alley",
              "Kunyang Sun",
              "Arkil Patel",
              "Max Lamparth",
              "Anka Reuel",
              "Linwei Xin",
              "Hanmeng Xu",
              "Jacob Loader",
              "Freddie Martin",
              "Zixuan Wang",
              "Andrea Achilleos",
              "Thomas Preu",
              "Tomek Korbak",
              "Ida Bosio",
              "Fereshteh Kazemi",
              "Ziye Chen",
              "Bir\u00f3 B\u00e1lint",
              "Eve J. Y. Lo",
              "Jiaqi Wang",
              "Maria In\u00eas S. Nunes",
              "Jeremiah Milbauer",
              "M Saiful Bari",
              "Zihao Wang",
              "Behzad Ansarinejad",
              "Yewen Sun",
              "Stephane Durand",
              "Hossam Elgnainy",
              "Guillaume Douville",
              "Daniel Tordera",
              "George Balabanian",
              "Hew Wolff",
              "Lynna Kvistad",
              "Hsiaoyun Milliron",
              "Ahmad Sakor",
              "Murat Eron",
              "Andrew Favre D. O.",
              "Shailesh Shah",
              "Xiaoxiang Zhou",
              "Firuz Kamalov",
              "Sherwin Abdoli",
              "Tim Santens",
              "Shaul Barkan",
              "Allison Tee",
              "Robin Zhang",
              "Alessandro Tomasiello",
              "G. Bruno De Luca",
              "Shi-Zhuo Looi",
              "Vinh-Kha Le",
              "Noam Kolt",
              "Jiayi Pan",
              "Emma Rodman",
              "Jacob Drori",
              "Carl J Fossum",
              "Niklas Muennighoff",
              "Milind Jagota",
              "Ronak Pradeep",
              "Honglu Fan",
              "Jonathan Eicher",
              "Michael Chen",
              "Kushal Thaman",
              "William Merrill",
              "Moritz Firsching",
              "Carter Harris",
              "Stefan Ciob\u00e2c\u0103",
              "Jason Gross",
              "Rohan Pandey",
              "Ilya Gusev",
              "Adam Jones",
              "Shashank Agnihotri",
              "Pavel Zhelnov",
              "Mohammadreza Mofayezi",
              "Alexander Piperski",
              "David K. Zhang",
              "Kostiantyn Dobarskyi",
              "Roman Leventov",
              "Ignat Soroko",
              "Joshua Duersch",
              "Vage Taamazyan",
              "Andrew Ho",
              "Wenjie Ma",
              "William Held",
              "Ruicheng Xian",
              "Armel Randy Zebaze",
              "Mohanad Mohamed",
              "Julian Noah Leser",
              "Michelle X Yuan",
              "Laila Yacar",
              "Johannes Lengler",
              "Katarzyna Olszewska",
              "Claudio Di Fratta",
              "Edson Oliveira",
              "Joseph W. Jackson",
              "Andy Zou",
              "Muthu Chidambaram",
              "Timothy Manik",
              "Hector Haffenden",
              "Dashiell Stander",
              "Ali Dasouqi",
              "Alexander Shen",
              "Bita Golshani",
              "David Stap",
              "Egor Kretov",
              "Mikalai Uzhou",
              "Alina Borisovna Zhidkovskaya",
              "Nick Winter",
              "Miguel Orbegozo Rodriguez",
              "Robert Lauff",
              "Dustin Wehr",
              "Colin Tang",
              "Zaki Hossain",
              "Shaun Phillips",
              "Fortuna Samuele",
              "Fredrik Ekstr\u00f6m",
              "Angela Hammon",
              "Oam Patel",
              "Faraz Farhidi",
              "George Medley",
              "Forough Mohammadzadeh",
              "Madellene Pe\u00f1aflor",
              "Haile Kassahun",
              "Alena Friedrich",
              "Rayner Hernandez Perez",
              "Daniel Pyda",
              "Taom Sakal",
              "Omkar Dhamane",
              "Ali Khajegili Mirabadi",
              "Eric Hallman",
              "Kenchi Okutsu",
              "Mike Battaglia",
              "Mohammad Maghsoudimehrabani",
              "Alon Amit",
              "Dave Hulbert",
              "Roberto Pereira",
              "Simon Weber",
              "Handoko",
              "Anton Peristyy",
              "Stephen Malina",
              "Mustafa Mehkary",
              "Rami Aly",
              "Frank Reidegeld",
              "Anna-Katharina Dick",
              "Cary Friday",
              "Mukhwinder Singh",
              "Hassan Shapourian",
              "Wanyoung Kim",
              "Mariana Costa",
              "Hubeyb Gurdogan",
              "Harsh Kumar",
              "Chiara Ceconello",
              "Chao Zhuang",
              "Haon Park",
              "Micah Carroll",
              "Andrew R. Tawfeek",
              "Stefan Steinerberger",
              "Daattavya Aggarwal",
              "Michael Kirchhof",
              "Linjie Dai",
              "Evan Kim",
              "Johan Ferret",
              "Jainam Shah",
              "Yuzhou Wang",
              "Minghao Yan",
              "Krzysztof Burdzy",
              "Lixin Zhang",
              "Antonio Franca",
              "Diana T. Pham",
              "Kang Yong Loh",
              "Joshua Robinson",
              "Abram Jackson",
              "Paolo Giordano",
              "Philipp Petersen",
              "Adrian Cosma",
              "Jesus Colino",
              "Colin White",
              "Jacob Votava",
              "Vladimir Vinnikov",
              "Ethan Delaney",
              "Petr Spelda",
              "Vit Stritecky",
              "Syed M. Shahid",
              "Jean-Christophe Mourrat",
              "Lavr Vetoshkin",
              "Koen Sponselee",
              "Renas Bacho",
              "Zheng-Xin Yong",
              "Florencia de la Rosa",
              "Nathan Cho",
              "Xiuyu Li",
              "Guillaume Malod",
              "Orion Weller",
              "Guglielmo Albani",
              "Leon Lang",
              "Julien Laurendeau",
              "Dmitry Kazakov",
              "Fatimah Adesanya",
              "Julien Portier",
              "Lawrence Hollom",
              "Victor Souza",
              "Yuchen Anna Zhou",
              "Julien Degorre",
              "Yi\u011fit Yal\u0131n",
              "Gbenga Daniel Obikoya",
              "Rai",
              "Filippo Bigi",
              "M. C. Bosc\u00e1",
              "Oleg Shumar",
              "Kaniuar Bacho",
              "Gabriel Recchia",
              "Mara Popescu",
              "Nikita Shulga",
              "Ngefor Mildred Tanwie",
              "Thomas C. H. Lux",
              "Ben Rank",
              "Colin Ni",
              "Matthew Brooks",
              "Alesia Yakimchyk",
              "Huanxu",
              "Liu",
              "Stefano Cavalleri",
              "Olle H\u00e4ggstr\u00f6m",
              "Emil Verkama",
              "Joshua Newbould",
              "Hans Gundlach",
              "Leonor Brito-Santana",
              "Brian Amaro",
              "Vivek Vajipey",
              "Rynaa Grover",
              "Ting Wang",
              "Yosi Kratish",
              "Wen-Ding Li",
              "Sivakanth Gopi",
              "Andrea Caciolai",
              "Christian Schroeder de Witt",
              "Pablo Hern\u00e1ndez-C\u00e1mara",
              "Emanuele Rodol\u00e0",
              "Jules Robins",
              "Dominic Williamson",
              "Vincent Cheng",
              "Brad Raynor",
              "Hao Qi",
              "Ben Segev",
              "Jingxuan Fan",
              "Sarah Martinson",
              "Erik Y. Wang",
              "Kaylie Hausknecht",
              "Michael P. Brenner",
              "Mao Mao",
              "Christoph Demian",
              "Peyman Kassani",
              "Xinyu Zhang",
              "David Avagian",
              "Eshawn Jessica Scipio",
              "Alon Ragoler",
              "Justin Tan",
              "Blake Sims",
              "Rebeka Plecnik",
              "Aaron Kirtland",
              "Omer Faruk Bodur",
              "D. P. Shinde",
              "Yan Carlos Leyva Labrador",
              "Zahra Adoul",
              "Mohamed Zekry",
              "Ali Karakoc",
              "Tania C. B. Santos",
              "Samir Shamseldeen",
              "Loukmane Karim",
              "Anna Liakhovitskaia",
              "Nate Resman",
              "Nicholas Farina",
              "Juan Carlos Gonzalez",
              "Gabe Maayan",
              "Earth Anderson",
              "Rodrigo De Oliveira Pena",
              "Elizabeth Kelley",
              "Hodjat Mariji",
              "Rasoul Pouriamanesh",
              "Wentao Wu",
              "Ross Finocchio",
              "Ismail Alarab",
              "Joshua Cole",
              "Danyelle Ferreira",
              "Bryan Johnson",
              "Mohammad Safdari",
              "Liangti Dai",
              "Siriphan Arthornthurasuk",
              "Isaac C. McAlister",
              "Alejandro Jos\u00e9 Moyano",
              "Alexey Pronin",
              "Jing Fan",
              "Angel Ramirez-Trinidad",
              "Yana Malysheva",
              "Daphiny Pottmaier",
              "Omid Taheri",
              "Stanley Stepanic",
              "Samuel Perry",
              "Luke Askew",
              "Ra\u00fal Adri\u00e1n Huerta Rodr\u00edguez",
              "Ali M. R. Minissi",
              "Ricardo Lorena",
              "Krishnamurthy Iyer",
              "Arshad Anil Fasiludeen",
              "Ronald Clark",
              "Josh Ducey",
              "Matheus Piza",
              "Maja Somrak",
              "Eric Vergo",
              "Juehang Qin",
              "Benj\u00e1min Borb\u00e1s",
              "Eric Chu",
              "Jack Lindsey",
              "Antoine Jallon",
              "I. M. J. McInnis",
              "Evan Chen",
              "Avi Semler",
              "Luk Gloor",
              "Tej Shah",
              "Marc Carauleanu",
              "Pascal Lauer",
              "Tran \u0110uc Huy",
              "Hossein Shahrtash",
              "Emilien Duc",
              "Lukas Lewark",
              "Assaf Brown",
              "Samuel Albanie",
              "Brian Weber",
              "Warren S. Vaz",
              "Pierre Clavier",
              "Yiyang Fan",
              "Gabriel Poesia Reis e Silva",
              "Long",
              "Lian",
              "Marcus Abramovitch",
              "Xi Jiang",
              "Sandra Mendoza",
              "Murat Islam",
              "Juan Gonzalez",
              "Vasilios Mavroudis",
              "Justin Xu",
              "Pawan Kumar",
              "Laxman Prasad Goswami",
              "Daniel Bugas",
              "Nasser Heydari",
              "Ferenc Jeanplong",
              "Thorben Jansen",
              "Antonella Pinto",
              "Archimedes Apronti",
              "Abdallah Galal",
              "Ng Ze-An",
              "Ankit Singh",
              "Tong Jiang",
              "Joan of Arc Xavier",
              "Kanu Priya Agarwal",
              "Mohammed Berkani",
              "Gang Zhang",
              "Zhehang Du",
              "Benedito Alves de Oliveira Junior",
              "Dmitry Malishev",
              "Nicolas Remy",
              "Taylor D. Hartman",
              "Tim Tarver",
              "Stephen Mensah",
              "Gautier Abou Loume",
              "Wiktor Morak",
              "Farzad Habibi",
              "Sarah Hoback",
              "Will Cai",
              "Javier Gimenez",
              "Roselynn Grace Montecillo",
              "Jakub \u0141ucki",
              "Russell Campbell",
              "Asankhaya Sharma",
              "Khalida Meer",
              "Shreen Gul",
              "Daniel Espinosa Gonzalez",
              "Xavier Alapont",
              "Alex Hoover",
              "Gunjan Chhablani",
              "Freddie Vargus",
              "Arunim Agarwal",
              "Yibo Jiang",
              "Deepakkumar Patil",
              "David Outevsky",
              "Kevin Joseph Scaria",
              "Rajat Maheshwari",
              "Abdelkader Dendane",
              "Priti Shukla",
              "Ashley Cartwright",
              "Sergei Bogdanov",
              "Niels M\u00fcndler",
              "S\u00f6ren M\u00f6ller",
              "Luca Arnaboldi",
              "Kunvar Thaman",
              "Muhammad Rehan Siddiqi",
              "Prajvi Saxena",
              "Himanshu Gupta",
              "Tony Fruhauff",
              "Glen Sherman",
              "M\u00e1ty\u00e1s Vincze",
              "Siranut Usawasutsakorn",
              "Dylan Ler",
              "Anil Radhakrishnan",
              "Innocent Enyekwe",
              "Sk Md Salauddin",
              "Jiang Muzhen",
              "Aleksandr Maksapetyan",
              "Vivien Rossbach",
              "Chris Harjadi",
              "Mohsen Bahaloohoreh",
              "Claire Sparrow",
              "Jasdeep Sidhu",
              "Sam Ali",
              "Song Bian",
              "John Lai",
              "Eric Singer",
              "Justine Leon Uro",
              "Greg Bateman",
              "Mohamed Sayed",
              "Ahmed Menshawy",
              "Darling Duclosel",
              "Dario Bezzi",
              "Yashaswini Jain",
              "Ashley Aaron",
              "Murat Tiryakioglu",
              "Sheeshram Siddh",
              "Keith Krenek",
              "Imad Ali Shah",
              "Jun Jin",
              "Scott Creighton",
              "Denis Peskoff",
              "Zienab EL-Wasif",
              "Ragavendran P V",
              "Michael Richmond",
              "Joseph McGowan",
              "Tejal Patwardhan",
              "Hao-Yu Sun",
              "Ting Sun",
              "Nikola Zubi\u0107",
              "Samuele Sala",
              "Stephen Ebert",
              "Jean Kaddour",
              "Manuel Schottdorf",
              "Dianzhuo Wang",
              "Gerol Petruzella",
              "Alex Meiburg",
              "Tilen Medved",
              "Ali ElSheikh",
              "S Ashwin Hebbar",
              "Lorenzo Vaquero",
              "Xianjun Yang",
              "Jason Poulos",
              "Vil\u00e9m Zouhar",
              "Sergey Bogdanik",
              "Mingfang Zhang",
              "Jorge Sanz-Ros",
              "David Anugraha",
              "Yinwei Dai",
              "Anh N. Nhu",
              "Xue Wang",
              "Ali Anil Demircali",
              "Zhibai Jia",
              "Yuyin Zhou",
              "Juncheng Wu",
              "Mike He",
              "Nitin Chandok",
              "Aarush Sinha",
              "Gaoxiang Luo",
              "Long Le",
              "Micka\u00ebl Noy\u00e9",
              "Micha\u0142 Pere\u0142kiewicz",
              "Ioannis Pantidis",
              "Tianbo Qi",
              "Soham Sachin Purohit",
              "Letitia Parcalabescu",
              "Thai-Hoa Nguyen",
              "Genta Indra Winata",
              "Edoardo M. Ponti",
              "Hanchen Li",
              "Kaustubh Dhole",
              "Jongee Park",
              "Dario Abbondanza",
              "Yuanli Wang",
              "Anupam Nayak",
              "Diogo M. Caetano",
              "Antonio A. W. L. Wong",
              "Maria del Rio-Chanona",
              "D\u00e1niel Kondor",
              "Pieter Francois",
              "Ed Chalstrey",
              "Jakob Zsambok",
              "Dan Hoyer",
              "Jenny Reddish",
              "Jakob Hauser",
              "Francisco-Javier Rodrigo-Gin\u00e9s",
              "Suchandra Datta",
              "Maxwell Shepherd",
              "Thom Kamphuis",
              "Qizheng Zhang",
              "Hyunjun Kim",
              "Ruiji Sun",
              "Jianzhu Yao",
              "Franck Dernoncourt",
              "Satyapriya Krishna",
              "Sina Rismanchian",
              "Bonan Pu",
              "Francesco Pinto",
              "Yingheng Wang",
              "Kumar Shridhar",
              "Kalon J. Overholt",
              "Glib Briia",
              "Hieu Nguyen",
              "David",
              "Soler Bartomeu",
              "Tony CY Pang",
              "Adam Wecker",
              "Yifan Xiong",
              "Fanfei Li",
              "Lukas S. Huber",
              "Joshua Jaeger",
              "Romano De Maddalena",
              "Xing Han L\u00f9",
              "Yuhui Zhang",
              "Claas Beger",
              "Patrick Tser Jern Kon",
              "Sean Li",
              "Vivek Sanker",
              "Ming Yin",
              "Yihao Liang",
              "Xinlu Zhang",
              "Ankit Agrawal",
              "Li S. Yifei",
              "Zechen Zhang",
              "Mu Cai",
              "Yasin Sonmez",
              "Costin Cozianu",
              "Changhao Li",
              "Alex Slen",
              "Shoubin Yu",
              "Hyun Kyu Park",
              "Gabriele Sarti",
              "Marcin Bria\u0144ski",
              "Alessandro Stolfo",
              "Truong An Nguyen",
              "Mike Zhang",
              "Yotam Perlitz",
              "Jose Hernandez-Orallo",
              "Runjia Li",
              "Amin Shabani",
              "Felix Juefei-Xu",
              "Shikhar Dhingra",
              "Orr Zohar",
              "My Chiffon Nguyen",
              "Alexander Pondaven",
              "Abdurrahim Yilmaz",
              "Xuandong Zhao",
              "Chuanyang Jin",
              "Muyan Jiang",
              "Stefan Todoran",
              "Xinyao Han",
              "Jules Kreuer",
              "Brian Rabern",
              "Anna Plassart",
              "Martino Maggetti",
              "Luther Yap",
              "Robert Geirhos",
              "Jonathon Kean",
              "Dingsu Wang",
              "Sina Mollaei",
              "Chenkai Sun",
              "Yifan Yin",
              "Shiqi Wang",
              "Rui Li",
              "Yaowen Chang",
              "Anjiang Wei",
              "Alice Bizeul",
              "Xiaohan Wang",
              "Alexandre Oliveira Arrais",
              "Kushin Mukherjee",
              "Jorge Chamorro-Padial",
              "Jiachen Liu",
              "Xingyu Qu",
              "Junyi Guan",
              "Adam Bouyamourn",
              "Shuyu Wu",
              "Martyna Plomecka",
              "Junda Chen",
              "Mengze Tang",
              "Jiaqi Deng",
              "Shreyas Subramanian",
              "Haocheng Xi",
              "Haoxuan Chen",
              "Weizhi Zhang",
              "Yinuo Ren",
              "Haoqin Tu",
              "Sejong Kim",
              "Yushun Chen",
              "Sara Vera Marjanovi\u0107",
              "Junwoo Ha",
              "Grzegorz Luczyna",
              "Jeff J. Ma",
              "Zewen Shen",
              "Dawn Song",
              "Cedegao E. Zhang",
              "Zhun Wang",
              "Ga\u00ebl Gendron",
              "Yunze Xiao",
              "Leo Smucker",
              "Erica Weng",
              "Kwok Hao Lee",
              "Zhe Ye",
              "Stefano Ermon",
              "Ignacio D. Lopez-Miguel",
              "Theo Knights",
              "Anthony Gitter",
              "Namkyu Park",
              "Boyi Wei",
              "Hongzheng Chen",
              "Kunal Pai",
              "Ahmed Elkhanany",
              "Han Lin",
              "Philipp D. Siedler",
              "Jichao Fang",
              "Ritwik Mishra",
              "K\u00e1roly Zsolnai-Feh\u00e9r",
              "Xilin Jiang",
              "Shadab Khan",
              "Jun Yuan",
              "Rishab Kumar Jain",
              "Xi Lin",
              "Mike Peterson",
              "Zhe Wang",
              "Aditya Malusare",
              "Maosen Tang",
              "Isha Gupta",
              "Ivan Fosin",
              "Timothy Kang",
              "Barbara Dworakowska",
              "Kazuki Matsumoto",
              "Guangyao Zheng",
              "Gerben Sewuster",
              "Jorge Pretel Villanueva",
              "Ivan Rannev",
              "Igor Chernyavsky",
              "Jiale Chen",
              "Deepayan Banik",
              "Ben Racz",
              "Wenchao Dong",
              "Jianxin Wang",
              "Laila Bashmal",
              "Duarte V. Gon\u00e7alves",
              "Wei Hu",
              "Kaushik Bar",
              "Ondrej Bohdal",
              "Atharv Singh Patlan",
              "Shehzaad Dhuliawala",
              "Caroline Geirhos",
              "Julien Wist",
              "Yuval Kansal",
              "Bingsen Chen",
              "Kutay Tire",
              "Atak Talay Y\u00fccel",
              "Brandon Christof",
              "Veerupaksh Singla",
              "Zijian Song",
              "Sanxing Chen",
              "Jiaxin Ge",
              "Kaustubh Ponkshe",
              "Isaac Park",
              "Tianneng Shi",
              "Martin Q. Ma",
              "Joshua Mak",
              "Sherwin Lai",
              "Antoine Moulin",
              "Zhuo Cheng",
              "Zhanda Zhu",
              "Ziyi Zhang",
              "Vaidehi Patil",
              "Ketan Jha",
              "Qiutong Men",
              "Jiaxuan Wu",
              "Tianchi Zhang",
              "Bruno Hebling Vieira",
              "Alham Fikri Aji",
              "Jae-Won Chung",
              "Mohammed Mahfoud",
              "Ha Thi Hoang",
              "Marc Sperzel",
              "Wei Hao",
              "Kristof Meding",
              "Sihan Xu",
              "Vassilis Kostakos",
              "Davide Manini",
              "Yueying Liu",
              "Christopher Toukmaji",
              "Jay Paek",
              "Eunmi Yu",
              "Arif Engin Demircali",
              "Zhiyi Sun",
              "Ivan Dewerpe",
              "Hongsen Qin",
              "Roman Pflugfelder",
              "James Bailey",
              "Johnathan Morris",
              "Ville Heilala",
              "Sybille Rosset",
              "Zishun Yu",
              "Peter E. Chen",
              "Woongyeong Yeo",
              "Eeshaan Jain",
              "Ryan Yang",
              "Sreekar Chigurupati",
              "Julia Chernyavsky",
              "Sai Prajwal Reddy",
              "Subhashini Venugopalan",
              "Hunar Batra",
              "Core Francisco Park",
              "Hieu Tran",
              "Guilherme Maximiano",
              "Genghan Zhang",
              "Yizhuo Liang",
              "Hu Shiyu",
              "Rongwu Xu",
              "Rui Pan",
              "Siddharth Suresh",
              "Ziqi Liu",
              "Samaksh Gulati",
              "Songyang Zhang",
              "Peter Turchin",
              "Christopher W. Bartlett",
              "Christopher R. Scotese",
              "Phuong M. Cao",
              "Aakaash Nattanmai",
              "Gordon McKellips",
              "Anish Cheraku",
              "Asim Suhail",
              "Ethan Luo",
              "Marvin Deng",
              "Jason Luo",
              "Ashley Zhang",
              "Kavin Jindel",
              "Jay Paek",
              "Kasper Halevy",
              "Allen Baranov",
              "Michael Liu",
              "Advaith Avadhanam",
              "David Zhang",
              "Vincent Cheng",
              "Brad Ma",
              "Evan Fu",
              "Liam Do",
              "Joshua Lass",
              "Hubert Yang",
              "Surya Sunkari",
              "Vishruth Bharath",
              "Violet Ai",
              "James Leung",
              "Rishit Agrawal",
              "Alan Zhou",
              "Kevin Chen",
              "Tejas Kalpathi",
              "Ziqi Xu",
              "Gavin Wang",
              "Tyler Xiao",
              "Erik Maung",
              "Sam Lee",
              "Ryan Yang",
              "Roy Yue",
              "Ben Zhao",
              "Julia Yoon",
              "Sunny Sun",
              "Aryan Singh",
              "Ethan Luo",
              "Clark Peng",
              "Tyler Osbey",
              "Taozhi Wang",
              "Daryl Echeazu",
              "Hubert Yang",
              "Timothy Wu",
              "Spandan Patel",
              "Vidhi Kulkarni",
              "Vijaykaarti Sundarapandiyan",
              "Ashley Zhang",
              "Andrew Le",
              "Zafir Nasim",
              "Srikar Yalam",
              "Ritesh Kasamsetty",
              "Soham Samal",
              "Hubert Yang",
              "David Sun",
              "Nihar Shah",
              "Abhijeet Saha",
              "Alex Zhang",
              "Leon Nguyen",
              "Laasya Nagumalli",
              "Kaixin Wang",
              "Alan Zhou",
              "Aidan Wu",
              "Jason Luo",
              "Anwith Telluri",
              "Summer Yue",
              "Alexandr Wang",
              "Dan Hendrycks"
            ],
            "organization": null,
            "date": "2025-01-24T05:27:46Z",
            "url": "https://arxiv.org/abs/2501.14249",
            "description": "Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90\\% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. HLE consists of 2,500 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading. Each question has a known solution that is unambiguous and easily verifiable, but cannot be quickly answered via internet retrieval. State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions. To inform research and policymaking upon a clear understanding of model capabilities, we publicly release HLE at https://lastexam.ai.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 173,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- 2500 questions: multimodal, many subjects, multiple-choice + short-answer\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- 2500 questions: multimodal, many subjects, multiple-choice + short-answer",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 174,
          "function_name": "knowledge_benchmarks",
          "code": "image(\"images/hle-examples.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/hle-examples.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 175,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Awarded $500K prize pool + co-authorship to question creators\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Awarded $500K prize pool + co-authorship to question creators",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 176,
          "function_name": "knowledge_benchmarks",
          "code": "text(\"- Filtered by frontier LLMs, multiple stages of review\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Filtered by frontier LLMs, multiple stages of review",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 177,
          "function_name": "knowledge_benchmarks",
          "code": "image(\"images/hle-pipeline.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/hle-pipeline.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 178,
          "function_name": "knowledge_benchmarks",
          "code": "image(\"images/hle-results.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/hle-results.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 179,
          "function_name": "knowledge_benchmarks",
          "code": "link(title=\"[latest leaderboard]\", url=\"https://agi.safe.ai/\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[latest leaderboard]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://agi.safe.ai/",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 13,
          "function_name": "main",
          "code": "knowledge_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 182,
          "function_name": "instruction_following_benchmarks",
          "code": "def instruction_following_benchmarks():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 183,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"So far, we've been evaluating on fairly structured tasks.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "So far, we've been evaluating on fairly structured tasks.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 184,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"Instruction following (as popularized by ChatGPT): just follow the instructions.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Instruction following (as popularized by ChatGPT): just follow the instructions.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 185,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"Challenge: how to evaluate an open-ended response?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Challenge: how to evaluate an open-ended response?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 187,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"### Chatbot Arena\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Chatbot Arena",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 188,
          "function_name": "instruction_following_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2403.04132\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference",
            "authors": [
              "Wei-Lin Chiang",
              "Lianmin Zheng",
              "Ying Sheng",
              "Anastasios Nikolas Angelopoulos",
              "Tianle Li",
              "Dacheng Li",
              "Hao Zhang",
              "Banghua Zhu",
              "Michael Jordan",
              "Joseph E. Gonzalez",
              "Ion Stoica"
            ],
            "organization": null,
            "date": "2024-03-07T01:22:38Z",
            "url": "https://arxiv.org/abs/2403.04132",
            "description": "Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowdsourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. Our demo is publicly available at \\url{https://chat.lmsys.org}.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 189,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"How it works:\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "How it works:",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 190,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Random person from the Internet types in prompt\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Random person from the Internet types in prompt",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 191,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- They get response from two random (anonymized) models\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- They get response from two random (anonymized) models",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 192,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- They rate which one is better\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- They rate which one is better",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 193,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- ELO scores are computed based on the pairwise comparisons\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- ELO scores are computed based on the pairwise comparisons",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 194,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Features: live (not static) inputs, can accomodate new models\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Features: live (not static) inputs, can accomodate new models",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 195,
          "function_name": "instruction_following_benchmarks",
          "code": "image(\"images/chatbot-arena-leaderboard.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/chatbot-arena-leaderboard.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 196,
          "function_name": "instruction_following_benchmarks",
          "code": "link(title=\"[Chatbot Arena]\", url=\"https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[Chatbot Arena]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 198,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"### Instruction-Following Eval (IFEval)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Instruction-Following Eval (IFEval)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 199,
          "function_name": "instruction_following_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2311.07911\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Instruction-Following Evaluation for Large Language Models",
            "authors": [
              "Jeffrey Zhou",
              "Tianjian Lu",
              "Swaroop Mishra",
              "Siddhartha Brahma",
              "Sujoy Basu",
              "Yi Luan",
              "Denny Zhou",
              "Le Hou"
            ],
            "organization": null,
            "date": "2023-11-14T05:13:55Z",
            "url": "https://arxiv.org/abs/2311.07911",
            "description": "One core capability of Large Language Models (LLMs) is to follow natural language instructions. However, the evaluation of such abilities is not standardized: Human evaluations are expensive, slow, and not objectively reproducible, while LLM-based auto-evaluation is potentially biased or limited by the ability of the evaluator LLM. To overcome these issues, we introduce Instruction-Following Eval (IFEval) for large language models. IFEval is a straightforward and easy-to-reproduce evaluation benchmark. It focuses on a set of \"verifiable instructions\" such as \"write in more than 400 words\" and \"mention the keyword of AI at least 3 times\". We identified 25 types of those verifiable instructions and constructed around 500 prompts, with each prompt containing one or more verifiable instructions. We show evaluation results of two widely available LLMs on the market. Our code and data can be found at https://github.com/google-research/google-research/tree/master/instruction_following_eval",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 200,
          "function_name": "instruction_following_benchmarks",
          "code": "image(\"images/ifeval-categories.png\", width=600)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/ifeval-categories.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 201,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Add simple synthetic constraints to instructions\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Add simple synthetic constraints to instructions",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 202,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Constraints can be automatically verified, but not the semantics of the response\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Constraints can be automatically verified, but not the semantics of the response",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 203,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Fairly simple instructions, constraints are a bit artificial\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Fairly simple instructions, constraints are a bit artificial",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 204,
          "function_name": "instruction_following_benchmarks",
          "code": "link(title=\"[HELM IFEval for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/ifeval\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM IFEval for visualizing predictions]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/ifeval",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 206,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"### AlpacaEval\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### AlpacaEval",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 207,
          "function_name": "instruction_following_benchmarks",
          "code": "link(\"https://tatsu-lab.github.io/alpaca_eval/\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": null,
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://tatsu-lab.github.io/alpaca_eval/",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 208,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- 805 instructions from various sources\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- 805 instructions from various sources",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 209,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Metric: win rate against GPT-4 preview as judged by GPT-4 preview (potential bias)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Metric: win rate against GPT-4 preview as judged by GPT-4 preview (potential bias)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 210,
          "function_name": "instruction_following_benchmarks",
          "code": "image(\"images/alpacaeval-leaderboard.png\", width=600)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/alpacaeval-leaderboard.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 212,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"### WildBench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### WildBench",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 213,
          "function_name": "instruction_following_benchmarks",
          "code": "link(\"https://arxiv.org/pdf/2406.04770\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild",
            "authors": [
              "Bill Yuchen Lin",
              "Yuntian Deng",
              "Khyathi Chandu",
              "Faeze Brahman",
              "Abhilasha Ravichander",
              "Valentina Pyatkin",
              "Nouha Dziri",
              "Ronan Le Bras",
              "Yejin Choi"
            ],
            "organization": null,
            "date": "2024-06-07T09:15:44Z",
            "url": "https://arxiv.org/pdf/2406.04770",
            "description": "We introduce WildBench, an automated evaluation framework designed to benchmark large language models (LLMs) using challenging, real-world user queries. WildBench consists of 1,024 tasks carefully selected from over one million human-chatbot conversation logs. For automated evaluation with WildBench, we have developed two metrics, WB-Reward and WB-Score, which are computable using advanced LLMs such as GPT-4-turbo. WildBench evaluation uses task-specific checklists to evaluate model outputs systematically and provides structured explanations that justify the scores and comparisons, resulting in more reliable and interpretable automatic judgments. WB-Reward employs fine-grained pairwise comparisons between model responses, generating five potential outcomes: much better, slightly better, slightly worse, much worse, or a tie. Unlike previous evaluations that employed a single baseline model, we selected three baseline models at varying performance levels to ensure a comprehensive pairwise evaluation. Additionally, we propose a simple method to mitigate length bias, by converting outcomes of ``slightly better/worse'' to ``tie'' if the winner response exceeds the loser one by more than $K$ characters. WB-Score evaluates the quality of model outputs individually, making it a fast and cost-efficient evaluation metric. WildBench results demonstrate a strong correlation with the human-voted Elo ratings from Chatbot Arena on hard tasks. Specifically, WB-Reward achieves a Pearson correlation of 0.98 with top-ranking models. Additionally, WB-Score reaches 0.95, surpassing both ArenaHard's 0.91 and AlpacaEval2.0's 0.89 for length-controlled win rates, as well as the 0.87 for regular win rates.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 214,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Sourced 1024 examples from 1M human-chatbot conversations\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Sourced 1024 examples from 1M human-chatbot conversations",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 215,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Uses GPT-4 turbo as a judge with a checklist (like CoT for judging) + GPT-4 as a judge\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Uses GPT-4 turbo as a judge with a checklist (like CoT for judging) + GPT-4 as a judge",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 216,
          "function_name": "instruction_following_benchmarks",
          "code": "text(\"- Well-correlated (0.95) with Chatbot Arena (seems to be the de facto sanity check for benchmarks)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Well-correlated (0.95) with Chatbot Arena (seems to be the de facto sanity check for benchmarks)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 217,
          "function_name": "instruction_following_benchmarks",
          "code": "image(\"images/wildbench.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/wildbench.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 218,
          "function_name": "instruction_following_benchmarks",
          "code": "link(title=\"[HELM WildBench for visualizing predictions]\", url=\"https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/wildbench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM WildBench for visualizing predictions]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/capabilities/latest/#/leaderboard/wildbench",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 14,
          "function_name": "main",
          "code": "instruction_following_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 221,
          "function_name": "agent_benchmarks",
          "code": "def agent_benchmarks():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 222,
          "function_name": "agent_benchmarks",
          "code": "text(\"Consider tasks that require tool use (e.g., running code) and iterating over a period of time\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Consider tasks that require tool use (e.g., running code) and iterating over a period of time",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 223,
          "function_name": "agent_benchmarks",
          "code": "text(\"Agent = language model + agent scaffolding (logic for deciding how to use the LM)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Agent = language model + agent scaffolding (logic for deciding how to use the LM)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 225,
          "function_name": "agent_benchmarks",
          "code": "text(\"### SWEBench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### SWEBench",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 226,
          "function_name": "agent_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2310.06770\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?",
            "authors": [
              "Carlos E. Jimenez",
              "John Yang",
              "Alexander Wettig",
              "Shunyu Yao",
              "Kexin Pei",
              "Ofir Press",
              "Karthik Narasimhan"
            ],
            "organization": null,
            "date": "2023-10-10T16:47:29Z",
            "url": "https://arxiv.org/abs/2310.06770",
            "description": "Language models have outpaced our ability to evaluate them effectively, but for their future development it is essential to study the frontier of their capabilities. We find real-world software engineering to be a rich, sustainable, and challenging testbed for evaluating the next generation of language models. To this end, we introduce SWE-bench, an evaluation framework consisting of $2,294$ software engineering problems drawn from real GitHub issues and corresponding pull requests across $12$ popular Python repositories. Given a codebase along with a description of an issue to be resolved, a language model is tasked with editing the codebase to address the issue. Resolving issues in SWE-bench frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously, calling for models to interact with execution environments, process extremely long contexts and perform complex reasoning that goes far beyond traditional code generation tasks. Our evaluations show that both state-of-the-art proprietary models and our fine-tuned model SWE-Llama can resolve only the simplest issues. The best-performing model, Claude 2, is able to solve a mere $1.96$% of the issues. Advances on SWE-bench represent steps towards LMs that are more practical, intelligent, and autonomous.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 227,
          "function_name": "agent_benchmarks",
          "code": "text(\"- 2294 tasks across 12 Python repositories\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- 2294 tasks across 12 Python repositories",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 228,
          "function_name": "agent_benchmarks",
          "code": "text(\"- Given codebase + issue description, submit a PR\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Given codebase + issue description, submit a PR",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 229,
          "function_name": "agent_benchmarks",
          "code": "text(\"- Evaluation metric: unit tests\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Evaluation metric: unit tests",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 230,
          "function_name": "agent_benchmarks",
          "code": "image(\"images/swebench.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/swebench.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 232,
          "function_name": "agent_benchmarks",
          "code": "text(\"### CyBench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### CyBench",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 233,
          "function_name": "agent_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2408.08926\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models",
            "authors": [
              "Andy K. Zhang",
              "Neil Perry",
              "Riya Dulepet",
              "Joey Ji",
              "Celeste Menders",
              "Justin W. Lin",
              "Eliot Jones",
              "Gashon Hussein",
              "Samantha Liu",
              "Donovan Jasper",
              "Pura Peetathawatchai",
              "Ari Glenn",
              "Vikram Sivashankar",
              "Daniel Zamoshchin",
              "Leo Glikbarg",
              "Derek Askaryar",
              "Mike Yang",
              "Teddy Zhang",
              "Rishi Alluri",
              "Nathan Tran",
              "Rinnara Sangpisit",
              "Polycarpos Yiorkadjis",
              "Kenny Osele",
              "Gautham Raghupathi",
              "Dan Boneh",
              "Daniel E. Ho",
              "Percy Liang"
            ],
            "organization": null,
            "date": "2024-08-15T17:23:10Z",
            "url": "https://arxiv.org/abs/2408.08926",
            "description": "Language Model (LM) agents for cybersecurity that are capable of autonomously identifying vulnerabilities and executing exploits have potential to cause real-world impact. Policymakers, model providers, and researchers in the AI and cybersecurity communities are interested in quantifying the capabilities of such agents to help mitigate cyberrisk and investigate opportunities for penetration testing. Toward that end, we introduce Cybench, a framework for specifying cybersecurity tasks and evaluating agents on those tasks. We include 40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF competitions, chosen to be recent, meaningful, and spanning a wide range of difficulties. Each task includes its own description, starter files, and is initialized in an environment where an agent can execute commands and observe outputs. Since many tasks are beyond the capabilities of existing LM agents, we introduce subtasks for each task, which break down a task into intermediary steps for a more detailed evaluation. To evaluate agent capabilities, we construct a cybersecurity agent and evaluate 8 models: GPT-4o, OpenAI o1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct, Gemini 1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. For the top performing models (GPT-4o and Claude 3.5 Sonnet), we further investigate performance across 4 agent scaffolds (structed bash, action-only, pseudoterminal, and web search). Without subtask guidance, agents leveraging Claude 3.5 Sonnet, GPT-4o, OpenAI o1-preview, and Claude 3 Opus successfully solved complete tasks that took human teams up to 11 minutes to solve. In comparison, the most difficult task took human teams 24 hours and 54 minutes to solve. All code and data are publicly available at https://cybench.github.io.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 234,
          "function_name": "agent_benchmarks",
          "code": "text(\"- 40 Capture the Flag (CTF) tasks\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- 40 Capture the Flag (CTF) tasks",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 235,
          "function_name": "agent_benchmarks",
          "code": "text(\"- Use first-solve time as a measure of difficulty\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Use first-solve time as a measure of difficulty",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 236,
          "function_name": "agent_benchmarks",
          "code": "image(\"images/cybench.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/cybench.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 237,
          "function_name": "agent_benchmarks",
          "code": "image(\"images/cybench-agent.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/cybench-agent.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 238,
          "function_name": "agent_benchmarks",
          "code": "image(\"images/cybench-results.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/cybench-results.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 240,
          "function_name": "agent_benchmarks",
          "code": "text(\"### MLEBench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### MLEBench",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 241,
          "function_name": "agent_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2410.07095\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
            "authors": [
              "Jun Shern Chan",
              "Neil Chowdhury",
              "Oliver Jaffe",
              "James Aung",
              "Dane Sherburn",
              "Evan Mays",
              "Giulio Starace",
              "Kevin Liu",
              "Leon Maksin",
              "Tejal Patwardhan",
              "Lilian Weng",
              "Aleksander M\u0105dry"
            ],
            "organization": null,
            "date": "2024-10-09T17:34:27Z",
            "url": "https://arxiv.org/abs/2410.07095",
            "description": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering. To this end, we curate 75 ML engineering-related competitions from Kaggle, creating a diverse set of challenging tasks that test real-world ML engineering skills such as training models, preparing datasets, and running experiments. We establish human baselines for each competition using Kaggle's publicly available leaderboards. We use open-source agent scaffolds to evaluate several frontier language models on our benchmark, finding that the best-performing setup--OpenAI's o1-preview with AIDE scaffolding--achieves at least the level of a Kaggle bronze medal in 16.9% of competitions. In addition to our main results, we investigate various forms of resource scaling for AI agents and the impact of contamination from pre-training. We open-source our benchmark code (github.com/openai/mle-bench/) to facilitate future research in understanding the ML engineering capabilities of AI agents.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 242,
          "function_name": "agent_benchmarks",
          "code": "text(\"- 75 Kaggle competitions (require training models, processing data, etc.)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- 75 Kaggle competitions (require training models, processing data, etc.)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 243,
          "function_name": "agent_benchmarks",
          "code": "image(\"images/mlebench.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/mlebench.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 244,
          "function_name": "agent_benchmarks",
          "code": "image(\"images/mlebench-results.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/mlebench-results.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 15,
          "function_name": "main",
          "code": "agent_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 247,
          "function_name": "pure_reasoning_benchmarks",
          "code": "def pure_reasoning_benchmarks():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 248,
          "function_name": "pure_reasoning_benchmarks",
          "code": "text(\"All of the tasks so far require linguistic and world knowledge\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "All of the tasks so far require linguistic and world knowledge",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 249,
          "function_name": "pure_reasoning_benchmarks",
          "code": "text(\"Can we isolate reasoning from knowledge?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Can we isolate reasoning from knowledge?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 250,
          "function_name": "pure_reasoning_benchmarks",
          "code": "text(\"Arguably, reasoning captures a more pure form of intelligence (isn't just about memorizing facts)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Arguably, reasoning captures a more pure form of intelligence (isn't just about memorizing facts)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 252,
          "function_name": "pure_reasoning_benchmarks",
          "code": "link(title=\"ARC-AGI\", url=\"https://arcprize.org/arc-agi\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "ARC-AGI",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://arcprize.org/arc-agi",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 253,
          "function_name": "pure_reasoning_benchmarks",
          "code": "text(\"Introduced in 2019 by Francois Chollet\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Introduced in 2019 by Francois Chollet",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 255,
          "function_name": "pure_reasoning_benchmarks",
          "code": "text(\"ARC-AGI-1\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "ARC-AGI-1",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 256,
          "function_name": "pure_reasoning_benchmarks",
          "code": "image(\"https://arcprize.org/media/images/arc-task-grids.jpg\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-d1a33e9159cfdb77197551bbbecc6a76-https_arcprize_org_media_images_arc-task-grids_jpg",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 257,
          "function_name": "pure_reasoning_benchmarks",
          "code": "image(\"https://arcprize.org/media/images/oseriesleaderboard.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-cb3ca481cdf3a72e48fabc7953f49867-https_arcprize_org_media_images_oseriesleaderboard_png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 259,
          "function_name": "pure_reasoning_benchmarks",
          "code": "text(\"ARC-AGI-2: harder\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "ARC-AGI-2: harder",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 260,
          "function_name": "pure_reasoning_benchmarks",
          "code": "image(\"https://arcprize.org/media/images/blog/arc-agi-2-unsolved-1.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-a0338c9fb72d1163cfc8ac66fea4e4ed-https_arcprize_org_media_images_blog_arc-agi-2-unsolved-1_png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 16,
          "function_name": "main",
          "code": "pure_reasoning_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 263,
          "function_name": "safety_benchmarks",
          "code": "def safety_benchmarks():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 264,
          "function_name": "safety_benchmarks",
          "code": "image(\"https://www.team-bhp.com/forum/attachments/road-safety/2173645d1625144681-will-crash-test-rating-change-if-higher-variant-chosen-images-30.jpeg\", width=500)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-a375cd28c372458baf4135c081a1ce8b-https_www_team-bhp_com_forum_attachments_road-safety_2173645d1625144681-will-crash-test-rating-change-if-higher-variant-chosen-images-30_jpeg",
          "style": {
            "width": 500
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 265,
          "function_name": "safety_benchmarks",
          "code": "text(\"What does safety mean for AI?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "What does safety mean for AI?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 267,
          "function_name": "safety_benchmarks",
          "code": "link(title=\"[HELM safety: curated set of benchmarks]\", url=\"https://crfm.stanford.edu/helm/safety/latest/#/leaderboard\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM safety: curated set of benchmarks]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/safety/latest/#/leaderboard",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 269,
          "function_name": "safety_benchmarks",
          "code": "text(\"### HarmBench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### HarmBench",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 270,
          "function_name": "safety_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2402.04249\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal",
            "authors": [
              "Mantas Mazeika",
              "Long Phan",
              "Xuwang Yin",
              "Andy Zou",
              "Zifan Wang",
              "Norman Mu",
              "Elham Sakhaee",
              "Nathaniel Li",
              "Steven Basart",
              "Bo Li",
              "David Forsyth",
              "Dan Hendrycks"
            ],
            "organization": null,
            "date": "2024-02-06T18:59:08Z",
            "url": "https://arxiv.org/abs/2402.04249",
            "description": "Automated red teaming holds substantial promise for uncovering and mitigating the risks associated with the malicious use of large language models (LLMs), yet the field lacks a standardized evaluation framework to rigorously assess new methods. To address this issue, we introduce HarmBench, a standardized evaluation framework for automated red teaming. We identify several desirable properties previously unaccounted for in red teaming evaluations and systematically design HarmBench to meet these criteria. Using HarmBench, we conduct a large-scale comparison of 18 red teaming methods and 33 target LLMs and defenses, yielding novel insights. We also introduce a highly efficient adversarial training method that greatly enhances LLM robustness across a wide range of attacks, demonstrating how HarmBench enables codevelopment of attacks and defenses. We open source HarmBench at https://github.com/centerforaisafety/HarmBench.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 271,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Based on 510 harmful behaviors that violate laws or norms\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Based on 510 harmful behaviors that violate laws or norms",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 272,
          "function_name": "safety_benchmarks",
          "code": "link(title=\"[HarmBench on HELM]\", url=\"https://crfm.stanford.edu/helm/safety/latest/#/leaderboard/harm_bench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HarmBench on HELM]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/safety/latest/#/leaderboard/harm_bench",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 273,
          "function_name": "safety_benchmarks",
          "code": "link(title=\"[Example of safety failure]\", url=\"https://crfm.stanford.edu/helm/safety/latest/#/runs/harm_bench:model=anthropic_claude-3-7-sonnet-20250219?instancesPage=4\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[Example of safety failure]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/safety/latest/#/runs/harm_bench:model=anthropic_claude-3-7-sonnet-20250219?instancesPage=4",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 275,
          "function_name": "safety_benchmarks",
          "code": "text(\"### AIR-Bench\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### AIR-Bench",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 276,
          "function_name": "safety_benchmarks",
          "code": "link(\"https://arxiv.org/abs/2407.17436\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "AIR-Bench 2024: A Safety Benchmark Based on Risk Categories from Regulations and Policies",
            "authors": [
              "Yi Zeng",
              "Yu Yang",
              "Andy Zhou",
              "Jeffrey Ziwei Tan",
              "Yuheng Tu",
              "Yifan Mai",
              "Kevin Klyman",
              "Minzhou Pan",
              "Ruoxi Jia",
              "Dawn Song",
              "Percy Liang",
              "Bo Li"
            ],
            "organization": null,
            "date": "2024-07-11T21:16:48Z",
            "url": "https://arxiv.org/abs/2407.17436",
            "description": "Foundation models (FMs) provide societal benefits but also amplify risks. Governments, companies, and researchers have proposed regulatory frameworks, acceptable use policies, and safety benchmarks in response. However, existing public benchmarks often define safety categories based on previous literature, intuitions, or common sense, leading to disjointed sets of categories for risks specified in recent regulations and policies, which makes it challenging to evaluate and compare FMs across these benchmarks. To bridge this gap, we introduce AIR-Bench 2024, the first AI safety benchmark aligned with emerging government regulations and company policies, following the regulation-based safety categories grounded in our AI risks study, AIR 2024. AIR 2024 decomposes 8 government regulations and 16 company policies into a four-tiered safety taxonomy with 314 granular risk categories in the lowest tier. AIR-Bench 2024 contains 5,694 diverse prompts spanning these categories, with manual curation and human auditing to ensure quality. We evaluate leading language models on AIR-Bench 2024, uncovering insights into their alignment with specified safety concerns. By bridging the gap between public benchmarks and practical AI risks, AIR-Bench 2024 provides a foundation for assessing model safety across jurisdictions, fostering the development of safer and more responsible AI systems.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 277,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Based on regulatory frameworks and company policies\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Based on regulatory frameworks and company policies",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 278,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Taxonomized into 314 risk categories, 5694 prompts\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Taxonomized into 314 risk categories, 5694 prompts",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 279,
          "function_name": "safety_benchmarks",
          "code": "image(\"https://crfm.stanford.edu/helm/assets/air-overview-d2e6c49f.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-0195288103aa687af7faedeaca538056-https_crfm_stanford_edu_helm_assets_air-overview-d2e6c49f_png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 280,
          "function_name": "safety_benchmarks",
          "code": "link(title=\"[HELM AIR-Bench]\", url=\"https://crfm.stanford.edu/helm/air-bench/latest/#/leaderboard\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[HELM AIR-Bench]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/air-bench/latest/#/leaderboard",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 282,
          "function_name": "safety_benchmarks",
          "code": "text(\"### Jailbreaking\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Jailbreaking",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 283,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Language models are trained to refuse harmful instructions\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Language models are trained to refuse harmful instructions",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 284,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Greedy Coordinate Gradient (GCG) automatically optimizes prompts to bypass safety \"), link(\"https://arxiv.org/pdf/2307.15043\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Greedy Coordinate Gradient (GCG) automatically optimizes prompts to bypass safety ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models",
            "authors": [
              "Andy Zou",
              "Zifan Wang",
              "Nicholas Carlini",
              "Milad Nasr",
              "J. Zico Kolter",
              "Matt Fredrikson"
            ],
            "organization": null,
            "date": "2023-07-27T17:49:12Z",
            "url": "https://arxiv.org/pdf/2307.15043",
            "description": "Because \"out-of-the-box\" large language models are capable of generating a great deal of objectionable content, recent work has focused on aligning these models in an attempt to prevent undesirable generation. While there has been some success at circumventing these measures -- so-called \"jailbreaks\" against LLMs -- these attacks have required significant human ingenuity and are brittle in practice. In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors. Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer). However, instead of relying on manual engineering, our approach automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past automatic prompt generation methods. Surprisingly, we find that the adversarial prompts generated by our approach are quite transferable, including to black-box, publicly released LLMs. Specifically, we train an adversarial attack suffix on multiple prompts (i.e., queries asking for many different types of objectionable content), as well as multiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting attack suffix is able to induce objectionable content in the public interfaces to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat, Pythia, Falcon, and others. In total, this work significantly advances the state-of-the-art in adversarial attacks against aligned language models, raising important questions about how such systems can be prevented from producing objectionable information. Code is available at github.com/llm-attacks/llm-attacks.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 285,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Transfers from open-weight models (Llama) to closed models (GPT-4)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Transfers from open-weight models (Llama) to closed models (GPT-4)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 286,
          "function_name": "safety_benchmarks",
          "code": "image(\"images/gcg-examples.png\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/gcg-examples.png",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 288,
          "function_name": "safety_benchmarks",
          "code": "text(\"### Pre-deployment testing\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Pre-deployment testing",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 289,
          "function_name": "safety_benchmarks",
          "code": "text(\"- US Safety Institute + UK AI Safety Institute working together\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- US Safety Institute + UK AI Safety Institute working together",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 290,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Company gives safety institutes access to model before release (currently voluntary)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Company gives safety institutes access to model before release (currently voluntary)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 291,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Safety institutes run evaluations and produce a report to company\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Safety institutes run evaluations and produce a report to company",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 292,
          "function_name": "safety_benchmarks",
          "code": "link(title=\"[report]\", url=\"https://www.nist.gov/system/files/documents/2024/12/18/US_UK_AI%20Safety%20Institute_%20December_Publication-OpenAIo1.pdf\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[report]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://www.nist.gov/system/files/documents/2024/12/18/US_UK_AI%20Safety%20Institute_%20December_Publication-OpenAIo1.pdf",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 294,
          "function_name": "safety_benchmarks",
          "code": "text(\"### But what is safety?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### But what is safety?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 295,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Many aspects of safety are strongly contextual (politics, law, social norms - which vary across countries)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Many aspects of safety are strongly contextual (politics, law, social norms - which vary across countries)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 296,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Naively, one might think safety is about refusal and is at odds with capability, but there's more...\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Naively, one might think safety is about refusal and is at odds with capability, but there's more...",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 297,
          "function_name": "safety_benchmarks",
          "code": "text(\"- Hallucinations in a medical setting makes systems more capable and more safe\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Hallucinations in a medical setting makes systems more capable and more safe",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 299,
          "function_name": "safety_benchmarks",
          "code": "text(\"Two aspects of a model that reduce safety: capabilities + propensity\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Two aspects of a model that reduce safety: capabilities + propensity",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 300,
          "function_name": "safety_benchmarks",
          "code": "text(\"- A system could be capable of doing something, but refuse to do it\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- A system could be capable of doing something, but refuse to do it",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 301,
          "function_name": "safety_benchmarks",
          "code": "text(\"- For API models, propensity matters\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- For API models, propensity matters",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 302,
          "function_name": "safety_benchmarks",
          "code": "text(\"- For open weight models, capability matters (since can easily fine-tune safety away)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- For open weight models, capability matters (since can easily fine-tune safety away)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 304,
          "function_name": "safety_benchmarks",
          "code": "text(\"**Dual-use**: capable cybersecurity agents (do well on CyBench) can be used to hack into a system or to do penetration testing\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "**Dual-use**: capable cybersecurity agents (do well on CyBench) can be used to hack into a system or to do penetration testing",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 305,
          "function_name": "safety_benchmarks",
          "code": "text(\"CyBench is used by the safety institute as a safety evaluation, but is it really a capability evaluation?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "CyBench is used by the safety institute as a safety evaluation, but is it really a capability evaluation?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 17,
          "function_name": "main",
          "code": "safety_benchmarks()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 308,
          "function_name": "realism",
          "code": "def realism():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 309,
          "function_name": "realism",
          "code": "text(\"Language models are used heavily in practice:\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Language models are used heavily in practice:",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 310,
          "function_name": "realism",
          "code": "image(\"images/openai-100b-tokens.png\", width=600); link(title=\" [tweet]\", url=\"https://x.com/sama/status/1756089361609981993\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/openai-100b-tokens.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": " [tweet]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://x.com/sama/status/1756089361609981993",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 311,
          "function_name": "realism",
          "code": "image(\"images/cursor-1b-lines.png\", width=600); link(title=\" [tweet]\", url=\"https://x.com/amanrsanger/status/1916968123535880684\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/cursor-1b-lines.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": " [tweet]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://x.com/amanrsanger/status/1916968123535880684",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 313,
          "function_name": "realism",
          "code": "text(\"However, most existing benchmarks (e.g., MMLU) are far away from real-world use.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "However, most existing benchmarks (e.g., MMLU) are far away from real-world use.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 314,
          "function_name": "realism",
          "code": "text(\"Live traffic from real people contain garbage, that's not always what we want either.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Live traffic from real people contain garbage, that's not always what we want either.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 316,
          "function_name": "realism",
          "code": "text(\"Two types of prompts:\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Two types of prompts:",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 317,
          "function_name": "realism",
          "code": "text(\"1. Quizzing: User knows the answer and trying to test the system (think standardized exams).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "1. Quizzing: User knows the answer and trying to test the system (think standardized exams).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 318,
          "function_name": "realism",
          "code": "text(\"2. Asking: User doesn't know the answer is trying to use the system to get it.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "2. Asking: User doesn't know the answer is trying to use the system to get it.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 319,
          "function_name": "realism",
          "code": "text(\"Asking is more realistic and produces value for the user.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Asking is more realistic and produces value for the user.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 321,
          "function_name": "realism",
          "code": "text(\"### Clio (Anthropic)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Clio (Anthropic)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 322,
          "function_name": "realism",
          "code": "link(\"https://arxiv.org/abs/2412.13678\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Clio: Privacy-Preserving Insights into Real-World AI Use",
            "authors": [
              "Alex Tamkin",
              "Miles McCain",
              "Kunal Handa",
              "Esin Durmus",
              "Liane Lovitt",
              "Ankur Rathi",
              "Saffron Huang",
              "Alfred Mountfield",
              "Jerry Hong",
              "Stuart Ritchie",
              "Michael Stern",
              "Brian Clarke",
              "Landon Goldberg",
              "Theodore R. Sumers",
              "Jared Mueller",
              "William McEachen",
              "Wes Mitchell",
              "Shan Carter",
              "Jack Clark",
              "Jared Kaplan",
              "Deep Ganguli"
            ],
            "organization": null,
            "date": "2024-12-18T10:05:43Z",
            "url": "https://arxiv.org/abs/2412.13678",
            "description": "How are AI assistants being used in the real world? While model providers in theory have a window into this impact via their users' data, both privacy concerns and practical challenges have made analyzing this data difficult. To address these issues, we present Clio (Claude insights and observations), a privacy-preserving platform that uses AI assistants themselves to analyze and surface aggregated usage patterns across millions of conversations, without the need for human reviewers to read raw conversations. We validate this can be done with a high degree of accuracy and privacy by conducting extensive evaluations. We demonstrate Clio's usefulness in two broad ways. First, we share insights about how models are being used in the real world from one million Claude.ai Free and Pro conversations, ranging from providing advice on hairstyles to providing guidance on Git operations and concepts. We also identify the most common high-level use cases on Claude.ai (coding, writing, and research tasks) as well as patterns that differ across languages (e.g., conversations in Japanese discuss elder care and aging populations at higher-than-typical rates). Second, we use Clio to make our systems safer by identifying coordinated attempts to abuse our systems, monitoring for unknown unknowns during critical periods like launches of new capabilities or major world events, and improving our existing monitoring systems. We also discuss the limitations of our approach, as well as risks and ethical concerns. By enabling analysis of real-world AI usage, Clio provides a scalable platform for empirically grounded AI safety and governance.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 323,
          "function_name": "realism",
          "code": "text(\"- Use language models to analyze real user data\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Use language models to analyze real user data",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 324,
          "function_name": "realism",
          "code": "text(\"- Share general patterns of what people are asking\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Share general patterns of what people are asking",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 325,
          "function_name": "realism",
          "code": "image(\"images/clio-table4.png\", width=700)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/clio-table4.png",
          "style": {
            "width": 700
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 327,
          "function_name": "realism",
          "code": "text(\"### MedHELM\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### MedHELM",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 328,
          "function_name": "realism",
          "code": "link(\"https://arxiv.org/abs/2412.13678\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Clio: Privacy-Preserving Insights into Real-World AI Use",
            "authors": [
              "Alex Tamkin",
              "Miles McCain",
              "Kunal Handa",
              "Esin Durmus",
              "Liane Lovitt",
              "Ankur Rathi",
              "Saffron Huang",
              "Alfred Mountfield",
              "Jerry Hong",
              "Stuart Ritchie",
              "Michael Stern",
              "Brian Clarke",
              "Landon Goldberg",
              "Theodore R. Sumers",
              "Jared Mueller",
              "William McEachen",
              "Wes Mitchell",
              "Shan Carter",
              "Jack Clark",
              "Jared Kaplan",
              "Deep Ganguli"
            ],
            "organization": null,
            "date": "2024-12-18T10:05:43Z",
            "url": "https://arxiv.org/abs/2412.13678",
            "description": "How are AI assistants being used in the real world? While model providers in theory have a window into this impact via their users' data, both privacy concerns and practical challenges have made analyzing this data difficult. To address these issues, we present Clio (Claude insights and observations), a privacy-preserving platform that uses AI assistants themselves to analyze and surface aggregated usage patterns across millions of conversations, without the need for human reviewers to read raw conversations. We validate this can be done with a high degree of accuracy and privacy by conducting extensive evaluations. We demonstrate Clio's usefulness in two broad ways. First, we share insights about how models are being used in the real world from one million Claude.ai Free and Pro conversations, ranging from providing advice on hairstyles to providing guidance on Git operations and concepts. We also identify the most common high-level use cases on Claude.ai (coding, writing, and research tasks) as well as patterns that differ across languages (e.g., conversations in Japanese discuss elder care and aging populations at higher-than-typical rates). Second, we use Clio to make our systems safer by identifying coordinated attempts to abuse our systems, monitoring for unknown unknowns during critical periods like launches of new capabilities or major world events, and improving our existing monitoring systems. We also discuss the limitations of our approach, as well as risks and ethical concerns. By enabling analysis of real-world AI usage, Clio provides a scalable platform for empirically grounded AI safety and governance.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 329,
          "function_name": "realism",
          "code": "text(\"- Previous medical benchmarks were based on standardized exams\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Previous medical benchmarks were based on standardized exams",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 330,
          "function_name": "realism",
          "code": "text(\"- 121 clinical tasks sourced from 29 clinicians, mixture of private and public datasets\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- 121 clinical tasks sourced from 29 clinicians, mixture of private and public datasets",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 331,
          "function_name": "realism",
          "code": "image(\"https://crfm.stanford.edu/helm/assets/medhelm-overview-3ddfcd65.png\", width=700)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-dd0716ead405df19ab6676c1baa73632-https_crfm_stanford_edu_helm_assets_medhelm-overview-3ddfcd65_png",
          "style": {
            "width": 700
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 332,
          "function_name": "realism",
          "code": "link(title=\"[MedHELM]\", url=\"https://crfm.stanford.edu/helm/medhelm/latest/#/leaderboard\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "[MedHELM]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://crfm.stanford.edu/helm/medhelm/latest/#/leaderboard",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 334,
          "function_name": "realism",
          "code": "text(\"Unfortunately, realism and privacy are sometimes at odds with each other.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Unfortunately, realism and privacy are sometimes at odds with each other.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 19,
          "function_name": "main",
          "code": "realism()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 337,
          "function_name": "validity",
          "code": "def validity():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 338,
          "function_name": "validity",
          "code": "text(\"How do we know our evaluations are valid?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "How do we know our evaluations are valid?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 340,
          "function_name": "validity",
          "code": "text(\"### Train-test overlap\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Train-test overlap",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 341,
          "function_name": "validity",
          "code": "text(\"- Machine learning 101: don't train on your test set\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Machine learning 101: don't train on your test set",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 342,
          "function_name": "validity",
          "code": "text(\"- Pre-foundation models (ImageNet, SQuAD): well-defined train-test splits\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Pre-foundation models (ImageNet, SQuAD): well-defined train-test splits",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 343,
          "function_name": "validity",
          "code": "text(\"- Nowadays: train on the Internet and don't tell people about your data\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Nowadays: train on the Internet and don't tell people about your data",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 345,
          "function_name": "validity",
          "code": "text(\"Route 1: try to infer train-test overlap from model\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Route 1: try to infer train-test overlap from model",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 346,
          "function_name": "validity",
          "code": "text(\"- Exploit exchangeability of data points\"), link(\"https://arxiv.org/pdf/2310.17623\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Exploit exchangeability of data points",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Proving Test Set Contamination in Black Box Language Models",
            "authors": [
              "Yonatan Oren",
              "Nicole Meister",
              "Niladri Chatterji",
              "Faisal Ladhak",
              "Tatsunori B. Hashimoto"
            ],
            "organization": null,
            "date": "2023-10-26T17:43:13Z",
            "url": "https://arxiv.org/pdf/2310.17623",
            "description": "Large language models are trained on vast amounts of internet data, prompting concerns and speculation that they have memorized public benchmarks. Going from speculation to proof of contamination is challenging, as the pretraining data used by proprietary models are often not publicly accessible. We show that it is possible to provide provable guarantees of test set contamination in language models without access to pretraining data or model weights. Our approach leverages the fact that when there is no data contamination, all orderings of an exchangeable benchmark should be equally likely. In contrast, the tendency for language models to memorize example order means that a contaminated language model will find certain canonical orderings to be much more likely than others. Our test flags potential contamination whenever the likelihood of a canonically ordered benchmark dataset is significantly higher than the likelihood after shuffling the examples. We demonstrate that our procedure is sensitive enough to reliably prove test set contamination in challenging situations, including models as small as 1.4 billion parameters, on small test sets of only 1000 examples, and datasets that appear only a few times in the pretraining corpus. Using our test, we audit five popular publicly accessible language models for test set contamination and find little evidence for pervasive contamination.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 347,
          "function_name": "validity",
          "code": "image(\"images/contamination-exchangeability.png\", width=600)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/contamination-exchangeability.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 349,
          "function_name": "validity",
          "code": "text(\"Route 2: encourage reporting norms (e.g., people report confidence intervals)\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Route 2: encourage reporting norms (e.g., people report confidence intervals)",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 350,
          "function_name": "validity",
          "code": "text(\"- Model providers should report train-test overlap \"), link(\"https://arxiv.org/abs/2410.08385\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Model providers should report train-test overlap ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Language model developers should report train-test overlap",
            "authors": [
              "Andy K Zhang",
              "Kevin Klyman",
              "Yifan Mai",
              "Yoav Levine",
              "Yian Zhang",
              "Rishi Bommasani",
              "Percy Liang"
            ],
            "organization": null,
            "date": "2024-10-10T21:44:56Z",
            "url": "https://arxiv.org/abs/2410.08385",
            "description": "Language models are extensively evaluated, but correctly interpreting evaluation results requires knowledge of train-test overlap which refers to the extent to which the language model is trained on the very data it is being tested on. The public currently lacks adequate information about train-test overlap: most models have no public train-test overlap statistics, and third parties cannot directly measure train-test overlap since they do not have access to the training data. To make this clear, we document the practices of 30 model developers, finding that just 9 developers report train-test overlap: 4 developers release training data under open-source licenses, enabling the community to directly measure train-test overlap, and 5 developers publish their train-test overlap methodology and statistics. By engaging with language model developers, we provide novel information about train-test overlap for three additional developers. Overall, we take the position that language model developers should publish train-test overlap statistics and/or training data whenever they report evaluation results on public test sets. We hope our work increases transparency into train-test overlap to increase the community-wide trust in model evaluations.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 352,
          "function_name": "validity",
          "code": "text(\"### Dataset quality\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "### Dataset quality",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 353,
          "function_name": "validity",
          "code": "text(\"- Fixed up SWE-Bench to produce SWE-Bench Verified \"), blog_link(\"https://openai.com/index/introducing-swe-bench-verified/\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Fixed up SWE-Bench to produce SWE-Bench Verified ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": " [blog]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://openai.com/index/introducing-swe-bench-verified/",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 354,
          "function_name": "validity",
          "code": "text(\"- Create Platinum versions of benchmarks\"), link(\"https://arxiv.org/abs/2502.03461\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Create Platinum versions of benchmarks",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "Do Large Language Model Benchmarks Test Reliability?",
            "authors": [
              "Joshua Vendrow",
              "Edward Vendrow",
              "Sara Beery",
              "Aleksander Madry"
            ],
            "organization": null,
            "date": "2025-02-05T18:58:19Z",
            "url": "https://arxiv.org/abs/2502.03461",
            "description": "When deploying large language models (LLMs), it is important to ensure that these models are not only capable, but also reliable. Many benchmarks have been created to track LLMs' growing capabilities, however there has been no similar focus on measuring their reliability. To understand the potential ramifications of this gap, we investigate how well current benchmarks quantify model reliability. We find that pervasive label errors can compromise these evaluations, obscuring lingering model failures and hiding unreliable behavior. Motivated by this gap in the evaluation of reliability, we then propose the concept of so-called platinum benchmarks, i.e., benchmarks carefully curated to minimize label errors and ambiguity. As a first attempt at constructing such benchmarks, we revise examples from fifteen existing popular benchmarks. We evaluate a wide range of models on these platinum benchmarks and find that, indeed, frontier LLMs still exhibit failures on simple tasks such as elementary-level math word problems. Analyzing these failures further reveals previously unidentified patterns of problems on which frontier models consistently struggle. We provide code at https://github.com/MadryLab/platinum-benchmarks",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 355,
          "function_name": "validity",
          "code": "image(\"https://pbs.twimg.com/media/GjICXQlWkAAYnDS?format=jpg&name=4096x4096\", width=700)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-a1149b095a48ea306dcdea342363230c-https_pbs_twimg_com_media_GjICXQlWkAAYnDS_format_jpg_name_4096x4096",
          "style": {
            "width": 700
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 356,
          "function_name": "validity",
          "code": "image(\"https://pbs.twimg.com/media/GjICcGQXYAAM4o1?format=jpg&name=4096x4096\", width=800)"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "var/files/image-306ae3f862cee7c7842c0b29af3a2f5c-https_pbs_twimg_com_media_GjICcGQXYAAM4o1_format_jpg_name_4096x4096",
          "style": {
            "width": 800
          },
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 20,
          "function_name": "main",
          "code": "validity()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 359,
          "function_name": "what_are_we_evaluating",
          "code": "def what_are_we_evaluating():"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 360,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"What are we even evaluating?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "What are we even evaluating?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 361,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"In other words, what are the rules of a game?\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "In other words, what are the rules of a game?",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 363,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"Pre-foundation models, we evaluated **methods** (standardized train-test splits).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Pre-foundation models, we evaluated **methods** (standardized train-test splits).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 364,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"Today, we're evaluating **models/systems** (anything goes).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Today, we're evaluating **models/systems** (anything goes).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 366,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"There are some exceptions...\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "There are some exceptions...",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 367,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"nanogpt speedrun: fixed data, compute time to get to a particular validation loss\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "nanogpt speedrun: fixed data, compute time to get to a particular validation loss",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 368,
          "function_name": "what_are_we_evaluating",
          "code": "image(\"images/karpathy-nanogpt-speedrun.png\", width=600), x_link(\"https://x.com/karpathy/status/1846790537262571739\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "image",
          "data": "images/karpathy-nanogpt-speedrun.png",
          "style": {
            "width": 600
          },
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": " [X]",
            "authors": null,
            "organization": null,
            "date": null,
            "url": "https://x.com/karpathy/status/1846790537262571739",
            "description": null,
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 370,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"DataComp-LM: given a raw dataset, get the best accuracy using standard training pipeline \"), link(\"https://arxiv.org/abs/2406.11794\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "DataComp-LM: given a raw dataset, get the best accuracy using standard training pipeline ",
          "style": {},
          "external_link": null,
          "internal_link": null
        },
        {
          "type": "link",
          "data": null,
          "style": {},
          "external_link": {
            "title": "DataComp-LM: In search of the next generation of training sets for language models",
            "authors": [
              "Jeffrey Li",
              "Alex Fang",
              "Georgios Smyrnis",
              "Maor Ivgi",
              "Matt Jordan",
              "Samir Gadre",
              "Hritik Bansal",
              "Etash Guha",
              "Sedrick Keh",
              "Kushal Arora",
              "Saurabh Garg",
              "Rui Xin",
              "Niklas Muennighoff",
              "Reinhard Heckel",
              "Jean Mercat",
              "Mayee Chen",
              "Suchin Gururangan",
              "Mitchell Wortsman",
              "Alon Albalak",
              "Yonatan Bitton",
              "Marianna Nezhurina",
              "Amro Abbas",
              "Cheng-Yu Hsieh",
              "Dhruba Ghosh",
              "Josh Gardner",
              "Maciej Kilian",
              "Hanlin Zhang",
              "Rulin Shao",
              "Sarah Pratt",
              "Sunny Sanyal",
              "Gabriel Ilharco",
              "Giannis Daras",
              "Kalyani Marathe",
              "Aaron Gokaslan",
              "Jieyu Zhang",
              "Khyathi Chandu",
              "Thao Nguyen",
              "Igor Vasiljevic",
              "Sham Kakade",
              "Shuran Song",
              "Sujay Sanghavi",
              "Fartash Faghri",
              "Sewoong Oh",
              "Luke Zettlemoyer",
              "Kyle Lo",
              "Alaaeldin El-Nouby",
              "Hadi Pouransari",
              "Alexander Toshev",
              "Stephanie Wang",
              "Dirk Groeneveld",
              "Luca Soldaini",
              "Pang Wei Koh",
              "Jenia Jitsev",
              "Thomas Kollar",
              "Alexandros G. Dimakis",
              "Yair Carmon",
              "Achal Dave",
              "Ludwig Schmidt",
              "Vaishaal Shankar"
            ],
            "organization": null,
            "date": "2024-06-17T17:42:57Z",
            "url": "https://arxiv.org/abs/2406.11794",
            "description": "We introduce DataComp for Language Models (DCLM), a testbed for controlled dataset experiments with the goal of improving language models. As part of DCLM, we provide a standardized corpus of 240T tokens extracted from Common Crawl, effective pretraining recipes based on the OpenLM framework, and a broad suite of 53 downstream evaluations. Participants in the DCLM benchmark can experiment with data curation strategies such as deduplication, filtering, and data mixing at model scales ranging from 412M to 7B parameters. As a baseline for DCLM, we conduct extensive experiments and find that model-based filtering is key to assembling a high-quality training set. The resulting dataset, DCLM-Baseline enables training a 7B parameter language model from scratch to 64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the previous state-of-the-art in open-data language models, DCLM-Baseline represents a 6.6 percentage point improvement on MMLU while being trained with 40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and Llama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53 natural language understanding tasks while being trained with 6.6x less compute than Llama 3 8B. Our results highlight the importance of dataset design for training language models and offer a starting point for further research on data curation.",
            "notes": null
          },
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 372,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"Evaluating methods encourage algorithmic innovation from researchers.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Evaluating methods encourage algorithmic innovation from researchers.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 373,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"Evaluating models/systems is useful for downstream users.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Evaluating models/systems is useful for downstream users.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        },
        {
          "path": "lecture_12.py",
          "line_number": 375,
          "function_name": "what_are_we_evaluating",
          "code": "text(\"Either way, we need to define the rules of the game!\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Either way, we need to define the rules of the game!",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 21,
          "function_name": "main",
          "code": "what_are_we_evaluating()"
        }
      ],
      "env": {},
      "renderings": [],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 23,
          "function_name": "main",
          "code": "text(\"Takeaways\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "Takeaways",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 24,
          "function_name": "main",
          "code": "text(\"- There is no one true evaluation; choose the evaluation depending on what you're trying to measure.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- There is no one true evaluation; choose the evaluation depending on what you're trying to measure.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 25,
          "function_name": "main",
          "code": "text(\"- Always look at the individual instances and the predictions.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Always look at the individual instances and the predictions.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 26,
          "function_name": "main",
          "code": "text(\"- There are many aspects to consider: capabilities, safety, costs, realism.\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- There are many aspects to consider: capabilities, safety, costs, realism.",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    },
    {
      "stack": [
        {
          "path": "lecture_12.py",
          "line_number": 27,
          "function_name": "main",
          "code": "text(\"- Clearly state the rules of the game (methods versus models/systems).\")"
        }
      ],
      "env": {},
      "renderings": [
        {
          "type": "markdown",
          "data": "- Clearly state the rules of the game (methods versus models/systems).",
          "style": {},
          "external_link": null,
          "internal_link": null
        }
      ],
      "stdout": "",
      "stderr": ""
    }
  ]
}