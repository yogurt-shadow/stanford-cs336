<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D2204.07705%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=2204.07705&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/FwRyKabj3gH3NogNch5jZFKsWoc</id>
  <updated>2025-05-13T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2204.07705v3</id>
    <updated>2022-10-24T07:00:15Z</updated>
    <published>2022-04-16T03:12:30Z</published>
    <title>Super-NaturalInstructions: Generalization via Declarative Instructions
  on 1600+ NLP Tasks</title>
    <summary>  How well can NLP models generalize to a variety of unseen tasks when provided
with task instructions? To address this question, we first introduce
Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their
expert-written instructions. Our collection covers 76 distinct task types,
including but not limited to classification, extraction, infilling, sequence
tagging, text rewriting, and text composition. This large and diverse
collection of tasks enables rigorous benchmarking of cross-task generalization
under instructions -- training models to follow instructions on a subset of
tasks and evaluating them on the remaining unseen ones. Furthermore, we build
Tk-Instruct, a transformer model trained to follow a variety of in-context
instructions (plain language task definitions or k-shot examples). Our
experiments show that Tk-Instruct outperforms existing instruction-following
models such as InstructGPT by over 9% on our benchmark despite being an order
of magnitude smaller. We further analyze generalization as a function of
various scaling parameters, such as the number of observed tasks, the number of
instances per task, and model sizes. We hope our dataset and model facilitate
future progress towards more general-purpose NLP models.
</summary>
    <author>
      <name>Yizhong Wang</name>
    </author>
    <author>
      <name>Swaroop Mishra</name>
    </author>
    <author>
      <name>Pegah Alipoormolabashi</name>
    </author>
    <author>
      <name>Yeganeh Kordi</name>
    </author>
    <author>
      <name>Amirreza Mirzaei</name>
    </author>
    <author>
      <name>Anjana Arunkumar</name>
    </author>
    <author>
      <name>Arjun Ashok</name>
    </author>
    <author>
      <name>Arut Selvan Dhanasekaran</name>
    </author>
    <author>
      <name>Atharva Naik</name>
    </author>
    <author>
      <name>David Stap</name>
    </author>
    <author>
      <name>Eshaan Pathak</name>
    </author>
    <author>
      <name>Giannis Karamanolakis</name>
    </author>
    <author>
      <name>Haizhi Gary Lai</name>
    </author>
    <author>
      <name>Ishan Purohit</name>
    </author>
    <author>
      <name>Ishani Mondal</name>
    </author>
    <author>
      <name>Jacob Anderson</name>
    </author>
    <author>
      <name>Kirby Kuznia</name>
    </author>
    <author>
      <name>Krima Doshi</name>
    </author>
    <author>
      <name>Maitreya Patel</name>
    </author>
    <author>
      <name>Kuntal Kumar Pal</name>
    </author>
    <author>
      <name>Mehrad Moradshahi</name>
    </author>
    <author>
      <name>Mihir Parmar</name>
    </author>
    <author>
      <name>Mirali Purohit</name>
    </author>
    <author>
      <name>Neeraj Varshney</name>
    </author>
    <author>
      <name>Phani Rohitha Kaza</name>
    </author>
    <author>
      <name>Pulkit Verma</name>
    </author>
    <author>
      <name>Ravsehaj Singh Puri</name>
    </author>
    <author>
      <name>Rushang Karia</name>
    </author>
    <author>
      <name>Shailaja Keyur Sampat</name>
    </author>
    <author>
      <name>Savan Doshi</name>
    </author>
    <author>
      <name>Siddhartha Mishra</name>
    </author>
    <author>
      <name>Sujan Reddy</name>
    </author>
    <author>
      <name>Sumanta Patro</name>
    </author>
    <author>
      <name>Tanay Dixit</name>
    </author>
    <author>
      <name>Xudong Shen</name>
    </author>
    <author>
      <name>Chitta Baral</name>
    </author>
    <author>
      <name>Yejin Choi</name>
    </author>
    <author>
      <name>Noah A. Smith</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2022, 25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2204.07705v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2204.07705v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
