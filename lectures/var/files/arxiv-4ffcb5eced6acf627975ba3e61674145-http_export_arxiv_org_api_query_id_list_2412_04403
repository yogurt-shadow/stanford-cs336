<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3D%26id_list%3D2412.04403%26start%3D0%26max_results%3D10" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=&amp;id_list=2412.04403&amp;start=0&amp;max_results=10</title>
  <id>http://arxiv.org/api/Ij9pgu28TlrhmF6MfXnCpRNvH40</id>
  <updated>2025-05-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">10</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2412.04403v1</id>
    <updated>2024-12-05T18:21:49Z</updated>
    <published>2024-12-05T18:21:49Z</published>
    <title>Establishing Task Scaling Laws via Compute-Efficient Model Ladders</title>
    <summary>  We develop task scaling laws and model ladders to predict the individual task
performance of pretrained language models (LMs) in the overtrained setting.
Standard power laws for language modeling loss cannot accurately model task
performance. Therefore, we leverage a two-step prediction approach: first use
model and data size to predict a task-specific loss, and then use this task
loss to predict task performance. We train a set of small-scale "ladder"
models, collect data points to fit the parameterized functions of the two
prediction steps, and make predictions for two target models: a 7B model
trained to 4T tokens and a 13B model trained to 5T tokens. Training the ladder
models only costs 1% of the compute used for the target models. On four
multiple-choice tasks written in ranked classification format, we can predict
the accuracy of both target models within 2 points of absolute error. We have
higher prediction error on four other tasks (average absolute error 6.9) and
find that these are often tasks with higher variance in task metrics. We also
find that using less compute to train fewer ladder models tends to deteriorate
predictions. Finally, we empirically show that our design choices and the
two-step approach lead to superior performance in establishing scaling laws.
</summary>
    <author>
      <name>Akshita Bhagia</name>
    </author>
    <author>
      <name>Jiacheng Liu</name>
    </author>
    <author>
      <name>Alexander Wettig</name>
    </author>
    <author>
      <name>David Heineman</name>
    </author>
    <author>
      <name>Oyvind Tafjord</name>
    </author>
    <author>
      <name>Ananya Harsh Jha</name>
    </author>
    <author>
      <name>Luca Soldaini</name>
    </author>
    <author>
      <name>Noah A. Smith</name>
    </author>
    <author>
      <name>Dirk Groeneveld</name>
    </author>
    <author>
      <name>Pang Wei Koh</name>
    </author>
    <author>
      <name>Jesse Dodge</name>
    </author>
    <author>
      <name>Hannaneh Hajishirzi</name>
    </author>
    <link href="http://arxiv.org/abs/2412.04403v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2412.04403v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
